{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37363014-d5bd-4d0b-8093-ad182644070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install gymnasium==0.28.1\n",
    "# !python -m pip install stable-baselines3[extra]==2.1.0\n",
    "# !python -m pip install ax-platform==0.3.4\n",
    "# !python -m pip install wandb\n",
    "# !python -m pip install onnx==1.14.1\n",
    "# !python -m pip install onnxruntime==1.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ed8b9b-73a0-4c11-9c12-4bbd6b0debfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.13.1\n",
      "gymnasium version: 0.28.1\n",
      "sb3 version: 2.1.0\n",
      "cv2 version: 4.8.0.76\n",
      "ax version: 0.3.4\n"
     ]
    }
   ],
   "source": [
    "# Check versions\n",
    "import importlib.metadata\n",
    "\n",
    "print(f\"torch version: {importlib.metadata.version('torch')}\")\n",
    "print(f\"gymnasium version: {importlib.metadata.version('gymnasium')}\")\n",
    "print(f\"sb3 version: {importlib.metadata.version('stable-baselines3')}\")\n",
    "print(f\"cv2 version: {importlib.metadata.version('opencv-python')}\")\n",
    "print(f\"ax version: {importlib.metadata.version('ax-platform')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6601a351-afc4-4ad6-8119-335dce1392cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Standard Library\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "import math\n",
    "import csv\n",
    "from typing import Any, Dict, Tuple, Union\n",
    "\n",
    "# Encoder and stepper controls (local)\n",
    "from control_comms import ControlComms, StatusCode, DebugLevel\n",
    "\n",
    "# Third-party packages\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "import torch as th\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Reinforcement model modules\n",
    "import stable_baselines3 as sb3\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import KVWriter, Logger\n",
    "\n",
    "# Meta Ax\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render\n",
    "from ax.utils.tutorials.cnn_utils import train, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002868a4-1404-46fb-88a0-80adf9ee9dc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5512c5e3-f346-4866-be07-c9f275fc1b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communication settings\n",
    "SERIAL_PORT = \"COM4\"    # Check your devices\n",
    "BAUD_RATE = 1_000_000   # Must match what's in the Arduino code!\n",
    "CTRL_TIMEOUT = 2.0      # Seconds\n",
    "DEBUG_LEVEL = DebugLevel.DEBUG_ERROR\n",
    "\n",
    "# Reinforcement learning settings\n",
    "K_T = 1                 # Reward constant to multiply theta (angle of encoder)\n",
    "K_DT = 0.01             # Reward constant to multiply dtheto/dt (angular velocity of encoder)\n",
    "K_P = 0.001             # Reward constant to multiply phi (angle of stepper)\n",
    "K_DP = 0.00001          # Reward constant to multiply dphi/dt (angular velocity of stepper)\n",
    "REWARD_OOB = -500       # Reward (penalty) for having the stepper motor move out of bounds (OOB)\n",
    "REWARD_LAND = 100       # Reward for having the pendulum softly reach the top of the swing up\n",
    "REWARD_CRASH = -200     # Reward (penalty) for having the pendulum swing too fast into the crash zone\n",
    "ENC_ANGLE_NORM = 180    # Divide by this to normalize +/-180 deg angle to +/-1\n",
    "ENC_GOAL_ANGLE = 5      # Reward agent and end episode if pendulum is within the goal (+/-5 deg)\n",
    "ENC_GOAL_VELOCITY = 540 # ...and velocity is <= this amount (deg/sec)\n",
    "ENC_CRASH_ANGLE = 45    # Penalize agent and end episode if pendulum is within the crash zone (+/- 45 deg)\n",
    "ENC_CRASH_VELOCITY = 540 # ...and veolicy is > this amount (deg/sec)\n",
    "STP_ACTIONS_MAP = {\n",
    "    0: -10,\n",
    "    1: 0,\n",
    "    2: 10,\n",
    "}\n",
    "STP_ANGLE_MIN = -180    # Episode ends if stepper goes beyond this angle\n",
    "STP_ANGLE_MAX = 180     # Episode ends if stepper goes beyond this angle\n",
    "STP_ANGLE_NORM = 180    # Divide by this to normalize +/-180 deg angle to +/-1\n",
    "\n",
    "# Environment settings\n",
    "ENV_TIMEOUT = 30.0\n",
    "RESET_SETTLE_TIME = 8.0 # Seconds to wait after reset to start moving again\n",
    "\n",
    "# Angle constants\n",
    "ENC_OFFSET = 180.0      # Pendulum in the \"up\" position should be 0 deg\n",
    "ANG_REV = 360           # Degrees in a single revolution\n",
    "\n",
    "# Conversion settings\n",
    "REP_SAMPLE_SET_PATH = \"rep-sample.npy\"  # Where to save representative sample set\n",
    "OUT_ONNX_PATH = \"pendulum-policy.onnx\"  # Where to save the final policy network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "631b6b53-ca9c-41c4-858c-581fcfbbe524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communication constants\n",
    "CMD_SET_HOME = 0        # Set current stepper position as home (0 deg)\n",
    "CMD_MOVE_TO = 1         # Move stepper to a particular position (deg)\n",
    "CMD_MOVE_BY = 2         # Move stepper by a given amount (deg)\n",
    "CMD_SET_STEP_MODE = 3   # Set step mode\n",
    "CMD_SET_BLOCK_MODE = 4  # Set blocking mode\n",
    "CMD_NOP = 5             # Take no action, just receive observation\n",
    "CMD_MOVE_HOME = 6       # Slowly move pendulum back to starting position\n",
    "STEP_MODE_1 = 0         # 1 division per step\n",
    "STEP_MODE_2 = 1         # 2 divisions per step\n",
    "STEP_MODE_4 = 2         # 4 divisions per step\n",
    "STEP_MODE_8 = 3         # 8 divisions per step\n",
    "STEP_MODE_16 = 4        # 16 divisions per step\n",
    "STATUS_OK = 0           # Stepper idle\n",
    "STATUS_STP_MOVING = 1   # Stepper is currently moving\n",
    "\n",
    "# Set to desired step mode\n",
    "STEP_MODE = STEP_MODE_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00724565-b597-4c6a-a8fd-9dec4114949b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "316bc585-a495-4ad3-ae94-6b0930a38bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection to Arduino board (if open)\n",
    "try:\n",
    "    controller.close()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd6f5fef-12a0-405f-972a-fc6eb40b2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Arduino board\n",
    "controller = ControlComms(timeout=CTRL_TIMEOUT, debug_level=DEBUG_LEVEL)\n",
    "ret = controller.connect(SERIAL_PORT, BAUD_RATE)\n",
    "if ret is not StatusCode.OK:\n",
    "    print(\"ERROR: Could not connect to board\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61f80790-322b-498b-bef8-211d8a2696d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing message. Message received: Observation: 0.94, -0.00, 0.08, 0.02, dtime: 2.350\n",
      "\n",
      "Error parsing message. Message received: Observation: 0.90, -0.50, 0.13, 0.69, dtime: 0.080\n",
      "\n",
      "Error parsing message. Message received: Observation: 0.90, -0.19, 0.13, 0.00, dtime: 0.009\n",
      "\n",
      "Error parsing message. Message received: Observation: 0.90, -0.09, 0.19, 0.73, dtime: 0.075\n",
      "\n",
      "Error parsing message. Message received: Observation: 0.90, 0.21, 0.19, 0.00, dtime: 0.008\n",
      "\n",
      "Error parsing message. Message received: Observation: 0.92, 0.27, 0.24, 0.73, dtime: 0.075\n",
      "\n",
      "Error parsing message. Message received: Observation: 0.92, 0.74, 0.24, 0.00, dtime: 0.009\n",
      "\n",
      "Error parsing message. Message received: Observation: 0.96, 0.53, 0.30, 0.73, dtime: 0.075\n",
      "\n",
      "Error parsing message. Message received: Observation: -0.99, 0.58, 0.36, 0.69, dtime: 0.080\n",
      "\n",
      "Error parsing message. Message received: Observation: -0.88, 1.59, 0.31, -0.75, dtime: 0.067\n",
      "\n",
      "Error parsing message. Message received: Observation: -0.80, 1.26, 0.25, -0.76, dtime: 0.066\n",
      "\n",
      "Error parsing message. Message received: Observation: -0.80, 0.56, 0.25, 0.00, dtime: 0.009\n",
      "\n",
      "Error parsing message. Message received: Observation: -0.76, 0.55, 0.21, -0.82, dtime: 0.061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test basic comms\n",
    "controller.step(CMD_SET_STEP_MODE, [STEP_MODE_8])\n",
    "controller.step(CMD_SET_HOME, [0])\n",
    "controller.step(CMD_SET_BLOCK_MODE, [1])\n",
    "for i in range(10):\n",
    "    controller.step(CMD_MOVE_BY, [10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef863618-7b2e-464f-9da1-f4f1f957d0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing message. Message received: Observation: -0.76, -0.19, 0.21, 0.00, dtime: 0.009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Numpy test\n",
    "action = np.array([[-25]])\n",
    "action_list = action.flatten().tolist()\n",
    "controller.step(CMD_MOVE_BY, action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9eeb8708-c488-42c6-8b2d-a6026fe9ea46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing message. Message received: Observation: -0.76, -0.21, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.77, -0.63, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.77, -0.56, 0.21, 0.00, dtime: 0.009\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.78, -0.83, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.79, -0.83, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.79, -0.56, 0.21, 0.00, dtime: 0.009\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.80, -1.04, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.81, -1.04, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.82, -1.30, 0.21, 0.00, dtime: 0.009\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.83, -1.25, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.84, -1.25, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.85, -1.11, 0.21, 0.00, dtime: 0.009\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.87, -1.67, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.88, -1.67, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.89, -1.30, 0.21, 0.00, dtime: 0.009\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.90, -1.67, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.92, -1.67, 0.21, 0.00, dtime: 0.009\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.93, -1.87, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.95, -1.67, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: -0.96, -1.48, 0.21, 0.00, dtime: 0.009\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Test hard limit (360 deg)\n",
    "for i in range(20):\n",
    "    resp = controller.step(CMD_MOVE_BY, [50])\n",
    "    print(resp)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c323e9db-1363-431f-8bae-9d44c0a03085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing message. Message received: Observation: -0.98, -2.08, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "Error parsing message. Message received: Observation: -0.99, -1.87, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: 1.00, -1.48, 0.21, 0.00, dtime: 0.009\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: 0.83, -2.24, 0.26, 0.73, dtime: 0.075\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: 0.81, -2.08, 0.26, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: 0.70, -1.53, 0.31, 0.73, dtime: 0.075\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: 0.69, -0.74, 0.31, 0.00, dtime: 0.009\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: 0.68, -0.83, 0.31, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: 0.68, -0.42, 0.31, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: 0.68, -0.19, 0.31, 0.00, dtime: 0.009\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: 0.68, -0.21, 0.31, 0.00, dtime: 0.008\n",
      "\n",
      "None\n",
      "Error parsing message. Message received: Observation: 0.68, 0.00, 0.31, 0.00, dtime: 0.008\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Stress/torque test\n",
    "resp = controller.step(CMD_MOVE_HOME, [0])\n",
    "controller.step(CMD_SET_BLOCK_MODE, [1])\n",
    "print(resp)\n",
    "time.sleep(2.0)\n",
    "action = 180\n",
    "for i in range(10):\n",
    "    action = -180 if action == 180 else 180\n",
    "    resp = controller.step(CMD_MOVE_BY, [action])\n",
    "    print(resp)\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cfacfca-7ede-4fc3-a300-083084de93fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comms stress test\n",
    "# resp = controller.step(CMD_MOVE_TO, [0])\n",
    "# print(resp)\n",
    "# time.sleep(2.0)\n",
    "# for i in range(100000):\n",
    "#     resp = controller.step(CMD_MOVE_BY, [0])\n",
    "#     time.sleep(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a35db2c4-96d4-42f2-81f1-4b6a3746e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing message. Message received: Observation: 0.68, 0.00, 0.31, 0.00, dtime: 0.009\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Move home\n",
    "resp = controller.step(CMD_MOVE_HOME, [0])\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c07c94e-8ab6-490f-b856-ca817352049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close comms\n",
    "controller.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827948c0-7a81-44e3-81e3-95d5c13eafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic step test\n",
    "action = np.array([[-10]])\n",
    "\n",
    "controller = ControlComms(timeout=CTRL_TIMEOUT, debug_level=DEBUG_LEVEL)\n",
    "ret = controller.connect(SERIAL_PORT, BAUD_RATE)\n",
    "if ret is not StatusCode.OK:\n",
    "    print(\"ERROR: Could not connect to board\")\n",
    "\n",
    "# Set to blocking mode\n",
    "resp = controller.step(CMD_SET_BLOCK_MODE, [1])\n",
    "print(resp)\n",
    "    \n",
    "# Reset\n",
    "time.sleep(2.0)\n",
    "resp = controller.step(CMD_MOVE_HOME, [0.0])\n",
    "print(resp)\n",
    "time.sleep(2.0)\n",
    "\n",
    "# Loop\n",
    "for i in range(10):\n",
    "    action_list = action.flatten().tolist()\n",
    "    resp = controller.step(CMD_MOVE_BY, action_list)\n",
    "    print(resp)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# Move home and close\n",
    "resp = controller.step(CMD_MOVE_TO, [0])\n",
    "print(resp)\n",
    "controller.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbf62f43-718b-4997-b112-86c364a3f7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshawnhymel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log in to Weights & Biases\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3cce2f0-188f-40af-9282-ea58bb80e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make wandb be quiet\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "logger = logging.getLogger(\"wandb\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1566ff73-1195-4710-bab6-05a8309f7fa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6800b3d-197b-465f-b09b-b451708a16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds(seed: int) -> None:\n",
    "    \"\"\"\n",
    "    Seed the different random generators.\n",
    "    https://stable-baselines3.readthedocs.io/en/master/_modules/stable_baselines3/common/utils.html\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set seed for Python random and NumPy\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9bb2c64-36e7-41cc-9c86-67b35d741ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_angular_velocity(ang, ang_prev, dt):\n",
    "    \"\"\"\n",
    "    Estimate engular velocity based on current and previous readings. Note that we assume that the\n",
    "    object in question cannot go the long way around (e.g. more than 180 deg).\n",
    "    \"\"\"\n",
    "    da = ang - ang_prev\n",
    "    if da > (ANG_REV / 2):\n",
    "        da -= ANG_REV\n",
    "    elif da < -(ANG_REV / 2):\n",
    "        da += ANG_REV\n",
    "    \n",
    "    return da / dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9cd180-65fe-40f2-88bf-e584bdbbd2cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build gym Environment\n",
    "\n",
    "Subclass gymnasium.Env to create a custom environment. Learn more here:<br>\n",
    "https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32bcddaa-b899-4cab-9a7b-82bd214c3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pendulum(gym.Env):\n",
    "    \"\"\"\n",
    "    Subclass gymnasium Env class\n",
    "    \n",
    "    This is the gym wrapper class that allows our agent to interact with our environment. We need\n",
    "    to implement four main methods: step(), reset(), render(), and close(). We should also define\n",
    "    the action_space and observation space as class members.\n",
    "    \n",
    "    Note: on Windows, time.sleep() is only accurate to around 10ms. As a result, setting fps_limit\n",
    "    will give you a \"best effort\" limit.\n",
    "    \n",
    "    More information: https://gymnasium.farama.org/api/env/\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        serial_port,\n",
    "        baud_rate,\n",
    "        ctrl_timeout=1.0,\n",
    "        debug_level=DebugLevel.DEBUG_NONE,\n",
    "        env_timeout=0.0, \n",
    "        stp_mode=STEP_MODE_8, \n",
    "        stp_blocking=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Set up the environment, action, and observation shapes. Optional tiemout in seconds.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Call superclass's constructor\n",
    "        super().__init__()\n",
    "        \n",
    "        # Connect to Arduino board\n",
    "        self.ctrl = ControlComms(timeout=ctrl_timeout, debug_level=debug_level)\n",
    "        try:\n",
    "            self.ctrl.close()\n",
    "        except:\n",
    "            pass\n",
    "        ret = self.ctrl.connect(serial_port, baud_rate)\n",
    "        if ret is not StatusCode.OK:\n",
    "            print(\"ERROR: Could not connect to board\")\n",
    "        \n",
    "        # Define action space (scalar signifying how many degrees to move stepper by)\n",
    "        self.action_space = gym.spaces.Discrete(len(STP_ACTIONS_MAP))\n",
    "        \n",
    "        # Define observation space \n",
    "        # [encoder angle, encoder angular velocity, stepper angle, stepper angular velocity]\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=np.array([-180, -np.inf, STP_ANGLE_MIN, -np.inf]),\n",
    "            high=np.array([180, np.inf, STP_ANGLE_MAX, np.inf]),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Record time from microcontroller and own elapsed time\n",
    "        self.timestamp = 0\n",
    "        self.timeout = env_timeout\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # Record previous encoder and stepper angles (to calculate velocities)\n",
    "        self.angle_stp_prev = 0\n",
    "        self.angle_enc_prev = 0\n",
    "        \n",
    "        # Set current stepper position as \"home\" and optionally set blocking\n",
    "        self.ctrl.step(CMD_SET_STEP_MODE, [stp_mode])\n",
    "        self.ctrl.step(CMD_SET_HOME, [0])\n",
    "        if stp_blocking:\n",
    "            self.ctrl.step(CMD_SET_BLOCK_MODE, [1])\n",
    "        else:\n",
    "            self.ctrl.step(CMD_SET_BLOCK_MODE, [0])\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"\n",
    "        Destructor: make sure to close the serial port\n",
    "        \"\"\"\n",
    "        self.close()\n",
    "    \n",
    "    def step(self, action: np.ndarray):\n",
    "        \"\"\"\n",
    "        What happens when you tell the stepper motor to do something then record the observation.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize return values\n",
    "        obs = np.array([0.0, 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "        reward = 0.0\n",
    "        info = {\"error\": False, \"dtime\": 0.0, \"elapsed_time\": 0.0}\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        \n",
    "        # Move the stepper motor and wait for a response\n",
    "        resp = self.ctrl.step(CMD_MOVE_BY, [STP_ACTIONS_MAP[action]])\n",
    "        \n",
    "        # Figure out reward and episode termination based on observation\n",
    "        if resp:\n",
    "            \n",
    "            # Extract information from controller response\n",
    "            status, timestamp, terminated, angles = resp\n",
    "            \n",
    "            # Compute lapsed time (in seconds) from previous observation (milliseconds)\n",
    "            info[\"dtime\"] = (timestamp - self.timestamp) / 1000.0\n",
    "            self.timestamp = timestamp\n",
    "            \n",
    "            # Offset encoder angle so that 0 deg is up\n",
    "            angles[0] -= ENC_OFFSET\n",
    "            \n",
    "            # Calculate velocities\n",
    "            dtheta = calc_angular_velocity(angles[0], self.angle_enc_prev, info['dtime'])\n",
    "            dphi = calc_angular_velocity(angles[1], self.angle_stp_prev, info['dtime'])\n",
    "            self.angle_enc_prev = angles[0]\n",
    "            self.angle_stp_prev = angles[1]\n",
    "            \n",
    "            # Construct observation (normalized)\n",
    "            obs[0] = angles[0] / ENC_ANGLE_NORM\n",
    "            obs[1] = dtheta / ENC_ANGLE_NORM\n",
    "            obs[2] = angles[1] / STP_ANGLE_NORM\n",
    "            obs[3] = dphi / STP_ANGLE_NORM\n",
    "\n",
    "            # Make sure stepper is in bounds\n",
    "            if (angles[1] >= STP_ANGLE_MIN) and (angles[1] <= STP_ANGLE_MAX):\n",
    "                \n",
    "                # Calculate reward\n",
    "                reward += -1 * (K_T * obs[0] ** 2 + \n",
    "                               K_DT * obs[1] ** 2 + \n",
    "                               K_P * obs[2] ** 2 +\n",
    "                               K_DP * obs[3] ** 2)\n",
    "                \n",
    "                \n",
    "                # If the pendulum is moving too fast in the crash zone, penalize and end\n",
    "                if (abs(angles[0]) <= ENC_CRASH_ANGLE) and (abs(dtheta) > ENC_CRASH_VELOCITY):\n",
    "                    reward += REWARD_CRASH\n",
    "                    terminated = True\n",
    "\n",
    "                # If the pendulum is moving slow enough in the goal zone, reward and end\n",
    "                elif (abs(angles[0]) <= ENC_GOAL_ANGLE) and (abs(dtheta) <= ENC_GOAL_VELOCITY):\n",
    "                    reward += REWARD_LAND\n",
    "                    terminated = True\n",
    "            \n",
    "            # Stepper motor is out of bounds--terminate episode\n",
    "            else:\n",
    "                reward = REWARD_OOB\n",
    "                terminated = True\n",
    "        \n",
    "        # Something is wrong with communication\n",
    "        else:\n",
    "            print(\"ERROR: Could not communicate with Arduino\")\n",
    "            info[\"error\"] = True\n",
    "            terminated = True\n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        info[\"elapsed_time\"] = time.time() - self.start_time\n",
    "        \n",
    "        # Check if we've exceeded the time limit\n",
    "        if not terminated and self.timeout > 0.0 and info[\"elapsed_time\"] >= self.timeout:\n",
    "            truncated = True\n",
    "        \n",
    "        return obs, reward, terminated, truncated, info\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        \"\"\"\n",
    "        Return the pendulum to the starting position\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize return values\n",
    "        obs = np.array([0.0, 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "        info = {\"error\": False, \"dtime\": 0, \"elapsed_time\": 0.0}\n",
    "        \n",
    "        # Reset timer\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # Let the pendulum fall and return to the starting position\n",
    "        time.sleep(2.0)\n",
    "        resp = self.ctrl.step(CMD_MOVE_HOME, [0.0])\n",
    "        if resp:\n",
    "            \n",
    "            # Extract information from controller response\n",
    "            status, timestamp, terminated, angles = resp\n",
    "            \n",
    "            # Compute lapsed time (in seconds) from previous observation (milliseconds)\n",
    "            info[\"dtime\"] = (timestamp - self.timestamp) / 1000.0\n",
    "            self.timestamp = timestamp\n",
    "            \n",
    "            # Offset encoder angle so that 0 deg is up\n",
    "            angles[0] -= ENC_OFFSET\n",
    "            \n",
    "            # Calculate velocities\n",
    "            dtheta = calc_angular_velocity(angles[0], self.angle_enc_prev, info['dtime'])\n",
    "            dphi = calc_angular_velocity(angles[1], self.angle_stp_prev, info['dtime'])\n",
    "            self.angle_enc_prev = angles[0]\n",
    "            self.angle_stp_prev = angles[1]\n",
    "            \n",
    "            # Construct observation (normalized)\n",
    "            obs[0] = angles[0] / ENC_ANGLE_NORM\n",
    "            obs[1] = dtheta / ENC_ANGLE_NORM\n",
    "            obs[2] = angles[1] / STP_ANGLE_NORM\n",
    "            obs[3] = dphi / STP_ANGLE_NORM\n",
    "            \n",
    "            # Let pendulum settle for a bit\n",
    "            time.sleep(RESET_SETTLE_TIME)\n",
    "            \n",
    "        # Something is wrong with communication\n",
    "        else:\n",
    "            print(\"ERROR: Could not communicate with Arduino\")\n",
    "            info[\"error\"] = True\n",
    "            \n",
    "        # Calculate elapsed time\n",
    "        info[\"elapsed_time\"] = time.time() - self.start_time\n",
    "        \n",
    "        return obs, info\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close connection to Arduino\n",
    "        \"\"\"\n",
    "        self.ctrl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac966999-8595-4e98-8a34-60ad251ce69c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test gym Environment\n",
    "\n",
    "Test the gym wrapper before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79b6c823-05f7-4368-815d-353bd1acf23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing message. Message received: \n",
      "Error parsing message. Message received: \n",
      "Error parsing message. Message received: \n"
     ]
    }
   ],
   "source": [
    "# Create our environment\n",
    "try:\n",
    "    env.close()\n",
    "except:\n",
    "    pass\n",
    "env = Pendulum(\n",
    "        SERIAL_PORT,\n",
    "        BAUD_RATE,\n",
    "        ctrl_timeout=CTRL_TIMEOUT,\n",
    "        debug_level=DEBUG_LEVEL,\n",
    "        env_timeout=ENV_TIMEOUT, \n",
    "        stp_mode=STEP_MODE, \n",
    "        stp_blocking=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4449add-5c21-4da2-9669-53e8017c7ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Check action space (should be what's on the STP_ACTIONS_MAP)\n",
    "for i in range(10):\n",
    "    print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f607dd4c-2858-48d4-a115-97e98a943c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing message. Message received: \n",
      "\n",
      "ERROR: Could not communicate with Arduino\n",
      "Stopping\n"
     ]
    }
   ],
   "source": [
    "# Test encoder\n",
    "obs, info = env.reset()\n",
    "obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "if info[\"error\"]:\n",
    "    print(\"Stopping\")\n",
    "else:\n",
    "    print(f\"{'Step': ^8} | {'Observation': ^36} | {'Reward': ^8} | {'Done': ^8} | Info\")\n",
    "    print(f\"{'Reset': ^8} | {obs_str: <36} | {0.0: <8} | {str(False): ^8} | {info}\")\n",
    "    for i in range(10):\n",
    "        obs, reward, terminated, truncated, info = env.step(1)\n",
    "        obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "        print(f\"{i: ^8} | {obs_str: <36} | {reward: <8.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "        if info[\"error\"]:\n",
    "            print(\"Stopping\")\n",
    "            break\n",
    "        if terminated or truncated:\n",
    "            print(\"Episode done\")\n",
    "            break\n",
    "        time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86c0662c-422c-4b5a-a58f-ba6b5e58eb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing message. Message received: --- Start episode ---\n",
      "\n",
      "ERROR: Could not communicate with Arduino\n",
      "Stopping\n"
     ]
    }
   ],
   "source": [
    "# Test encoder (no pause)\n",
    "obs, info = env.reset()\n",
    "obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "if info[\"error\"]:\n",
    "    print(\"Stopping\")\n",
    "else:\n",
    "    print(f\"{'Step': ^8} | {'Observation': ^36} | {'Reward': ^8} | {'Done': ^8} | Info\")\n",
    "    print(f\"{'Reset': ^8} | {obs_str: <36} | {0.0: <8} | {str(False): ^8} | {info}\")\n",
    "    for i in range(20):\n",
    "        obs, reward, terminated, truncated, info = env.step(1)\n",
    "        obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "        print(f\"{i: ^8} | {obs_str: <36} | {reward: <8.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "        if info[\"error\"]:\n",
    "            print(\"Stopping\")\n",
    "            break\n",
    "        if terminated or truncated:\n",
    "            print(\"Episode done\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ac5a0e1-d72a-4052-a8db-086fd6d288a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step   |  Action  |             Observation              |  Reward  |   Done   | Info\n",
      " Reset   |    0     | 1.00, 0.00, 0.00, 0.00               | 0.0      |  False   | {'error': False, 'dtime': 2.025, 'elapsed_time': 10.032556772232056}\n",
      "   0     |    0     | -0.96, 0.00, -0.05, -0.01            | -0.93    |  False   | {'error': False, 'dtime': 8.086, 'elapsed_time': 10.098191261291504}\n",
      "   1     |    1     | -0.96, 0.28, -0.05, 0.00             | -0.93    |  False   | {'error': False, 'dtime': 0.012, 'elapsed_time': 10.11621618270874}\n",
      "   2     |    1     | -0.96, -0.16, -0.05, 0.00            | -0.93    |  False   | {'error': False, 'dtime': 0.021, 'elapsed_time': 10.131706714630127}\n",
      "   3     |    1     | -0.97, -0.11, -0.05, 0.00            | -0.93    |  False   | {'error': False, 'dtime': 0.015, 'elapsed_time': 10.150167226791382}\n",
      "   4     |    0     | -0.94, 0.31, -0.10, -0.72            | -0.89    |  False   | {'error': False, 'dtime': 0.069, 'elapsed_time': 10.216284990310669}\n",
      "   5     |    2     | 0.99, -0.85, -0.05, 0.67             | -0.98    |  False   | {'error': False, 'dtime': 0.082, 'elapsed_time': 10.301149606704712}\n",
      "   6     |    2     | 0.92, -0.75, 0.01, 0.63              | -0.85    |  False   | {'error': False, 'dtime': 0.087, 'elapsed_time': 10.389235258102417}\n",
      "   7     |    1     | 0.92, -0.25, 0.01, 0.00              | -0.84    |  False   | {'error': False, 'dtime': 0.02, 'elapsed_time': 10.409626722335815}\n",
      "   8     |    1     | 0.92, 0.00, 0.01, 0.00               | -0.84    |  False   | {'error': False, 'dtime': 0.02, 'elapsed_time': 10.429126262664795}\n",
      "   9     |    0     | 0.96, 0.66, -0.04, -0.68             | -0.93    |  False   | {'error': False, 'dtime': 0.073, 'elapsed_time': 10.504684686660767}\n",
      "   10    |    2     | 0.95, -0.15, 0.01, 0.63              | -0.90    |  False   | {'error': False, 'dtime': 0.087, 'elapsed_time': 10.584837675094604}\n",
      "   11    |    0     | -0.98, 0.98, -0.04, -0.74            | -0.98    |  False   | {'error': False, 'dtime': 0.068, 'elapsed_time': 10.657327890396118}\n",
      "   12    |    1     | -0.97, 0.58, -0.04, 0.00             | -0.95    |  False   | {'error': False, 'dtime': 0.02, 'elapsed_time': 10.672405481338501}\n",
      "   13    |    0     | -0.91, 0.91, -0.09, -0.74            | -0.84    |  False   | {'error': False, 'dtime': 0.068, 'elapsed_time': 10.73869013786316}\n",
      "   14    |    0     | -0.87, 0.64, -0.14, -0.74            | -0.76    |  False   | {'error': False, 'dtime': 0.068, 'elapsed_time': 10.809038877487183}\n",
      "   15    |    0     | -0.85, 0.22, -0.19, -0.74            | -0.73    |  False   | {'error': False, 'dtime': 0.068, 'elapsed_time': 10.877455234527588}\n",
      "   16    |    2     | -0.95, -1.20, -0.13, 0.67            | -0.92    |  False   | {'error': False, 'dtime': 0.082, 'elapsed_time': 10.962343215942383}\n",
      "   17    |    2     | 0.93, -1.38, -0.08, 0.63             | -0.88    |  False   | {'error': False, 'dtime': 0.087, 'elapsed_time': 11.044270277023315}\n",
      "   18    |    2     | 0.84, -1.06, -0.02, 0.67             | -0.72    |  False   | {'error': False, 'dtime': 0.082, 'elapsed_time': 11.12597370147705}\n",
      "   19    |    1     | 0.84, -0.33, -0.02, 0.00             | -0.70    |  False   | {'error': False, 'dtime': 0.015, 'elapsed_time': 11.149164199829102}\n",
      "Action mean: 0.95\n",
      "Action std dev: 0.804673846971554\n",
      "Total reward: -17.425235959455208\n"
     ]
    }
   ],
   "source": [
    "# Run some random steps\n",
    "actions = []\n",
    "rewards = []\n",
    "obs, info = env.reset()\n",
    "if info[\"error\"]:\n",
    "    print(\"Stopping\")\n",
    "else:\n",
    "    print(f\"{'Step': ^8} | {'Action': ^8} | {'Observation': ^36} | {'Reward': ^8} | {'Done': ^8} | Info\")\n",
    "    print(f\"{'Reset': ^8} | {0: ^8} | {obs_str: <36} | {0.0: <8} | {str(False): ^8} | {info}\")\n",
    "    for i in range(20):\n",
    "        action = env.action_space.sample()\n",
    "        actions.append(action)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "        rewards.append(reward)\n",
    "        print(f\"{i: ^8} | {action: ^8} | {obs_str: <36} | {reward: <8.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "        if info[\"error\"]:\n",
    "            print(\"Stopping\")\n",
    "            break\n",
    "        if terminated or truncated:\n",
    "            print(\"Episode done\")\n",
    "            break\n",
    "\n",
    "# Print stats\n",
    "action_mean = np.mean(np.array(actions))\n",
    "action_std = np.std(np.array(actions))\n",
    "print(f\"Action mean: {action_mean}\")\n",
    "print(f\"Action std dev: {action_std}\")\n",
    "print(f\"Total reward: {sum(rewards)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3b1cc85-0cc9-496e-93ba-4f670de7c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs: [-0.8833333   0.13091879  0.          0.00940734], info: {'error': False, 'dtime': 2.126, 'elapsed_time': 10.106022596359253}\n",
      "Episode done\n"
     ]
    }
   ],
   "source": [
    "# Test timeout (stepper will reset and vibrate for a while)\n",
    "obs, info = env.reset()\n",
    "print(f\"obs: {obs}, info: {info}\")\n",
    "action = 0\n",
    "if not info[\"error\"]:\n",
    "    for i in range(1000):\n",
    "        action = 0 if action == 2 else 2\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        # print(f\"{i: ^8} | {obs_str: <36} | {reward: <8.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "        if terminated or truncated:\n",
    "            print(\"Episode done\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75c8710f-6a1b-4e54-ab1c-82cbc4d73080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final environment check to make sure it works with Stable-Baselines3 (no errors means it worked)\n",
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f593d48-dacf-424b-ae3c-531b2d5914c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a13f9-7fd8-41b8-a132-7ba226d43345",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74f6d7db-4f12-400a-b61e-b726e8f028a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that tests the model in the given environment\n",
    "def test_agent(env, model, max_steps=0):\n",
    "\n",
    "    # Reset environment\n",
    "    obs, info = env.reset()\n",
    "    ep_len = 0\n",
    "    ep_rew = 0\n",
    "    avg_step_time = 0.0\n",
    "    actions = []\n",
    "\n",
    "    # Run episode until complete\n",
    "    while True:\n",
    "\n",
    "        # Provide observation to policy to predict the next action\n",
    "        timestamp = time.time()\n",
    "        action, _ = model.predict(obs)\n",
    "        action = int(action)\n",
    "        actions.append(action)\n",
    "\n",
    "        # Perform action, update total reward\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        avg_step_time += time.time() - timestamp\n",
    "        ep_rew += reward\n",
    "\n",
    "        # Increase step counter\n",
    "        ep_len += 1\n",
    "        if (max_steps > 0) and (ep_len >= max_steps):\n",
    "            break\n",
    "\n",
    "        # Check to see if episode has ended\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "        \n",
    "    # Calculate average step time\n",
    "    avg_step_time /= ep_len\n",
    "    \n",
    "    # Calculate action stats\n",
    "    action_mean = np.mean(np.array(actions))\n",
    "    action_std = np.std(np.array(actions))\n",
    "    \n",
    "    return ep_len, ep_rew, avg_step_time, action_mean, action_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de81902-9bcc-451d-99fd-7db9febdd73a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing and logging callbacks\n",
    "\n",
    "Construct custom callbacks for Stable-Baselines3 to test our agent and log metrics to Weights & Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f3870bb-7d23-4d12-a171-4f284c3335e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate agent on a number of tests\n",
    "def evaluate_agent(env, model, steps_per_test, num_tests):\n",
    "    \n",
    "    # Initialize metrics\n",
    "    avg_ep_len = 0.0\n",
    "    avg_ep_rew = 0.0\n",
    "    avg_step_time = 0.0\n",
    "    avg_action_mean = 0.0\n",
    "    avg_action_std = 0.0\n",
    "    \n",
    "    # Test the agent a number of times\n",
    "    for ep in range(num_tests):\n",
    "        ep_len, ep_rew, step_time, action_mean, action_std = test_agent(env, model, max_steps=steps_per_test)\n",
    "        avg_ep_len += ep_len\n",
    "        avg_ep_rew += ep_rew\n",
    "        avg_step_time += step_time\n",
    "        avg_action_mean += action_mean\n",
    "        avg_action_std += action_std\n",
    "        \n",
    "    # Compute metrics\n",
    "    avg_ep_len /= num_tests\n",
    "    avg_ep_rew /= num_tests\n",
    "    avg_step_time /= num_tests\n",
    "    avg_action_mean /= num_tests\n",
    "    avg_action_std /= num_tests\n",
    "    \n",
    "    return avg_ep_len, avg_ep_rew, avg_step_time, avg_action_mean, avg_action_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e467390-4f21-48cd-a5e3-2862ddf25cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalAndSaveCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Evaluate and save the model every ``check_freq`` steps\n",
    "    \n",
    "    More info: https://stable-baselines3.readthedocs.io/en/master/guide/callbacks.html\n",
    "    \"\"\"\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(\n",
    "        self, \n",
    "        check_freq, \n",
    "        save_dir,\n",
    "        model_name=\"model\",\n",
    "        replay_buffer_name=None,\n",
    "        steps_per_test=0, \n",
    "        num_tests=10,\n",
    "        step_offset=0,\n",
    "        verbose=1,\n",
    "    ):\n",
    "        super(EvalAndSaveCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_dir = save_dir\n",
    "        self.model_name = model_name\n",
    "        self.replay_buffer_name = replay_buffer_name\n",
    "        self.num_tests = num_tests\n",
    "        self.steps_per_test = steps_per_test\n",
    "        self.step_offset = step_offset\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    # Create directory for saving the models\n",
    "    def _init_callback(self):\n",
    "        if self.save_dir is not None:\n",
    "            os.makedirs(self.save_dir, exist_ok=True)\n",
    "            \n",
    "    # Save and evaluate model at a set interval\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            \n",
    "            # Set actual number of steps (including offset)\n",
    "            actual_steps = self.step_offset + self.n_calls\n",
    "            \n",
    "            # Save model\n",
    "            model_path = os.path.join(self.save_dir, f\"{self.model_name}_{str(actual_steps)}\")\n",
    "            self.model.save(model_path)\n",
    "            \n",
    "            # Save replay buffer\n",
    "            if self.replay_buffer_name != None:\n",
    "                replay_buffer_path = os.path.join(self.save_dir, f\"{self.replay_buffer_name}\")\n",
    "                self.model.save_replay_buffer(replay_buffer_path)\n",
    "            \n",
    "            # Evaluate the agent\n",
    "            avg_ep_len, avg_ep_rew, avg_step_time, avg_action_mean, avg_action_std = evaluate_agent(\n",
    "                env, \n",
    "                self.model, \n",
    "                self.steps_per_test, \n",
    "                self.num_tests\n",
    "            )\n",
    "            if self.verbose:\n",
    "                print(f\"{str(actual_steps)} steps | average test length: {avg_ep_len}, average test reward: {avg_ep_rew}\")\n",
    "                \n",
    "            # Log metrics to WandB\n",
    "            log_dict = {\n",
    "                'avg_ep_len': avg_ep_len,\n",
    "                'avg_ep_rew': avg_ep_rew,\n",
    "                'avg_step_time': avg_step_time,\n",
    "                'avg_action_mean': avg_action_mean,\n",
    "                'avg_action_std': avg_action_std,\n",
    "            }\n",
    "            wandb.log(log_dict, commit=True, step=actual_steps)\n",
    "            \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ef5e1e7-bc63-4288-9a2e-f165b78a17fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandBWriter(KVWriter):\n",
    "    \"\"\"\n",
    "    Log metrics to Weights & Biases when called by .learn()\n",
    "    \n",
    "    More info: https://stable-baselines3.readthedocs.io/en/master/_modules/stable_baselines3/common/logger.html#KVWriter\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize run\n",
    "    def __init__(self, run, verbose=1):\n",
    "        super().__init__()\n",
    "        self.run = run\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # Write metrics to W&B project\n",
    "    def write(self, \n",
    "              key_values: Dict[str, Any], \n",
    "              key_excluded: Dict[str, Union[str, Tuple[str, ...]]], \n",
    "              step: int = 0) -> None:\n",
    "        log_dict = {}\n",
    "        \n",
    "        # Go through each key/value pairs\n",
    "        for (key, value), (_, excluded) in zip(\n",
    "            sorted(key_values.items()), sorted(key_excluded.items())):\n",
    "            \n",
    "            if self.verbose >= 2:\n",
    "                print(f\"step={step} | {key} : {value} ({type(value)})\")\n",
    "            \n",
    "            # Skip excluded items\n",
    "            if excluded is not None and \"wandb\" in excluded:\n",
    "                continue\n",
    "                \n",
    "            # Log integers and floats\n",
    "            if isinstance(value, np.ScalarType):\n",
    "                if not isinstance(value, str):\n",
    "                    wandb.log(data={key: value}, step=step)\n",
    "                    log_dict[key] = value\n",
    "                \n",
    "        # Print to console\n",
    "        if self.verbose >= 1:\n",
    "            print(f\"Log for steps={step}\")\n",
    "            print(f\"--------------\")\n",
    "            for (key, value) in sorted(log_dict.items()):\n",
    "                print(f\"  {key}: {value}\")\n",
    "            print()\n",
    "                \n",
    "    # Close the W&B run\n",
    "    def close(self) -> None:\n",
    "        self.run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdecb53-cf01-41b5-ad9e-224806c4ac7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define train and test function for a single trial\n",
    "\n",
    "A single \"trial\" is fully training and then testing the agent using one set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aebdc5ce-4123-448c-a675-d067932e24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_trial(settings, hparams):\n",
    "    \"\"\"\n",
    "    Training loop used to evaluate a set of hyperparameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set random seed\n",
    "    set_random_seeds(settings['seed'])\n",
    "    \n",
    "    # Create new W&B run\n",
    "    config = {}\n",
    "    dt = datetime.datetime.now(datetime.timezone.utc)\n",
    "    dt = dt.replace(microsecond=0, tzinfo=None)\n",
    "    run = wandb.init(\n",
    "        project=settings['wandb_project'], \n",
    "        name=str(dt), \n",
    "        config=config,\n",
    "        settings=wandb.Settings(silent=(not settings['verbose_wandb']))\n",
    "    )\n",
    "\n",
    "    # Print run info\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(f\"WandB run ID: {run.id}\")\n",
    "        print(f\"WandB run name: {run.name}\")\n",
    "    \n",
    "    # Log hyperparameters to W&B\n",
    "    wandb.config.update(hparams)\n",
    "    \n",
    "    # Set custom logger with our custom writer\n",
    "    wandb_writer = WandBWriter(run, verbose=settings['verbose_log'])\n",
    "    loggers = Logger(\n",
    "        folder=None,\n",
    "        output_formats=[wandb_writer]\n",
    "    )\n",
    "    \n",
    "    # Calculate derived hyperparameters\n",
    "    n_steps = 2 ** hparams['steps_per_update_pow2']\n",
    "    minibatch_size = (hparams['n_envs'] * n_steps) // (2 ** hparams['batch_size_div_pow2'])\n",
    "    layer_1 = 2 ** hparams['layer_1_pow2']\n",
    "    layer_2 = 2 ** hparams['layer_2_pow2']\n",
    "\n",
    "    # Create new agent\n",
    "    # PPO docs: https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html\n",
    "    # Policy networks: https://stable-baselines.readthedocs.io/en/master/modules/policies.html\n",
    "    model = sb3.PPO(\n",
    "        'MlpPolicy',\n",
    "        env,\n",
    "        learning_rate=hparams['learning_rate'], # Learning rate of neural network (default: 0.0003)\n",
    "        n_steps=n_steps,                        # Number of steps per update (default: 2048)\n",
    "        batch_size=minibatch_size,              # Minibatch size for NN update (default: 64)\n",
    "        gamma=hparams['gamma'],                 # Discount factor (default: 0.99)\n",
    "        gae_lambda=hparams['gae_lambda'],       # Trade-off of bias vs. variance for GAE (default: 0.95)\n",
    "        clip_range=hparams['clip_range'],       # Clipping parameter (default: 0.2)\n",
    "        ent_coef=hparams['entropy_coef'],       # Entropy, how much to explore (default: 0.0)\n",
    "        vf_coef=hparams['vf_coef'],             # Value function coefficient for the loss calculation (default: 0.5)\n",
    "        max_grad_norm=hparams['max_grad_norm'], # Max value for gradient clipping (default: 0.5)\n",
    "        use_sde=hparams['use_sde'],             # Use generalized State Dependent Exploration (default: False)\n",
    "        sde_sample_freq=hparams['sde_freq'],    # Number of steps before sampling new noise matrix (default -1)\n",
    "        policy_kwargs={\n",
    "            'activation_fn': th.nn.ReLU,        # (default: th.nn.Tanh)\n",
    "            'net_arch': [layer_1, layer_2]      # (default: [64, 64])\n",
    "        }, \n",
    "        verbose=settings['verbose_train']       # Print training metrics (default: 0)\n",
    "    )\n",
    "    steps_to_complete = settings['total_steps']\n",
    "        \n",
    "    # Set up checkpoint callback\n",
    "    checkpoint_callback = EvalAndSaveCallback(\n",
    "        check_freq=settings['checkpoint_freq'], \n",
    "        save_dir=settings['save_dir'],\n",
    "        model_name=settings['model_name'],\n",
    "        replay_buffer_name=settings['replay_buffer_name'],\n",
    "        steps_per_test=settings['steps_per_test'],\n",
    "        num_tests=settings['tests_per_check'],\n",
    "        step_offset=(settings['total_steps'] - steps_to_complete),\n",
    "        verbose=settings['verbose_test'],\n",
    "    )\n",
    "    \n",
    "    # Choo choo train\n",
    "    model.learn(total_timesteps=steps_to_complete, \n",
    "                callback=[checkpoint_callback])\n",
    "    \n",
    "    # Get dataframe of run metrics\n",
    "    history = wandb.Api().run(f\"{run.project}/{run.id}\").history()\n",
    "\n",
    "    # Get index of evaluation with maximum reward\n",
    "    max_idx = np.argmax(history.loc[:, 'avg_ep_rew'].values)\n",
    "\n",
    "    # Find number of steps required to produce that maximum reward\n",
    "    max_rew_steps = history['_step'][max_idx]\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(f\"Steps with max reward: {max_rew_steps}\")\n",
    "    \n",
    "    # Load model with maximum reward from previous run\n",
    "    model_path = os.path.join(settings['save_dir'], f\"{settings['model_name']}_{str(max_rew_steps)}.zip\")\n",
    "    model = sb3.PPO.load(model_path, env)\n",
    "    \n",
    "    # Evaluate the agent\n",
    "    avg_ep_len, avg_ep_rew, avg_step_time, avg_action_mean, avg_action_std = evaluate_agent(\n",
    "        env, \n",
    "        model, \n",
    "        settings['steps_per_test'],\n",
    "        settings['tests_per_check'],\n",
    "    )\n",
    "    \n",
    "    # Log final evaluation metrics to WandB run\n",
    "    wandb.run.summary['Average test episode length'] = avg_ep_len\n",
    "    wandb.run.summary['Average test episode reward'] = avg_ep_rew\n",
    "    wandb.run.summary['Average test step time'] = avg_step_time\n",
    "    \n",
    "    # Print final run metrics\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(\"---\")\n",
    "        print(f\"Best model: {settings['model_name']}_{str(max_rew_steps)}.zip\")\n",
    "        print(f\"Average episode length: {avg_ep_len}\")\n",
    "        print(f\"Average episode reward: {avg_ep_rew}\")\n",
    "        print(f\"Average step time: {avg_step_time}\")\n",
    "        print(f\"Average action mean: {avg_action_mean}\")\n",
    "        print(f\"Average action std dev: {avg_action_std}\")\n",
    "                      \n",
    "    # Close W&B run\n",
    "    run.finish()\n",
    "    \n",
    "    return avg_ep_rew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a7822-6c9e-4fff-a03f-0304d787702d",
   "metadata": {},
   "source": [
    "## Perform trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "288b5de3-822d-4395-b1e8-2537680b0336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project settings that do not change\n",
    "settings = {\n",
    "    'wandb_project': \"pendulum-esp32-hpo-5\",\n",
    "    'model_name': \"ppo-pendulum\",\n",
    "    'ax_experiment_name': \"ppo-pendulum-esp32-5\",\n",
    "    'ax_objective_name': \"avg_ep_rew\",\n",
    "    'replay_buffer_name': None,\n",
    "    'save_dir': \"checkpoints\",\n",
    "    'checkpoint_freq': 5_000,\n",
    "    'steps_per_test': 500,\n",
    "    'tests_per_check': 10,\n",
    "    'total_steps': 50_000,\n",
    "    'num_trials': 100,\n",
    "    'seed': 42,\n",
    "    'verbose_ax': False,\n",
    "    'verbose_wandb': False,\n",
    "    'verbose_train': 0,\n",
    "    'verbose_log': 0,\n",
    "    'verbose_test': 0,\n",
    "    'verbose_trial': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed4bcd36-4d5a-489a-8a4c-86403a6a1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters we want to optimize\n",
    "# Ref: https://github.com/facebook/Ax/blob/6443cee30cbf8cec290200a7420a3db08e4b5445/ax/service/ax_client.py#L236\n",
    "# Example: https://github.com/facebook/Ax/blob/main/tutorials/tune_cnn_service.ipynb\n",
    "# Hyperparameters: https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#stable_baselines3.ppo.PPO\n",
    "hparams = [\n",
    "    {\n",
    "        'name': \"n_envs\",\n",
    "        'type': \"fixed\",\n",
    "        'value_type': \"int\",\n",
    "        'value': 1,\n",
    "    },\n",
    "    {\n",
    "        'name': \"learning_rate\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [1e-5, 1e-3],\n",
    "        'log_scale': True,\n",
    "    },\n",
    "    {\n",
    "        'name': \"steps_per_update_pow2\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"int\",\n",
    "        'bounds': [8, 11], # Inclusive, 2**n between [256, 2048]\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"batch_size_div_pow2\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"int\",\n",
    "        'bounds': [0, 3], # Inclusive, 2**n between [512, 4096]\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"gae_lambda\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.9, 0.99],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"clip_range\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.1, 0.4],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"gamma\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.92, 0.99],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"entropy_coef\",\n",
    "        'value_type': \"float\",\n",
    "        'type': \"range\",\n",
    "        'bounds': [0.0, 0.01],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"vf_coef\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.2, 0.7],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"max_grad_norm\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.5, 5.0],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"use_sde\",\n",
    "        'type': \"fixed\",\n",
    "        'value_type': \"bool\",\n",
    "        'value': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"sde_freq\",\n",
    "        'type': \"fixed\",\n",
    "        'value_type': \"int\",\n",
    "        'value': -1,\n",
    "    },\n",
    "    {\n",
    "        'name': \"layer_1_pow2\",\n",
    "        'type': \"fixed\",\n",
    "        'value_type': \"int\",\n",
    "        'value': 8, # 2**n (is 256)\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"layer_2_pow2\",\n",
    "        'type': \"fixed\",\n",
    "        'value_type': \"int\",\n",
    "        'value': 8, # 2**n (is 256)\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Set parameter constraints\n",
    "# Example: https://github.com/facebook/Ax/issues/621\n",
    "parameter_constraints = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af5b3fb4-2186-425e-8079-a54735dde9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing message. Message received: Observation: 0.90, -0.36, 0.21, 0.00, dtime: 0.709\n",
      "\n",
      "Error parsing message. Message received: Observation: 0.91, 1.46, 0.21, 0.00, dtime: 0.008\n",
      "\n",
      "Error parsing message. Message received: Observation: 0.99, 1.04, 0.27, 0.73, dtime: 0.075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create our environment\n",
    "try:\n",
    "    env.close()\n",
    "except:\n",
    "    pass\n",
    "env = Pendulum(\n",
    "        SERIAL_PORT,\n",
    "        BAUD_RATE,\n",
    "        ctrl_timeout=CTRL_TIMEOUT,\n",
    "        debug_level=DEBUG_LEVEL,\n",
    "        env_timeout=ENV_TIMEOUT, \n",
    "        stp_mode=STEP_MODE, \n",
    "        stp_blocking=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "362c011c-85ab-4460-a5cd-a2a687feb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosntruct path to Ax experiment snapshot file\n",
    "ax_snapshot_path = os.path.join(settings['save_dir'], f\"{settings['ax_experiment_name']}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8a7eb35-aa2f-47ff-bdbf-de1658632e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DANGER! Uncomment to delete the experiment file to start over\n",
    "\n",
    "# os.remove(ax_snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70621040-a54e-4e8b-ba5b-89f30be1730f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 10-07 23:45:49] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading experiment from snapshot: checkpoints\\ppo-pendulum-esp32-5.json\n"
     ]
    }
   ],
   "source": [
    "# Load experiment from snapshot if it exists, otherwise create a new one\n",
    "# Ref: https://ax.dev/versions/0.2.10/api/service.html#ax.service.ax_client.AxClient.create_experiment\n",
    "if os.path.exists(ax_snapshot_path):\n",
    "    print(f\"Loading experiment from snapshot: {ax_snapshot_path}\")\n",
    "    ax_client = AxClient.load_from_json_file(ax_snapshot_path)\n",
    "else:\n",
    "    print(f\"Creating new experiment. Snapshot to be saved at {ax_snapshot_path}.\")\n",
    "    ax_client = AxClient(\n",
    "        random_seed=settings['seed'],\n",
    "        verbose_logging=settings['verbose_ax'],\n",
    "    )\n",
    "    ax_client.create_experiment(\n",
    "        name=settings['ax_experiment_name'],\n",
    "        parameters=hparams,\n",
    "        objective_name=settings['ax_objective_name'],\n",
    "        minimize=False,\n",
    "        parameter_constraints=parameter_constraints,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e98af995-9535-44d0-b269-16d341f7b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DANGER! Use this cell to mark trials as failed (e.g. if component breaks and WandB shows bad data for a given trial)\n",
    "# Check .json file with a site like https://jsonformatter.org/json-pretty-print\n",
    "\n",
    "# trial_index = 5\n",
    "# trial = ax_client.experiment.trials[trial_index]\n",
    "# trial.mark_failed(unsafe=True)\n",
    "# print(trial)\n",
    "# ax_client.save_to_json_file(ax_snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4a184b8-3f2b-48cf-9e07-c8f97dd23ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 10-07 23:46:13] ax.service.ax_client: Generated new trial 1 with parameters {'learning_rate': 6.5e-05, 'steps_per_update_pow2': 10, 'batch_size_div_pow2': 1, 'gae_lambda': 0.964348, 'clip_range': 0.223857, 'gamma': 0.960777, 'entropy_coef': 0.007052, 'vf_coef': 0.215646, 'max_grad_norm': 3.956313, 'n_envs': 1, 'use_sde': False, 'sde_freq': -1, 'layer_1_pow2': 8, 'layer_2_pow2': 8}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial 1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run ID: ybnog1su\n",
      "WandB run name: 2023-10-08 05:46:13\n",
      "Steps with max reward: 30000\n",
      "---\n",
      "Best model: ppo-pendulum_30000.zip\n",
      "Average episode length: 310.7\n",
      "Average episode reward: -230.7636959360869\n",
      "Average step time: 0.06225318977041803\n",
      "Average action mean: 0.9614089186781973\n",
      "Average action std dev: 0.8115665986086205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 10-08 02:05:17] ax.service.ax_client: Completed trial 1 with data: {'avg_ep_rew': (-230.763696, None)}.\n",
      "[INFO 10-08 02:05:17] ax.service.ax_client: Saved JSON-serialized state of optimization to `checkpoints\\ppo-pendulum-esp32-5.json`.\n",
      "[INFO 10-08 02:05:17] ax.service.ax_client: Generated new trial 2 with parameters {'learning_rate': 2.4e-05, 'steps_per_update_pow2': 9, 'batch_size_div_pow2': 2, 'gae_lambda': 0.906158, 'clip_range': 0.168439, 'gamma': 0.976861, 'entropy_coef': 0.001267, 'vf_coef': 0.43887, 'max_grad_norm': 3.731091, 'n_envs': 1, 'use_sde': False, 'sde_freq': -1, 'layer_1_pow2': 8, 'layer_2_pow2': 8}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial 2 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run ID: 8e5q1hzw\n",
      "WandB run name: 2023-10-08 08:05:17\n",
      "Steps with max reward: 50000\n",
      "---\n",
      "Best model: ppo-pendulum_50000.zip\n",
      "Average episode length: 323.6\n",
      "Average episode reward: -303.80948916444106\n",
      "Average step time: 0.058976005315618585\n",
      "Average action mean: 0.9826148590820922\n",
      "Average action std dev: 0.7805947377105328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 10-08 04:25:27] ax.service.ax_client: Completed trial 2 with data: {'avg_ep_rew': (-303.809489, None)}.\n",
      "[INFO 10-08 04:25:27] ax.service.ax_client: Saved JSON-serialized state of optimization to `checkpoints\\ppo-pendulum-esp32-5.json`.\n",
      "[INFO 10-08 04:25:27] ax.service.ax_client: Generated new trial 3 with parameters {'learning_rate': 0.000276, 'steps_per_update_pow2': 11, 'batch_size_div_pow2': 0, 'gae_lambda': 0.972363, 'clip_range': 0.349125, 'gamma': 0.943164, 'entropy_coef': 0.008766, 'vf_coef': 0.601399, 'max_grad_norm': 1.834309, 'n_envs': 1, 'use_sde': False, 'sde_freq': -1, 'layer_1_pow2': 8, 'layer_2_pow2': 8}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial 3 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a10fab043a84c1c95ed5c8aa9563126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run ID: x4ls8r5t\n",
      "WandB run name: 2023-10-08 10:25:27\n",
      "Steps with max reward: 20000\n",
      "---\n",
      "Best model: ppo-pendulum_20000.zip\n",
      "Average episode length: 222.5\n",
      "Average episode reward: -474.5755365269048\n",
      "Average step time: 0.06511511215441525\n",
      "Average action mean: 0.9968893671504565\n",
      "Average action std dev: 0.8251102325083902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 10-08 06:48:14] ax.service.ax_client: Completed trial 3 with data: {'avg_ep_rew': (-474.575537, None)}.\n",
      "[INFO 10-08 06:48:14] ax.service.ax_client: Saved JSON-serialized state of optimization to `checkpoints\\ppo-pendulum-esp32-5.json`.\n",
      "[INFO 10-08 06:48:14] ax.service.ax_client: Generated new trial 4 with parameters {'learning_rate': 0.00015, 'steps_per_update_pow2': 9, 'batch_size_div_pow2': 1, 'gae_lambda': 0.988324, 'clip_range': 0.391125, 'gamma': 0.93386, 'entropy_coef': 0.000134, 'vf_coef': 0.371305, 'max_grad_norm': 3.286363, 'n_envs': 1, 'use_sde': False, 'sde_freq': -1, 'layer_1_pow2': 8, 'layer_2_pow2': 8}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial 4 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fcb5b491624f7abe0e30e08279fd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666656966, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run ID: td11jkfg\n",
      "WandB run name: 2023-10-08 12:48:14\n",
      "Steps with max reward: 35000\n",
      "---\n",
      "Best model: ppo-pendulum_35000.zip\n",
      "Average episode length: 136.4\n",
      "Average episode reward: -141.79422704900588\n",
      "Average step time: 0.05034694238028429\n",
      "Average action mean: 1.0086364124560443\n",
      "Average action std dev: 0.7198438113578044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 10-08 09:07:45] ax.service.ax_client: Completed trial 4 with data: {'avg_ep_rew': (-141.794227, None)}.\n",
      "[INFO 10-08 09:07:45] ax.service.ax_client: Saved JSON-serialized state of optimization to `checkpoints\\ppo-pendulum-esp32-5.json`.\n",
      "[INFO 10-08 09:07:45] ax.service.ax_client: Generated new trial 5 with parameters {'learning_rate': 1e-05, 'steps_per_update_pow2': 11, 'batch_size_div_pow2': 3, 'gae_lambda': 0.913861, 'clip_range': 0.126504, 'gamma': 0.966461, 'entropy_coef': 0.007634, 'vf_coef': 0.638448, 'max_grad_norm': 2.235512, 'n_envs': 1, 'use_sde': False, 'sde_freq': -1, 'layer_1_pow2': 8, 'layer_2_pow2': 8}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial 5 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run ID: 40oyst7s\n",
      "WandB run name: 2023-10-08 15:07:45\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Perform trial\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m avg_ep_rew \u001b[38;5;241m=\u001b[39m \u001b[43mdo_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_hparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m ax_client\u001b[38;5;241m.\u001b[39mcomplete_trial(\n\u001b[0;32m     16\u001b[0m     trial_index\u001b[38;5;241m=\u001b[39mtrial_index,\n\u001b[0;32m     17\u001b[0m     raw_data\u001b[38;5;241m=\u001b[39mavg_ep_rew,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Save experiment snapshot\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[31], line 79\u001b[0m, in \u001b[0;36mdo_trial\u001b[1;34m(settings, hparams)\u001b[0m\n\u001b[0;32m     67\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m EvalAndSaveCallback(\n\u001b[0;32m     68\u001b[0m     check_freq\u001b[38;5;241m=\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_freq\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     69\u001b[0m     save_dir\u001b[38;5;241m=\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_dir\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m     verbose\u001b[38;5;241m=\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose_test\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     76\u001b[0m )\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Choo choo train\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_to_complete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Get dataframe of run metrics\u001b[39;00m\n\u001b[0;32m     83\u001b[0m history \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mApi()\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39mproject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mhistory()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:259\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 259\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:178\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mBox):\n\u001b[0;32m    176\u001b[0m     clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[1;32m--> 178\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:197\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "Cell \u001b[1;32mIn[18], line 89\u001b[0m, in \u001b[0;36mPendulum.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     86\u001b[0m truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Move the stepper motor and wait for a response\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCMD_MOVE_BY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mSTP_ACTIONS_MAP\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Figure out reward and episode termination based on observation\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp:\n\u001b[0;32m     93\u001b[0m     \n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# Extract information from controller response\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Projects\\GitHub\\pendulum-rl\\control_comms.py:249\u001b[0m, in \u001b[0;36mControlComms.step\u001b[1;34m(self, command, action)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# Wait for a response\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 249\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_until\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug_level \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m DebugLevel\u001b[38;5;241m.\u001b[39mDEBUG_ERROR:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\serial\\serialutil.py:663\u001b[0m, in \u001b[0;36mSerialBase.read_until\u001b[1;34m(self, expected, size)\u001b[0m\n\u001b[0;32m    661\u001b[0m timeout \u001b[38;5;241m=\u001b[39m Timeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout)\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 663\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c:\n\u001b[0;32m    665\u001b[0m         line \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m c\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\serial\\serialwin32.py:288\u001b[0m, in \u001b[0;36mSerial.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m read_ok \u001b[38;5;129;01mand\u001b[39;00m win32\u001b[38;5;241m.\u001b[39mGetLastError() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (win32\u001b[38;5;241m.\u001b[39mERROR_SUCCESS, win32\u001b[38;5;241m.\u001b[39mERROR_IO_PENDING):\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SerialException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadFile failed (\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ctypes\u001b[38;5;241m.\u001b[39mWinError()))\n\u001b[1;32m--> 288\u001b[0m result_ok \u001b[38;5;241m=\u001b[39m \u001b[43mwin32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetOverlappedResult\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_port_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_overlapped_read\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result_ok:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m win32\u001b[38;5;241m.\u001b[39mGetLastError() \u001b[38;5;241m!=\u001b[39m win32\u001b[38;5;241m.\u001b[39mERROR_OPERATION_ABORTED:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Choo choo! Perform trials to optimize hyperparameters\n",
    "while True:\n",
    "    \n",
    "    # Get next hyperparameters and end experiment if we've reached max trials\n",
    "    next_hparams, trial_index = ax_client.get_next_trial()\n",
    "    if trial_index >= settings['num_trials']:\n",
    "        break\n",
    "        \n",
    "    # Show that we're starting a new trial\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(f\"--- Trial {trial_index} ---\")\n",
    "        \n",
    "    # Perform trial\n",
    "    avg_ep_rew = do_trial(settings, next_hparams)\n",
    "    ax_client.complete_trial(\n",
    "        trial_index=trial_index,\n",
    "        raw_data=avg_ep_rew,\n",
    "    )\n",
    "    \n",
    "    # Save experiment snapshot\n",
    "    ax_client.save_to_json_file(ax_snapshot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1dc72-fc2e-4b2f-8f55-7c83978d67d9",
   "metadata": {},
   "source": [
    "## Analyze Top Performing Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a823a-2a29-4da1-9f07-8e8fdb99c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get runs in WandB project\n",
    "runs = wandb.Api().runs(settings['wandb_project'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b848830-72fe-42aa-b860-0542ce4164f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot best average episode reward from each run over time\n",
    "avg_rews = []\n",
    "for i, run in enumerate(runs):\n",
    "    avg_rew = run.summary['Average test episode reward']\n",
    "    if isinstance(avg_rew, float):\n",
    "        avg_rews.append(avg_rew)\n",
    "avg_rews.reverse()\n",
    "plt.plot(avg_rews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859de2a9-09c9-4d5f-b22a-53598098d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file path\n",
    "csv_file_path = os.path.join(\".\", settings['wandb_project'] + \".csv\")\n",
    "\n",
    "# List summary names\n",
    "summary_names = [\n",
    "    \"Average test episode reward\",\n",
    "    \"Average test episode length\",\n",
    "    \"Average test step time\",\n",
    "]\n",
    "\n",
    "# Get hyperparameter names\n",
    "hparam_names = [hparam['name'] for hparam in hparams]\n",
    "\n",
    "print()\n",
    "\n",
    "# Create CSV with HPO trial results\n",
    "with open(csv_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"name\"] + summary_names + hparam_names)\n",
    "    for run in runs:\n",
    "        row = [run.name]\n",
    "        for name in summary_names:\n",
    "            row.append(run.summary[name])\n",
    "        for name in hparam_names:\n",
    "            row.append(run.config[name])\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec2e501-fa2d-4c78-9912-d02fc950f338",
   "metadata": {},
   "source": [
    "## Train Model on Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb236c6-b6c5-4067-8752-637721654561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37fcd98-00c8-4db6-9197-7a5bc772701b",
   "metadata": {},
   "source": [
    "## Covnert Model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37be8581-8129-4b2a-bbe3-30012eba1176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "max_rew_steps = 40000   # Number of steps with best average reward (for model loading file)\n",
    "max_steps = 500\n",
    "num_tests = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "622fb7f7-34d4-4460-9047-396902f446b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnnxablePolicy(th.nn.Module):\n",
    "  \"\"\"\n",
    "  Convert SB3 model to ONNX model using PyTorch.\n",
    "  From: https://stable-baselines3.readthedocs.io/en/master/guide/export.html\n",
    "  \"\"\"\n",
    "  def __init__(self, extractor, action_net, value_net):\n",
    "    super().__init__()\n",
    "    self.extractor = extractor\n",
    "    self.action_net = action_net\n",
    "    self.value_net = value_net\n",
    "\n",
    "  def forward(self, observation):\n",
    "    # NOTE: You may have to process (normalize) observation in the correct\n",
    "    #       way before using this. See `common.preprocessing.preprocess_obs`\n",
    "    action_hidden, value_hidden = self.extractor(observation)\n",
    "    return self.action_net(action_hidden), self.value_net(value_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b465bd30-3955-45da-8c69-5ea00e1d2ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "model_path = os.path.join(settings['save_dir'], f\"{settings['model_name']}_{str(max_rew_steps)}.zip\")\n",
    "model = sb3.PPO.load(model_path, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8af94d5f-4655-4c93-b72c-4ac44a30d5d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pendulum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mPendulum\u001b[49m(\n\u001b[0;32m      7\u001b[0m         SERIAL_PORT,\n\u001b[0;32m      8\u001b[0m         BAUD_RATE,\n\u001b[0;32m      9\u001b[0m         ctrl_timeout\u001b[38;5;241m=\u001b[39mCTRL_TIMEOUT,\n\u001b[0;32m     10\u001b[0m         debug_level\u001b[38;5;241m=\u001b[39mDEBUG_LEVEL,\n\u001b[0;32m     11\u001b[0m         env_timeout\u001b[38;5;241m=\u001b[39mENV_TIMEOUT, \n\u001b[0;32m     12\u001b[0m         stp_mode\u001b[38;5;241m=\u001b[39mSTEP_MODE, \n\u001b[0;32m     13\u001b[0m         stp_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Store all observations for creating a representative sample set\u001b[39;00m\n\u001b[0;32m     17\u001b[0m obss \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pendulum' is not defined"
     ]
    }
   ],
   "source": [
    "# Create our environment\n",
    "try:\n",
    "    env.close()\n",
    "except:\n",
    "    pass\n",
    "env = Pendulum(\n",
    "        SERIAL_PORT,\n",
    "        BAUD_RATE,\n",
    "        ctrl_timeout=CTRL_TIMEOUT,\n",
    "        debug_level=DEBUG_LEVEL,\n",
    "        env_timeout=ENV_TIMEOUT, \n",
    "        stp_mode=STEP_MODE, \n",
    "        stp_blocking=True\n",
    ")\n",
    "\n",
    "# Store all observations for creating a representative sample set\n",
    "obss = []\n",
    "\n",
    "# Initialize metrics\n",
    "avg_ep_len = 0.0\n",
    "avg_ep_rew = 0.0\n",
    "avg_step_time = 0.0\n",
    "avg_action_mean = 0.0\n",
    "avg_action_std = 0.0\n",
    "\n",
    "# Test the agent a number of times\n",
    "for ep in range(num_tests):\n",
    "    \n",
    "    # Reset environment\n",
    "    obs, info = env.reset()\n",
    "    ep_len = 0\n",
    "    ep_rew = 0\n",
    "    avg_step_time = 0.0\n",
    "    actions = []\n",
    "\n",
    "    # Run episode until complete\n",
    "    while True:\n",
    "\n",
    "        # Provide observation to policy to predict the next action\n",
    "        timestamp = time.time()\n",
    "        action, _ = model.predict(obs)\n",
    "        action = int(action)\n",
    "        actions.append(action)\n",
    "\n",
    "        # Perform action, update total reward\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        avg_step_time += time.time() - timestamp\n",
    "        ep_rew += reward\n",
    "        obss.append(obs)\n",
    "\n",
    "        # Increase step counter\n",
    "        ep_len += 1\n",
    "        if (max_steps > 0) and (ep_len >= max_steps):\n",
    "            break\n",
    "\n",
    "        # Check to see if episode has ended\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "        \n",
    "    # Calculate average step time\n",
    "    avg_step_time /= ep_len\n",
    "    \n",
    "    # Calculate action stats\n",
    "    action_mean = np.mean(np.array(actions))\n",
    "    action_std = np.std(np.array(actions))\n",
    "    \n",
    "    # Acculumate metrics\n",
    "    avg_ep_len += ep_len\n",
    "    avg_ep_rew += ep_rew\n",
    "    avg_step_time += avg_step_time\n",
    "    avg_action_mean += action_mean\n",
    "    avg_action_std += action_std\n",
    "\n",
    "# Compute metrics\n",
    "avg_ep_len /= num_tests\n",
    "avg_ep_rew /= num_tests\n",
    "avg_step_time /= num_tests\n",
    "avg_action_mean /= num_tests\n",
    "avg_action_std /= num_tests\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Avg ep len: {avg_ep_len}\")\n",
    "print(f\"Avg ep rew: {avg_ep_rew}\")\n",
    "print(f\"Avg step time: {avg_step_time}\")\n",
    "print(f\"Avg action mean: {avg_action_mean}\")\n",
    "print(f\"Avg action std: {avg_action_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da0e028e-4c9e-4eb3-8858-cf3859252f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close environment and save observations as our representative sample set\n",
    "env.close()\n",
    "np.save(REP_SAMPLE_SET_PATH, np.array(obss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cb03c97-947a-4700-a134-3cfd829e05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert model to an intermediate form\n",
    "onnxable_model = OnnxablePolicy(\n",
    "    model.policy.mlp_extractor, model.policy.action_net, model.policy.value_net\n",
    ")\n",
    "\n",
    "# Set input shape and save to ONNX file\n",
    "observation_size = model.observation_space.shape\n",
    "dummy_input = th.randn(1, *observation_size).to('cpu')\n",
    "th.onnx.export(\n",
    "    onnxable_model.to('cpu'),\n",
    "    dummy_input,\n",
    "    OUT_ONNX_PATH,\n",
    "    opset_version=9,\n",
    "    input_names=[\"input\"],\n",
    ")\n",
    "\n",
    "# Load ONNX file\n",
    "onnx_model = onnx.load(OUT_ONNX_PATH)\n",
    "onnx.checker.check_model(OUT_ONNX_PATH)\n",
    "\n",
    "# Create a new architecture without the value network\n",
    "value_net_out = None\n",
    "new_nodes = []\n",
    "for node in onnx_model.graph.node:\n",
    "\n",
    "  # Find the value network output name\n",
    "  if \"value_net\" in node.name:\n",
    "    try:\n",
    "      int(node.output[0])\n",
    "      value_net_out = node.output[0]\n",
    "    except ValueError:\n",
    "      pass\n",
    "\n",
    "  # Construct new graph with non-value network nodes\n",
    "  else:\n",
    "    new_nodes.append(node)\n",
    "\n",
    "# Remove the output associated with the value network\n",
    "graph_output = []\n",
    "for output in onnx_model.graph.output:\n",
    "  if output.name != value_net_out:\n",
    "    graph_output.append(output)\n",
    "\n",
    "# Make sure we found the output node\n",
    "assert value_net_out is not None\n",
    "\n",
    "# Construct a new graph\n",
    "new_graph = onnx.helper.make_graph(\n",
    "    new_nodes,\n",
    "    onnx_model.graph.name,\n",
    "    onnx_model.graph.input,\n",
    "    graph_output,\n",
    "    onnx_model.graph.initializer\n",
    ")\n",
    "\n",
    "# Set the new graph as the model's graph\n",
    "onnx_model.graph.CopyFrom(new_graph)\n",
    "\n",
    "# Save the modified model\n",
    "# onnx.save(onnx_model, OUT_ONNX_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a17069c-17e4-40e3-a13a-c6e23876e11b",
   "metadata": {},
   "source": [
    "## Test the ONNX Model in the Environment\n",
    "\n",
    "You will need to turn this into C++ code to run on the target device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e106ab64-428f-4870-9f95-8892e2cb4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_obs(angles, angles_prev, dtime):\n",
    "    \n",
    "    # Offset encoder angle so that 0 deg is up\n",
    "    angles[0] -= ENC_OFFSET\n",
    "\n",
    "    # Calculate velocities\n",
    "    dtheta = calc_angular_velocity(angles[0], angles_prev[0], dtime)\n",
    "    dphi = calc_angular_velocity(angles[1], angles_prev[1], dtime)\n",
    "\n",
    "    # Construct observation (normalized)\n",
    "    obs[0] = angles[0] / ENC_ANGLE_NORM\n",
    "    obs[1] = dtheta / ENC_ANGLE_NORM\n",
    "    obs[2] = angles[1] / STP_ANGLE_NORM\n",
    "    obs[3] = dphi / STP_ANGLE_NORM\n",
    "    \n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4e256ebd-8d0c-408c-8845-114c9a09fb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Average dtime: 0.08837241379310345\n"
     ]
    }
   ],
   "source": [
    "# Close connection to Arduino board (if open)\n",
    "try:\n",
    "    controller.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Connect to Arduino board\n",
    "controller = ControlComms(timeout=CTRL_TIMEOUT, debug_level=DEBUG_LEVEL)\n",
    "ret = controller.connect(SERIAL_PORT, BAUD_RATE)\n",
    "if ret is not StatusCode.OK:\n",
    "    print(\"ERROR: Could not connect to board\")\n",
    "\n",
    "# Load ONNX model\n",
    "ort_sess = ort.InferenceSession(OUT_ONNX_PATH, providers=['CPUExecutionProvider'])\n",
    "\n",
    "# Move controller home\n",
    "angles_prev = [0, 0]\n",
    "timestamp_prev = 0\n",
    "resp = controller.step(CMD_MOVE_HOME, [0.0])\n",
    "if resp:\n",
    "    \n",
    "    # Extract information from controller response\n",
    "    status, timestamp, terminated, angles = resp\n",
    "    \n",
    "    # Compute lapsed time (in seconds) from previous observation (milliseconds)\n",
    "    dtime = (timestamp - timestamp_prev) / 1000.0\n",
    "    timestamp_prev = timestamp\n",
    "    \n",
    "    # Calculate the normalized observation\n",
    "    obs = calc_obs(angles, angles_prev, dtime)\n",
    "    angles_prev[0] = angles[0]\n",
    "    angles_prev[1] = angles[1]\n",
    "    \n",
    "    # Let pendulum settle for a bit\n",
    "    time.sleep(RESET_SETTLE_TIME)\n",
    "    \n",
    "# Something is wrong with communication\n",
    "else:\n",
    "    print(\"ERROR: Could not communicate with Arduino\")\n",
    "\n",
    "# Run episode until complete\n",
    "ep_running = True\n",
    "dtimes = []\n",
    "start_time = time.time()\n",
    "while ep_running:\n",
    "\n",
    "    # Provide observation to policy to predict the next action\n",
    "    action_logits = ort_sess.run(None, {\"input\": np.expand_dims(obs, axis=0)})\n",
    "    action = np.argmax(action_logits)\n",
    "    \n",
    "    # Convert action index to label (degrees to move stepper)\n",
    "    action = STP_ACTIONS_MAP[np.argmax(action_logits)]\n",
    "    \n",
    "    # Move the stepper motor and wait for a response\n",
    "    resp = controller.step(CMD_MOVE_BY, [action])\n",
    "    if resp:\n",
    "        \n",
    "        # Extract information from controller response\n",
    "        status, timestamp, terminated, angles = resp\n",
    "        \n",
    "        # Compute lapsed time (in seconds) from previous observation (milliseconds)\n",
    "        dtime = (timestamp - timestamp_prev) / 1000.0\n",
    "        timestamp_prev = timestamp\n",
    "        dtimes.append(dtime)\n",
    "        \n",
    "        # Calculate the normalized observation\n",
    "        obs = calc_obs(angles, angles_prev, dtime)\n",
    "        angles_prev[0] = angles[0]\n",
    "        angles_prev[1] = angles[1]\n",
    "        \n",
    "        # Make sure stepper is in bounds\n",
    "        if (angles[1] >= STP_ANGLE_MIN) and (angles[1] <= STP_ANGLE_MAX):\n",
    "            \n",
    "            # Fail. We \"crashed\" by swinging too hard\n",
    "            if (abs(angles[0]) <= ENC_CRASH_ANGLE) and (abs(obs[1] * ENC_ANGLE_NORM) > ENC_CRASH_VELOCITY):\n",
    "                print(\"Crashed\")\n",
    "                ep_running = False\n",
    "                \n",
    "            # Success! We landed softly at the top\n",
    "            elif (abs(angles[0]) <= ENC_GOAL_ANGLE) and (abs(obs[1] * ENC_ANGLE_NORM) <= ENC_GOAL_VELOCITY):\n",
    "                print(\"Success!\")\n",
    "                ep_running = False\n",
    "                \n",
    "        # Stepper moved out of bounds\n",
    "        else:\n",
    "            print(\"Stepper out of bounds\")\n",
    "            ep_running = False\n",
    "        \n",
    "    # Comms to Arduino lost\n",
    "    else:\n",
    "        print(\"ERROR: Could not communicate with Arduino\")\n",
    "        ep_running = False\n",
    "        \n",
    "    # Check timeout\n",
    "    if time.time() - start_time > ENV_TIMEOUT:\n",
    "        print(\"Episode timed out\")\n",
    "        ep_running = False\n",
    "        \n",
    "# Print average times\n",
    "print(f\"Average dtime: {sum(dtimes) / len(dtimes)}\")\n",
    "\n",
    "# Close comms\n",
    "controller.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0caf57-7ae4-45ac-82ba-3f1ae682a811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
