{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4561acc1-bea2-4e8b-8342-e1de5391f578",
   "metadata": {},
   "source": [
    "TODO:\n",
    " * Stepper motor skipping steps--more current (better power supply)?\n",
    " * Normalize action and observation spaces (see: https://ai.stackexchange.com/questions/21477/why-do-we-also-need-to-normalize-the-actions-values-on-continuous-action-spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37363014-d5bd-4d0b-8093-ad182644070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install gymnasium==0.28.1\n",
    "# !python -m pip install stable-baselines3[extra]==2.1.0\n",
    "# !python -m pip install ax-platform==0.3.4\n",
    "# !python -m pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ed8b9b-73a0-4c11-9c12-4bbd6b0debfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.0.0\n",
      "gymnasium version: 0.28.1\n",
      "sb3 version: 2.1.0\n",
      "cv2 version: 4.7.0.68\n",
      "ax version: 0.3.4\n"
     ]
    }
   ],
   "source": [
    "# Check versions\n",
    "import importlib.metadata\n",
    "\n",
    "print(f\"torch version: {importlib.metadata.version('torch')}\")\n",
    "print(f\"gymnasium version: {importlib.metadata.version('gymnasium')}\")\n",
    "print(f\"sb3 version: {importlib.metadata.version('stable-baselines3')}\")\n",
    "print(f\"cv2 version: {importlib.metadata.version('opencv-python')}\")\n",
    "print(f\"ax version: {importlib.metadata.version('ax-platform')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6601a351-afc4-4ad6-8119-335dce1392cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Standard Library\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "import math\n",
    "import csv\n",
    "from typing import Any, Dict, Tuple, Union\n",
    "\n",
    "# Encoder and stepper controls (local)\n",
    "from control_comms import ControlComms, StatusCode, DebugLevel\n",
    "\n",
    "# Third-party packages\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "# Reinforcement model modules\n",
    "import stable_baselines3 as sb3\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import KVWriter, Logger\n",
    "\n",
    "# Meta Ax\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render\n",
    "from ax.utils.tutorials.cnn_utils import train, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002868a4-1404-46fb-88a0-80adf9ee9dc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5512c5e3-f346-4866-be07-c9f275fc1b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communication settings\n",
    "SERIAL_PORT = \"COM4\"    # Check your devices\n",
    "BAUD_RATE = 1_000_000   # Must match what's in the Arduino code!\n",
    "CTRL_TIMEOUT = 2.0      # Seconds\n",
    "DEBUG_LEVEL = DebugLevel.DEBUG_ERROR\n",
    "\n",
    "# Reinforcement learning settings\n",
    "K_T = 1                 # Reward constant to multiply theta (angle of encoder)\n",
    "K_DT = 0.01             # Reward constant to multiply dtheto/dt (angular velocity of encoder)\n",
    "K_P = 0.001             # Reward constant to multiply phi (angle of stepper)\n",
    "K_DP = 0.00001           # Reward constant to multiply dphi/dt (angular velocity of stepper)\n",
    "REWARD_OOB = -500       # Reward (penalty) for ha ving the stepper motor move out of bounds (OOB)\n",
    "ENC_ANGLE_NORM = 180    # Divide by this to normalize +/-180 deg angle to +/-1\n",
    "STP_ACTION_MULT = 30    # Action space is normalized to [-1, 1], multiply by this to get actual action\n",
    "STP_ANGLE_MIN = -180    # Episode ends if stepper goes beyond this angle\n",
    "STP_ANGLE_MAX = 180     # Episode ends if stepper goes beyond this angle\n",
    "STP_ANGLE_NORM = 180    # Divide by this to normalize +/-180 deg angle to +/-1\n",
    "\n",
    "ENV_TIMEOUT = 30.0\n",
    "RESET_SETTLE_TIME = 2.0 # Seconds to wait after reset to start moving again\n",
    "\n",
    "# Angle constants\n",
    "ENC_OFFSET = 180.0      # Pendulum in the \"up\" position should be 0 deg\n",
    "ANG_REV = 360           # Degrees in a single revolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "631b6b53-ca9c-41c4-858c-581fcfbbe524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communication constants\n",
    "CMD_SET_HOME = 0        # Set current stepper position as home (0 deg)\n",
    "CMD_MOVE_TO = 1         # Move stepper to a particular position (deg)\n",
    "CMD_MOVE_BY = 2         # Move stepper by a given amount (deg)\n",
    "CMD_SET_STEP_MODE = 3   # Set step mode\n",
    "CMD_SET_BLOCK_MODE = 4  # Set blocking mode\n",
    "CMD_NOP = 5             # Take no action, just receive observation\n",
    "STEP_MODE_1 = 0         # 1 division per step\n",
    "STEP_MODE_2 = 1         # 2 divisions per step\n",
    "STEP_MODE_4 = 2         # 4 divisions per step\n",
    "STEP_MODE_8 = 3         # 8 divisions per step\n",
    "STEP_MODE_16 = 4        # 16 divisions per step\n",
    "STATUS_OK = 0           # Stepper idle\n",
    "STATUS_STP_MOVING = 1   # Stepper is currently moving\n",
    "\n",
    "# Set to desired step mode\n",
    "STEP_MODE = STEP_MODE_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00724565-b597-4c6a-a8fd-9dec4114949b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "316bc585-a495-4ad3-ae94-6b0930a38bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection to Arduino board (if open)\n",
    "try:\n",
    "    controller.close()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd6f5fef-12a0-405f-972a-fc6eb40b2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Arduino board\n",
    "controller = ControlComms(timeout=CTRL_TIMEOUT, debug_level=DEBUG_LEVEL)\n",
    "ret = controller.connect(SERIAL_PORT, BAUD_RATE)\n",
    "if ret is not StatusCode.OK:\n",
    "    print(\"ERROR: Could not connect to board\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61f80790-322b-498b-bef8-211d8a2696d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 88579, False, [3.0, 0.0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test basic comms\n",
    "controller.step(CMD_SET_STEP_MODE, [STEP_MODE_8])\n",
    "controller.step(CMD_SET_HOME, [0])\n",
    "controller.step(CMD_SET_BLOCK_MODE, [1])\n",
    "controller.step(CMD_MOVE_BY, [-25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef863618-7b2e-464f-9da1-f4f1f957d0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 92024, False, [0.3, -24.3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy test\n",
    "action = np.array([[-25]])\n",
    "action_list = action.flatten().tolist()\n",
    "controller.step(CMD_MOVE_BY, action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eeb8708-c488-42c6-8b2d-a6026fe9ea46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 94106, False, [9.9, -48.6])\n",
      "(0, 94353, False, [340.8, 1.8])\n",
      "(0, 94603, False, [344.7, 52.2])\n",
      "(0, 94851, False, [18.9, 102.6])\n",
      "(0, 95100, False, [336.3, 153.0])\n",
      "(0, 95352, False, [67.5, 203.4])\n",
      "(0, 95587, False, [85.2, 253.8])\n",
      "(0, 95821, False, [8.4, 304.2])\n",
      "(0, 95950, False, [12.6, 354.6])\n",
      "(0, 96074, False, [29.1, 354.6])\n",
      "(0, 96198, False, [23.4, 354.6])\n",
      "(0, 96308, False, [357.6, 354.6])\n",
      "(0, 96433, False, [350.7, 354.6])\n",
      "(0, 96542, False, [16.2, 354.6])\n",
      "(0, 96667, False, [17.7, 354.6])\n",
      "(0, 96790, False, [351.0, 354.6])\n",
      "(0, 96917, False, [358.8, 354.6])\n",
      "(0, 97043, False, [15.3, 354.6])\n",
      "(0, 97168, False, [359.4, 354.6])\n",
      "(0, 97293, False, [351.3, 354.6])\n"
     ]
    }
   ],
   "source": [
    "# Test hard limit (360 deg)\n",
    "for i in range(20):\n",
    "    resp = controller.step(CMD_MOVE_BY, [50])\n",
    "    print(resp)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c323e9db-1363-431f-8bae-9d44c0a03085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 97844, False, [10.2, 354.6])\n",
      "(0, 100148, False, [2.1, 0.0])\n",
      "(0, 100434, False, [40.5, -179.1])\n",
      "(0, 100724, False, [35.1, 0.9])\n",
      "(0, 101012, False, [45.9, -178.2])\n",
      "(0, 101301, False, [95.4, 1.8])\n",
      "(0, 101589, False, [333.6, -177.3])\n",
      "(0, 101880, False, [57.6, 2.7])\n",
      "(0, 102170, False, [348.0, -176.4])\n",
      "(0, 102460, False, [76.5, 3.6])\n",
      "(0, 102750, False, [352.8, -175.5])\n"
     ]
    }
   ],
   "source": [
    "# Stress/torque test\n",
    "resp = controller.step(CMD_MOVE_TO, [0])\n",
    "controller.step(CMD_SET_BLOCK_MODE, [1])\n",
    "print(resp)\n",
    "time.sleep(2.0)\n",
    "action = 180\n",
    "for i in range(10):\n",
    "    action = -180 if action == 180 else 180\n",
    "    resp = controller.step(CMD_MOVE_BY, [action])\n",
    "    print(resp)\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cfacfca-7ede-4fc3-a300-083084de93fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comms stress test\n",
    "# resp = controller.step(CMD_MOVE_TO, [0])\n",
    "# print(resp)\n",
    "# time.sleep(2.0)\n",
    "# for i in range(100000):\n",
    "#     resp = controller.step(CMD_MOVE_BY, [0])\n",
    "#     time.sleep(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a35db2c4-96d4-42f2-81f1-4b6a3746e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 154301, False, [356.1, 4.5])\n"
     ]
    }
   ],
   "source": [
    "# Move home\n",
    "resp = controller.step(CMD_MOVE_TO, [0])\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c07c94e-8ab6-490f-b856-ca817352049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close comms\n",
    "controller.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "827948c0-7a81-44e3-81e3-95d5c13eafb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 157405, False, [356.1, 0.0])\n",
      "(0, 157415, False, [356.1, 0.0])\n",
      "(0, 159438, False, [356.1, 0.0])\n",
      "(0, 161499, False, [356.1, 0.0])\n",
      "(0, 161669, False, [359.1, -9.0])\n",
      "(0, 161825, False, [350.4, -18.0])\n",
      "(0, 161982, False, [4.8, -27.0])\n",
      "(0, 162140, False, [351.0, -36.0])\n",
      "(0, 162296, False, [2.4, -45.0])\n",
      "(0, 162452, False, [353.1, -54.0])\n",
      "(0, 162610, False, [358.5, -63.0])\n",
      "(0, 162767, False, [356.1, -72.0])\n",
      "(0, 162921, False, [355.5, -81.0])\n",
      "(0, 163212, False, [359.1, -90.0])\n"
     ]
    }
   ],
   "source": [
    "# Basic step test\n",
    "action = np.array([[-10]])\n",
    "\n",
    "controller = ControlComms(timeout=CTRL_TIMEOUT, debug_level=DEBUG_LEVEL)\n",
    "ret = controller.connect(SERIAL_PORT, BAUD_RATE)\n",
    "if ret is not StatusCode.OK:\n",
    "    print(\"ERROR: Could not connect to board\")\n",
    "\n",
    "resp = controller.step(CMD_SET_BLOCK_MODE, [1])\n",
    "print(resp)\n",
    "resp = controller.step(CMD_SET_BLOCK_MODE, [1])\n",
    "print(resp)\n",
    "    \n",
    "# Reset\n",
    "time.sleep(2.0)\n",
    "resp = controller.step(CMD_MOVE_TO, [0.0])\n",
    "print(resp)\n",
    "time.sleep(2.0)\n",
    "\n",
    "# Loop\n",
    "for i in range(10):\n",
    "    action_list = action.flatten().tolist()\n",
    "    resp = controller.step(CMD_MOVE_BY, action_list)\n",
    "    print(resp)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# Move home and close\n",
    "resp = controller.step(CMD_MOVE_TO, [0])\n",
    "print(resp)\n",
    "controller.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbf62f43-718b-4997-b112-86c364a3f7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshawnhymel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log in to Weights & Biases\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3cce2f0-188f-40af-9282-ea58bb80e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make wandb be quiet\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "logger = logging.getLogger(\"wandb\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1566ff73-1195-4710-bab6-05a8309f7fa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6800b3d-197b-465f-b09b-b451708a16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds(seed: int) -> None:\n",
    "    \"\"\"\n",
    "    Seed the different random generators.\n",
    "    https://stable-baselines3.readthedocs.io/en/master/_modules/stable_baselines3/common/utils.html\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set seed for Python random and NumPy\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9bb2c64-36e7-41cc-9c86-67b35d741ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_angular_velocity(ang, ang_prev, dt):\n",
    "    \"\"\"\n",
    "    Estimate engular velocity based on current and previous readings. Note that we assume that the\n",
    "    object in question cannot go the long way around (e.g. more than 180 deg).\n",
    "    \"\"\"\n",
    "    da = ang - ang_prev\n",
    "    if da > (ANG_REV / 2):\n",
    "        da -= ANG_REV\n",
    "    elif da < -(ANG_REV / 2):\n",
    "        da += ANG_REV\n",
    "    \n",
    "    return da / dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9cd180-65fe-40f2-88bf-e584bdbbd2cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build gym Environment\n",
    "\n",
    "Subclass gymnasium.Env to create a custom environment. Learn more here:<br>\n",
    "https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "32bcddaa-b899-4cab-9a7b-82bd214c3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pendulum(gym.Env):\n",
    "    \"\"\"\n",
    "    Subclass gymnasium Env class\n",
    "    \n",
    "    This is the gym wrapper class that allows our agent to interact with our environment. We need\n",
    "    to implement four main methods: step(), reset(), render(), and close(). We should also define\n",
    "    the action_space and observation space as class members.\n",
    "    \n",
    "    Note: on Windows, time.sleep() is only accurate to around 10ms. As a result, setting fps_limit\n",
    "    will give you a \"best effort\" limit.\n",
    "    \n",
    "    More information: https://gymnasium.farama.org/api/env/\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        serial_port,\n",
    "        baud_rate,\n",
    "        ctrl_timeout=1.0,\n",
    "        debug_level=DebugLevel.DEBUG_NONE,\n",
    "        env_timeout=0.0, \n",
    "        stp_mode=STEP_MODE_8, \n",
    "        stp_blocking=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Set up the environment, action, and observation shapes. Optional tiemout in seconds.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Call superclass's constructor\n",
    "        super().__init__()\n",
    "        \n",
    "        # Connect to Arduino board\n",
    "        self.ctrl = ControlComms(timeout=ctrl_timeout, debug_level=debug_level)\n",
    "        try:\n",
    "            self.ctrl.close()\n",
    "        except:\n",
    "            pass\n",
    "        ret = self.ctrl.connect(serial_port, baud_rate)\n",
    "        if ret is not StatusCode.OK:\n",
    "            print(\"ERROR: Could not connect to board\")\n",
    "        \n",
    "        # Define action space (scalar signifying how many degrees to move stepper by)\n",
    "        self.action_space = gym.spaces.Box(\n",
    "            low=-1.0,\n",
    "            high=1.0,\n",
    "            shape=(1, 1),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Define observation space \n",
    "        # [encoder angle, encoder angular velocity, stepper angle, stepper angular velocity]\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=np.array([-180, -np.inf, STP_ANGLE_MIN, -np.inf]),\n",
    "            high=np.array([180, np.inf, STP_ANGLE_MAX, np.inf]),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Record time from microcontroller and own elapsed time\n",
    "        self.timestamp = 0\n",
    "        self.timeout = env_timeout\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # Record previous encoder and stepper angles (to calculate velocities)\n",
    "        self.angle_stp_prev = 0\n",
    "        self.angle_enc_prev = 0\n",
    "        \n",
    "        # Set current stepper position as \"home\" and optionally set blocking\n",
    "        self.ctrl.step(CMD_SET_STEP_MODE, [stp_mode])\n",
    "        self.ctrl.step(CMD_SET_HOME, [0])\n",
    "        if stp_blocking:\n",
    "            self.ctrl.step(CMD_SET_BLOCK_MODE, [1])\n",
    "        else:\n",
    "            self.ctrl.step(CMD_SET_BLOCK_MODE, [0])\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"\n",
    "        Destructor: make sure to close the serial port\n",
    "        \"\"\"\n",
    "        self.close()\n",
    "    \n",
    "    def step(self, action: np.ndarray):\n",
    "        \"\"\"\n",
    "        What happens when you tell the stepper motor to do something then record the observation.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize return values\n",
    "        obs = np.array([0.0, 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "        reward = 0.0\n",
    "        info = {\"error\": False, \"dtime\": 0.0, \"elapsed_time\": 0.0}\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        \n",
    "        # Scale normalized action [-1, 1] to actual action (e.g. [-60, 60])\n",
    "        action_scaled = STP_ACTION_MULT * action\n",
    "        \n",
    "        # Box is 2D NumPy array, action must be sent out as 1D list [...]\n",
    "        action_list = action_scaled.flatten().tolist()\n",
    "        \n",
    "        # Move the stepper motor and wait for a response\n",
    "        resp = self.ctrl.step(CMD_MOVE_BY, action_list)\n",
    "        if resp:\n",
    "            \n",
    "            # Extract information from controller response\n",
    "            status, timestamp, terminated, angles = resp\n",
    "            \n",
    "            # Compute lapsed time (in seconds) from previous observation (milliseconds)\n",
    "            info[\"dtime\"] = (timestamp - self.timestamp) / 1000.0\n",
    "            self.timestamp = timestamp\n",
    "            \n",
    "            # Offset encoder angle so that 0 deg is up\n",
    "            angles[0] -= ENC_OFFSET\n",
    "            \n",
    "            # Calculate velocities\n",
    "            dtheta = calc_angular_velocity(angles[0], self.angle_enc_prev, info['dtime'])\n",
    "            dphi = calc_angular_velocity(angles[1], self.angle_stp_prev, info['dtime'])\n",
    "            self.angle_enc_prev = angles[0]\n",
    "            self.angle_stp_prev = angles[1]\n",
    "            \n",
    "            # Construct observation (normalized)\n",
    "            obs[0] = angles[0] / ENC_ANGLE_NORM\n",
    "            obs[1] = dtheta / ENC_ANGLE_NORM\n",
    "            obs[2] = angles[1] / STP_ANGLE_NORM\n",
    "            obs[3] = dphi / STP_ANGLE_NORM\n",
    "                    \n",
    "            # Calculate reward if stepper is not out of bounds\n",
    "            if (angles[1] >= STP_ANGLE_MIN) and (angles[1] <= STP_ANGLE_MAX):\n",
    "                reward = -1 * (K_T * obs[0] ** 2 + \n",
    "                               K_DT * obs[1] ** 2 + \n",
    "                               K_P * obs[2] ** 2 +\n",
    "                               K_DP * obs[3] ** 2)\n",
    "            \n",
    "            # Stepper motor is out of bounds--terminate episode\n",
    "            else:\n",
    "                reward = REWARD_OOB\n",
    "                terminated = True\n",
    "        \n",
    "        # Something is wrong with communication\n",
    "        else:\n",
    "            print(\"ERROR: Could not communicate with Arduino\")\n",
    "            info[\"error\"] = True\n",
    "            terminated = True\n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        info[\"elapsed_time\"] = time.time() - self.start_time\n",
    "        \n",
    "        # Check if we've exceeded the time limit\n",
    "        if not terminated and self.timeout > 0.0 and info[\"elapsed_time\"] >= self.timeout:\n",
    "            truncated = True\n",
    "        \n",
    "        return obs, reward, terminated, truncated, info\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        \"\"\"\n",
    "        Return the pendulum to the starting position\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize return values\n",
    "        obs = np.array([0.0, 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "        info = {\"error\": False, \"dtime\": 0, \"elapsed_time\": 0.0}\n",
    "        \n",
    "        # Reset timer\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # Let the pendulum fall and return to the starting position\n",
    "        time.sleep(RESET_SETTLE_TIME)\n",
    "        resp = self.ctrl.step(CMD_MOVE_TO, [0.0])\n",
    "        if resp:\n",
    "            \n",
    "            # Extract information from controller response\n",
    "            status, timestamp, terminated, angles = resp\n",
    "            \n",
    "            # Compute lapsed time (in seconds) from previous observation (milliseconds)\n",
    "            info[\"dtime\"] = (timestamp - self.timestamp) / 1000.0\n",
    "            self.timestamp = timestamp\n",
    "            \n",
    "            # Offset encoder angle so that 0 deg is up\n",
    "            angles[0] -= ENC_OFFSET\n",
    "            \n",
    "            # Calculate velocities\n",
    "            dtheta = calc_angular_velocity(angles[0], self.angle_enc_prev, info['dtime'])\n",
    "            dphi = calc_angular_velocity(angles[1], self.angle_stp_prev, info['dtime'])\n",
    "            self.angle_enc_prev = angles[0]\n",
    "            self.angle_stp_prev = angles[1]\n",
    "            \n",
    "            # Construct observation (normalized)\n",
    "            obs[0] = angles[0] / ENC_ANGLE_NORM\n",
    "            obs[1] = dtheta / ENC_ANGLE_NORM\n",
    "            obs[2] = angles[1] / STP_ANGLE_NORM\n",
    "            obs[3] = dphi / STP_ANGLE_NORM\n",
    "            \n",
    "            # Let pendulum settle for a bit\n",
    "            time.sleep(RESET_SETTLE_TIME)\n",
    "            \n",
    "        # Something is wrong with communication\n",
    "        else:\n",
    "            print(\"ERROR: Could not communicate with Arduino\")\n",
    "            info[\"error\"] = True\n",
    "            \n",
    "        # Calculate elapsed time\n",
    "        info[\"elapsed_time\"] = time.time() - self.start_time\n",
    "        \n",
    "        return obs, info\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close connection to Arduino\n",
    "        \"\"\"\n",
    "        self.ctrl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac966999-8595-4e98-8a34-60ad251ce69c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test gym Environment\n",
    "\n",
    "Test the gym wrapper before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "79b6c823-05f7-4368-815d-353bd1acf23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our environment\n",
    "try:\n",
    "    env.close()\n",
    "except:\n",
    "    pass\n",
    "env = Pendulum(\n",
    "        SERIAL_PORT,\n",
    "        BAUD_RATE,\n",
    "        ctrl_timeout=CTRL_TIMEOUT,\n",
    "        debug_level=DEBUG_LEVEL,\n",
    "        env_timeout=ENV_TIMEOUT, \n",
    "        stp_mode=STEP_MODE, \n",
    "        stp_blocking=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f4449add-5c21-4da2-9669-53e8017c7ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9654957]]\n",
      "[[0.9681884]]\n",
      "[[0.02226986]]\n",
      "[[0.26244825]]\n",
      "[[0.74538463]]\n",
      "[[-0.58832335]]\n",
      "[[-0.10810516]]\n",
      "[[0.65737474]]\n",
      "[[0.12942122]]\n",
      "[[-0.10159676]]\n"
     ]
    }
   ],
   "source": [
    "# Check action space (should be normalized to [-1, 1])\n",
    "for i in range(10):\n",
    "    print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f607dd4c-2858-48d4-a115-97e98a943c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step   |             Observation              |  Reward  |   Done   | Info\n",
      " Reset   | 0.34, 0.00, 0.00, 0.00               | 0.0      |  False   | {'error': False, 'dtime': 814.853, 'elapsed_time': 4.029881954193115}\n",
      "   0     | 0.39, 0.03, 0.00, 0.00               | -0.15    |  False   | {'error': False, 'dtime': 2.026, 'elapsed_time': 4.04162859916687}\n",
      "   1     | 0.01, -0.38, 0.00, 0.00              | -0.00    |  False   | {'error': False, 'dtime': 1.011, 'elapsed_time': 5.057876348495483}\n",
      "   2     | -0.31, -0.31, 0.00, 0.00             | -0.10    |  False   | {'error': False, 'dtime': 1.026, 'elapsed_time': 6.083733081817627}\n",
      "   3     | -0.28, 0.03, 0.00, 0.00              | -0.08    |  False   | {'error': False, 'dtime': 1.029, 'elapsed_time': 7.1076812744140625}\n",
      "   4     | -0.28, 0.00, 0.00, 0.00              | -0.08    |  False   | {'error': False, 'dtime': 1.014, 'elapsed_time': 8.123551368713379}\n",
      "   5     | -0.32, -0.05, 0.00, 0.00             | -0.11    |  False   | {'error': False, 'dtime': 1.014, 'elapsed_time': 9.141027688980103}\n",
      "   6     | 0.34, 0.64, 0.00, 0.00               | -0.12    |  False   | {'error': False, 'dtime': 1.03, 'elapsed_time': 10.1716628074646}\n",
      "   7     | 0.34, 0.00, 0.00, 0.00               | -0.12    |  False   | {'error': False, 'dtime': 1.024, 'elapsed_time': 11.196577072143555}\n",
      "   8     | 0.34, 0.00, 0.00, 0.00               | -0.12    |  False   | {'error': False, 'dtime': 1.024, 'elapsed_time': 12.220224857330322}\n",
      "   9     | 0.34, 0.00, 0.00, 0.00               | -0.12    |  False   | {'error': False, 'dtime': 1.027, 'elapsed_time': 13.240270614624023}\n"
     ]
    }
   ],
   "source": [
    "# Test encoder\n",
    "obs, info = env.reset()\n",
    "obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "if info[\"error\"]:\n",
    "    print(\"Stopping\")\n",
    "else:\n",
    "    print(f\"{'Step': ^8} | {'Observation': ^36} | {'Reward': ^8} | {'Done': ^8} | Info\")\n",
    "    print(f\"{'Reset': ^8} | {obs_str: <36} | {0.0: <8} | {str(False): ^8} | {info}\")\n",
    "    for i in range(10):\n",
    "        obs, reward, terminated, truncated, info = env.step(np.array([[0]]))\n",
    "        obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "        print(f\"{i: ^8} | {obs_str: <36} | {reward: <8.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "        if info[\"error\"]:\n",
    "            print(\"Stopping\")\n",
    "            break\n",
    "        if terminated or truncated:\n",
    "            print(\"Episode done\")\n",
    "            break\n",
    "        time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7ac5a0e1-d72a-4052-a8db-086fd6d288a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step   |  Action  |             Observation              |  Reward  |   Done   | Info\n",
      " Reset   | 0.0      | 0.37, -0.17, 0.14, 0.50              | 0.0      |  False   | {'error': False, 'dtime': 5.098, 'elapsed_time': 4.109649419784546}\n",
      "   0     | -0.79    | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 2.106, 'elapsed_time': 4.209275007247925}\n",
      "   1     | 0.28     | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.061, 'elapsed_time': 4.264204978942871}\n",
      "   2     | 0.54     | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.074, 'elapsed_time': 4.342162370681763}\n",
      "   3     | -0.53    | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.083, 'elapsed_time': 4.426619529724121}\n",
      "   4     | -0.23    | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.055, 'elapsed_time': 4.475358486175537}\n",
      "   5     | 0.59     | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.078, 'elapsed_time': 4.55588960647583}\n",
      "   6     | -0.31    | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.056, 'elapsed_time': 4.612909317016602}\n",
      "   7     | 0.70     | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.093, 'elapsed_time': 4.702006101608276}\n",
      "   8     | 0.26     | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.056, 'elapsed_time': 4.7665016651153564}\n",
      "   9     | 0.71     | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.092, 'elapsed_time': 4.857341289520264}\n",
      "   10    | 0.93     | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.112, 'elapsed_time': 4.970534086227417}\n",
      "   11    | 0.51     | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.084, 'elapsed_time': 5.048440456390381}\n",
      "   12    | -0.16    | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.031, 'elapsed_time': 5.08362889289856}\n",
      "   13    | 0.35     | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.063, 'elapsed_time': 5.140882730484009}\n",
      "   14    | -0.61    | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.084, 'elapsed_time': 5.2292022705078125}\n",
      "   15    | -0.40    | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.059, 'elapsed_time': 5.289382219314575}\n",
      "   16    | 0.51     | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.084, 'elapsed_time': 5.373351812362671}\n",
      "   17    | 0.39     | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.074, 'elapsed_time': 5.4366679191589355}\n",
      "   18    | 0.24     | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.041, 'elapsed_time': 5.483983993530273}\n",
      "   19    | -0.64    | 0.37, -0.17, 0.14, 0.50              | -0.00    |  False   | {'error': False, 'dtime': 0.078, 'elapsed_time': 5.560397386550903}\n",
      "Action mean: 0.11804966628551483\n",
      "Action std dev: 0.5124720335006714\n",
      "Total reward: -0.004430439166094604\n"
     ]
    }
   ],
   "source": [
    "# Run some random steps\n",
    "actions = []\n",
    "rewards = []\n",
    "obs, info = env.reset()\n",
    "if info[\"error\"]:\n",
    "    print(\"Stopping\")\n",
    "else:\n",
    "    print(f\"{'Step': ^8} | {'Action': ^8} | {'Observation': ^36} | {'Reward': ^8} | {'Done': ^8} | Info\")\n",
    "    print(f\"{'Reset': ^8} | {0.0: <8} | {obs_str: <36} | {0.0: <8} | {str(False): ^8} | {info}\")\n",
    "    for i in range(20):\n",
    "        action = env.action_space.sample()\n",
    "        actions.append(action)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        print(f\"{i: ^8} | {action[0][0]: <8.2f} | {obs_str: <36} | {reward: <8.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "        if info[\"error\"]:\n",
    "            print(\"Stopping\")\n",
    "            break\n",
    "        if terminated or truncated:\n",
    "            print(\"Episode done\")\n",
    "            break\n",
    "\n",
    "# Print stats\n",
    "action_mean = np.mean(np.array(actions))\n",
    "action_std = np.std(np.array(actions))\n",
    "print(f\"Action mean: {action_mean}\")\n",
    "print(f\"Action std dev: {action_std}\")\n",
    "print(f\"Total reward: {sum(rewards)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "656213f8-6fa8-4a41-828a-0761a601b384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step   |             Observation              |  Reward  |   Done   | Info\n",
      " Reset   | 0.37, 0.00, 0.00, 0.00               | 0.0      |  False   | {'error': False, 'dtime': 1108.516, 'elapsed_time': 4.027516841888428}\n",
      "   0     | 0.37, 0.00, 0.00, 0.00               | -0.14    |  False   | {'error': False, 'dtime': 2.037, 'elapsed_time': 4.062477111816406}\n",
      "   1     | 0.37, 0.16, 0.01, 0.48               | -0.14    |  False   | {'error': False, 'dtime': 0.031, 'elapsed_time': 4.09613037109375}\n",
      "   2     | 0.37, -0.05, 0.03, 0.42              | -0.14    |  False   | {'error': False, 'dtime': 0.036, 'elapsed_time': 4.131204843521118}\n",
      "   3     | 0.37, -0.10, 0.05, 0.43              | -0.14    |  False   | {'error': False, 'dtime': 0.035, 'elapsed_time': 4.162210464477539}\n",
      "   4     | 0.36, -0.17, 0.06, 0.50              | -0.13    |  False   | {'error': False, 'dtime': 0.03, 'elapsed_time': 4.195092678070068}\n",
      "   5     | 0.37, 0.05, 0.08, 0.43               | -0.13    |  False   | {'error': False, 'dtime': 0.035, 'elapsed_time': 4.231054306030273}\n",
      "   6     | 0.37, 0.10, 0.09, 0.43               | -0.14    |  False   | {'error': False, 'dtime': 0.035, 'elapsed_time': 4.266849517822266}\n",
      "   7     | 0.37, 0.10, 0.10, 0.43               | -0.14    |  False   | {'error': False, 'dtime': 0.035, 'elapsed_time': 4.29628849029541}\n",
      "   8     | 0.37, 0.06, 0.12, 0.50               | -0.14    |  False   | {'error': False, 'dtime': 0.03, 'elapsed_time': 4.326393127441406}\n",
      "   9     | 0.37, -0.17, 0.14, 0.50              | -0.14    |  False   | {'error': False, 'dtime': 0.03, 'elapsed_time': 4.355566501617432}\n"
     ]
    }
   ],
   "source": [
    "# Try running the environment for a few steps (stepper should move some)\n",
    "obs, info = env.reset()\n",
    "obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "if info[\"error\"]:\n",
    "    print(\"Stopping\")\n",
    "else:\n",
    "    print(f\"{'Step': ^8} | {'Observation': ^36} | {'Reward': ^8} | {'Done': ^8} | Info\")\n",
    "    print(f\"{'Reset': ^8} | {obs_str: <36} | {0.0: <8} | {str(False): ^8} | {info}\")\n",
    "    for i in range(10):\n",
    "        obs, reward, terminated, truncated, info = env.step(np.array([[0.1]]))\n",
    "        obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "        print(f\"{i: ^8} | {obs_str: <36} | {reward: <8.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "        if info[\"error\"]:\n",
    "            print(\"Stopping\")\n",
    "            break\n",
    "        if terminated or truncated:\n",
    "            print(\"Episode done\")\n",
    "            break\n",
    "        # time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "29e42ab0-f298-4443-983e-ee356ed9b61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.36166668, 0.08556981, 0.        , 0.        ], dtype=float32),\n",
       " {'error': False, 'dtime': 4.285, 'elapsed_time': 4.015100002288818})"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0f17830a-cf64-4f28-b268-f1770ee132eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step   |             Observation              |  Reward  |   Done   | Info\n",
      "Total reward: -0.004251805699303806\n"
     ]
    }
   ],
   "source": [
    "# Run reward test (try moving the pendulum)\n",
    "print(f\"{'Step': ^8} | {'Observation': ^36} | {'Reward': ^8} | {'Done': ^8} | Info\")\n",
    "rewards = []\n",
    "for i in range(100):\n",
    "    obs, reward, terminated, truncated, info = env.step(np.array([[0.0]]))\n",
    "    rewards.append(reward)\n",
    "    obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "    # print(f\"{i: ^8} | {obs_str: <36} | {reward: <8.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "    if info[\"error\"]:\n",
    "        print(\"Stopping\")\n",
    "        break\n",
    "    if terminated or truncated:\n",
    "        print(\"Episode done\")\n",
    "        break\n",
    "\n",
    "print(f\"Total reward: {sum(rewards)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e3b1cc85-0cc9-496e-93ba-4f670de7c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs: [0.36333334 0.04709472 0.         0.        ], info: {'error': False, 'dtime': 7.538, 'elapsed_time': 4.030154705047607}\n",
      "Episode done\n"
     ]
    }
   ],
   "source": [
    "# Test timeout (stepper will reset and vibrate for a while)\n",
    "obs, info = env.reset()\n",
    "print(f\"obs: {obs}, info: {info}\")\n",
    "action = 0.1\n",
    "if not info[\"error\"]:\n",
    "    for i in range(1000):\n",
    "        action = -0.1 if action == 0.1 else 0.1\n",
    "        obs, reward, terminated, truncated, info = env.step(np.array([[action]]))\n",
    "        # print(f\"{i: ^8} | {obs_str: <36} | {reward: <8.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "        if terminated or truncated:\n",
    "            print(\"Episode done\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "75c8710f-6a1b-4e54-ab1c-82cbc4d73080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final environment check to make sure it works with Stable-Baselines3 (no errors means it worked)\n",
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8f593d48-dacf-424b-ae3c-531b2d5914c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a13f9-7fd8-41b8-a132-7ba226d43345",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "74f6d7db-4f12-400a-b61e-b726e8f028a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that tests the model in the given environment\n",
    "def test_agent(env, model, max_steps=0):\n",
    "\n",
    "    # Reset environment\n",
    "    obs, info = env.reset()\n",
    "    ep_len = 0\n",
    "    ep_rew = 0\n",
    "    avg_step_time = 0.0\n",
    "    actions = []\n",
    "\n",
    "    # Run episode until complete\n",
    "    while True:\n",
    "\n",
    "        # Provide observation to policy to predict the next action\n",
    "        timestamp = time.time()\n",
    "        action, _ = model.predict(obs)\n",
    "        actions.append(action)\n",
    "\n",
    "        # Perform action, update total reward\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        avg_step_time += time.time() - timestamp\n",
    "        ep_rew += reward\n",
    "\n",
    "        # Increase step counter\n",
    "        ep_len += 1\n",
    "        if (max_steps > 0) and (ep_len >= max_steps):\n",
    "            break\n",
    "\n",
    "        # Check to see if episode has ended\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "        \n",
    "    # Calculate average step time\n",
    "    avg_step_time /= ep_len\n",
    "    \n",
    "    # Calculate action stats\n",
    "    action_mean = np.mean(np.array(actions))\n",
    "    action_std = np.std(np.array(actions))\n",
    "    \n",
    "    return ep_len, ep_rew, avg_step_time, action_mean, action_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de81902-9bcc-451d-99fd-7db9febdd73a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing and logging callbacks\n",
    "\n",
    "Construct custom callbacks for Stable-Baselines3 to test our agent and log metrics to Weights & Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1f3870bb-7d23-4d12-a171-4f284c3335e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate agent on a number of tests\n",
    "def evaluate_agent(env, model, steps_per_test, num_tests):\n",
    "    \n",
    "    # Initialize metrics\n",
    "    avg_ep_len = 0.0\n",
    "    avg_ep_rew = 0.0\n",
    "    avg_step_time = 0.0\n",
    "    avg_action_mean = 0.0\n",
    "    avg_action_std = 0.0\n",
    "    \n",
    "    # Test the agent a number of times\n",
    "    for ep in range(num_tests):\n",
    "        ep_len, ep_rew, step_time, action_mean, action_std = test_agent(env, model, max_steps=steps_per_test)\n",
    "        avg_ep_len += ep_len\n",
    "        avg_ep_rew += ep_rew\n",
    "        avg_step_time += step_time\n",
    "        avg_action_mean += action_mean\n",
    "        avg_action_std += action_std\n",
    "        \n",
    "    # Compute metrics\n",
    "    avg_ep_len /= num_tests\n",
    "    avg_ep_rew /= num_tests\n",
    "    avg_step_time /= num_tests\n",
    "    avg_action_mean /= num_tests\n",
    "    avg_action_std /= num_tests\n",
    "    \n",
    "    return avg_ep_len, avg_ep_rew, avg_step_time, avg_action_mean, avg_action_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7e467390-4f21-48cd-a5e3-2862ddf25cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalAndSaveCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Evaluate and save the model every ``check_freq`` steps\n",
    "    \n",
    "    More info: https://stable-baselines3.readthedocs.io/en/master/guide/callbacks.html\n",
    "    \"\"\"\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(\n",
    "        self, \n",
    "        check_freq, \n",
    "        save_dir,\n",
    "        model_name=\"model\",\n",
    "        replay_buffer_name=None,\n",
    "        steps_per_test=0, \n",
    "        num_tests=10,\n",
    "        step_offset=0,\n",
    "        verbose=1,\n",
    "    ):\n",
    "        super(EvalAndSaveCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_dir = save_dir\n",
    "        self.model_name = model_name\n",
    "        self.replay_buffer_name = replay_buffer_name\n",
    "        self.num_tests = num_tests\n",
    "        self.steps_per_test = steps_per_test\n",
    "        self.step_offset = step_offset\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    # Create directory for saving the models\n",
    "    def _init_callback(self):\n",
    "        if self.save_dir is not None:\n",
    "            os.makedirs(self.save_dir, exist_ok=True)\n",
    "            \n",
    "    # Save and evaluate model at a set interval\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            \n",
    "            # Set actual number of steps (including offset)\n",
    "            actual_steps = self.step_offset + self.n_calls\n",
    "            \n",
    "            # Save model\n",
    "            model_path = os.path.join(self.save_dir, f\"{self.model_name}_{str(actual_steps)}\")\n",
    "            self.model.save(model_path)\n",
    "            \n",
    "            # Save replay buffer\n",
    "            if self.replay_buffer_name != None:\n",
    "                replay_buffer_path = os.path.join(self.save_dir, f\"{self.replay_buffer_name}\")\n",
    "                self.model.save_replay_buffer(replay_buffer_path)\n",
    "            \n",
    "            # Evaluate the agent\n",
    "            avg_ep_len, avg_ep_rew, avg_step_time, avg_action_mean, avg_action_std = evaluate_agent(\n",
    "                env, \n",
    "                self.model, \n",
    "                self.steps_per_test, \n",
    "                self.num_tests\n",
    "            )\n",
    "            if self.verbose:\n",
    "                print(f\"{str(actual_steps)} steps | average test length: {avg_ep_len}, average test reward: {avg_ep_rew}\")\n",
    "                \n",
    "            # Log metrics to WandB\n",
    "            log_dict = {\n",
    "                'avg_ep_len': avg_ep_len,\n",
    "                'avg_ep_rew': avg_ep_rew,\n",
    "                'avg_step_time': avg_step_time,\n",
    "                'avg_action_mean': avg_action_mean,\n",
    "                'avg_action_std': avg_action_std,\n",
    "            }\n",
    "            wandb.log(log_dict, commit=True, step=actual_steps)\n",
    "            \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9ef5e1e7-bc63-4288-9a2e-f165b78a17fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandBWriter(KVWriter):\n",
    "    \"\"\"\n",
    "    Log metrics to Weights & Biases when called by .learn()\n",
    "    \n",
    "    More info: https://stable-baselines3.readthedocs.io/en/master/_modules/stable_baselines3/common/logger.html#KVWriter\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize run\n",
    "    def __init__(self, run, verbose=1):\n",
    "        super().__init__()\n",
    "        self.run = run\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # Write metrics to W&B project\n",
    "    def write(self, \n",
    "              key_values: Dict[str, Any], \n",
    "              key_excluded: Dict[str, Union[str, Tuple[str, ...]]], \n",
    "              step: int = 0) -> None:\n",
    "        log_dict = {}\n",
    "        \n",
    "        # Go through each key/value pairs\n",
    "        for (key, value), (_, excluded) in zip(\n",
    "            sorted(key_values.items()), sorted(key_excluded.items())):\n",
    "            \n",
    "            if self.verbose >= 2:\n",
    "                print(f\"step={step} | {key} : {value} ({type(value)})\")\n",
    "            \n",
    "            # Skip excluded items\n",
    "            if excluded is not None and \"wandb\" in excluded:\n",
    "                continue\n",
    "                \n",
    "            # Log integers and floats\n",
    "            if isinstance(value, np.ScalarType):\n",
    "                if not isinstance(value, str):\n",
    "                    wandb.log(data={key: value}, step=step)\n",
    "                    log_dict[key] = value\n",
    "                \n",
    "        # Print to console\n",
    "        if self.verbose >= 1:\n",
    "            print(f\"Log for steps={step}\")\n",
    "            print(f\"--------------\")\n",
    "            for (key, value) in sorted(log_dict.items()):\n",
    "                print(f\"  {key}: {value}\")\n",
    "            print()\n",
    "                \n",
    "    # Close the W&B run\n",
    "    def close(self) -> None:\n",
    "        self.run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdecb53-cf01-41b5-ad9e-224806c4ac7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define train and test function for a single trial\n",
    "\n",
    "A single \"trial\" is fully training and then testing the agent using one set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aebdc5ce-4123-448c-a675-d067932e24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_trial(settings, hparams):\n",
    "    \"\"\"\n",
    "    Training loop used to evaluate a set of hyperparameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set random seed\n",
    "    set_random_seeds(settings['seed'])\n",
    "    \n",
    "    # Create new W&B run\n",
    "    config = {}\n",
    "    dt = datetime.datetime.now(datetime.timezone.utc)\n",
    "    dt = dt.replace(microsecond=0, tzinfo=None)\n",
    "    run = wandb.init(\n",
    "        project=settings['wandb_project'], \n",
    "        name=str(dt), \n",
    "        config=config,\n",
    "        settings=wandb.Settings(silent=(not settings['verbose_wandb']))\n",
    "    )\n",
    "\n",
    "    # Print run info\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(f\"WandB run ID: {run.id}\")\n",
    "        print(f\"WandB run name: {run.name}\")\n",
    "    \n",
    "    # Log hyperparameters to W&B\n",
    "    wandb.config.update(hparams)\n",
    "    \n",
    "    # Set custom logger with our custom writer\n",
    "    wandb_writer = WandBWriter(run, verbose=settings['verbose_log'])\n",
    "    loggers = Logger(\n",
    "        folder=None,\n",
    "        output_formats=[wandb_writer]\n",
    "    )\n",
    "    \n",
    "    # Calculate derived hyperparameters\n",
    "    n_steps = 2 ** hparams['steps_per_update_pow2']\n",
    "    minibatch_size = (hparams['n_envs'] * n_steps) / (2 ** hparams['batch_size_div_pow2'])\n",
    "    layer_1 = 2 ** hparams['layer_1_pow2']\n",
    "    layer_2 = 2 ** hparams['layer_2_pow2']\n",
    "\n",
    "    # Create new agent\n",
    "    # PPO docs: https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html\n",
    "    # Policy networks: https://stable-baselines.readthedocs.io/en/master/modules/policies.html\n",
    "    model = sb3.PPO(\n",
    "        'MlpPolicy',\n",
    "        env,\n",
    "        learning_rate=hparams['learning_rate'], # Learning rate of neural network (default: 0.0003)\n",
    "        n_steps=n_steps,                        # Number of steps per update (default: 2048)\n",
    "        batch_size=minibatch_size,              # Minibatch size for NN update (default: 64)\n",
    "        gamma=hparams['gamma'],                 # Discount factor (default: 0.99)\n",
    "        gae_lambda=hparams['gae_lambda'],       # Trade-off of bias vs. variance for GAE (default: 0.95)\n",
    "        clip_range=hparams['clip_range'],       # Clipping parameter (default: 0.2)\n",
    "        ent_coef=hparams['entropy_coef'],       # Entropy, how much to explore (default: 0.0)\n",
    "        vf_coef=hparams['vf_coef'],             # Value function coefficient for the loss calculation (default: 0.5)\n",
    "        max_grad_norm=hparams['max_grad_norm'], # Max value for gradient clipping (default: 0.5)\n",
    "        use_sde=hparams['use_sde'],             # Use generalized State Dependent Exploration (default: False)\n",
    "        sde_sample_freq=hparams['sde_freq'],    # Number of steps before sampling new noise matrix (default -1)\n",
    "        policy_kwargs={'net_arch': [layer_1, layer_2]}, # (default: [64, 64])\n",
    "        verbose=settings['verbose_train']       # Print training metrics (default: 0)\n",
    "    )\n",
    "    steps_to_complete = settings['total_steps']\n",
    "        \n",
    "    # Set up checkpoint callback\n",
    "    checkpoint_callback = EvalAndSaveCallback(\n",
    "        check_freq=settings['checkpoint_freq'], \n",
    "        save_dir=settings['save_dir'],\n",
    "        model_name=settings['model_name'],\n",
    "        replay_buffer_name=settings['replay_buffer_name'],\n",
    "        steps_per_test=settings['steps_per_test'],\n",
    "        num_tests=settings['tests_per_check'],\n",
    "        step_offset=(settings['total_steps'] - steps_to_complete),\n",
    "        verbose=settings['verbose_test'],\n",
    "    )\n",
    "    \n",
    "    # Choo choo train\n",
    "    model.learn(total_timesteps=steps_to_complete, \n",
    "                callback=[checkpoint_callback])\n",
    "    \n",
    "    # Get dataframe of run metrics\n",
    "    history = wandb.Api().run(f\"{run.project}/{run.id}\").history()\n",
    "\n",
    "    # Get index of evaluation with maximum reward\n",
    "    max_idx = np.argmax(history.loc[:, 'avg_ep_rew'].values)\n",
    "\n",
    "    # Find number of steps required to produce that maximum reward\n",
    "    max_rew_steps = history['_step'][max_idx]\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(f\"Steps with max reward: {max_rew_steps}\")\n",
    "    \n",
    "    # Load model with maximum reward from previous run\n",
    "    model_path = os.path.join(settings['save_dir'], f\"{settings['model_name']}_{str(max_rew_steps)}.zip\")\n",
    "    model = sb3.PPO.load(model_path, env)\n",
    "    \n",
    "    # Evaluate the agent\n",
    "    avg_ep_len, avg_ep_rew, avg_step_time, avg_action_mean, avg_action_std = evaluate_agent(\n",
    "        env, \n",
    "        model, \n",
    "        settings['steps_per_test'],\n",
    "        settings['tests_per_check'],\n",
    "    )\n",
    "    \n",
    "    # Log final evaluation metrics to WandB run\n",
    "    wandb.run.summary['Average test episode length'] = avg_ep_len\n",
    "    wandb.run.summary['Average test episode reward'] = avg_ep_rew\n",
    "    wandb.run.summary['Average test step time'] = avg_step_time\n",
    "    \n",
    "    # Print final run metrics\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(\"---\")\n",
    "        print(f\"Best model: {settings['model_name']}_{str(max_rew_steps)}.zip\")\n",
    "        print(f\"Average episode length: {avg_ep_len}\")\n",
    "        print(f\"Average episode reward: {avg_ep_rew}\")\n",
    "        print(f\"Average step time: {avg_step_time}\")\n",
    "        print(f\"Average action mean: {avg_action_mean}\")\n",
    "        print(f\"Average action std dev: {avg_action_std}\")\n",
    "                      \n",
    "    # Close W&B run\n",
    "    run.finish()\n",
    "    \n",
    "    return avg_ep_rew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a7822-6c9e-4fff-a03f-0304d787702d",
   "metadata": {},
   "source": [
    "## Perform trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "288b5de3-822d-4395-b1e8-2537680b0336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project settings that do not change\n",
    "settings = {\n",
    "    'wandb_project': \"pendulum-esp32-hpo-1\",\n",
    "    'model_name': \"ppo-pendulum\",\n",
    "    'ax_experiment_name': \"ppo-pendulum-esp32-1\",\n",
    "    'ax_objective_name': \"avg_ep_rew\",\n",
    "    'replay_buffer_name': None,\n",
    "    'save_dir': \"checkpoints\",\n",
    "    'checkpoint_freq': 5_000,\n",
    "    'steps_per_test': 500,\n",
    "    'tests_per_check': 10,\n",
    "    'total_steps': 50_000,\n",
    "    'num_trials': 100,\n",
    "    'seed': 42,\n",
    "    'verbose_ax': False,\n",
    "    'verbose_wandb': False,\n",
    "    'verbose_train': 0,\n",
    "    'verbose_log': 0,\n",
    "    'verbose_test': 0,\n",
    "    'verbose_trial': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed4bcd36-4d5a-489a-8a4c-86403a6a1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters we want to optimize\n",
    "# Ref: https://github.com/facebook/Ax/blob/6443cee30cbf8cec290200a7420a3db08e4b5445/ax/service/ax_client.py#L236\n",
    "# Example: https://github.com/facebook/Ax/blob/main/tutorials/tune_cnn_service.ipynb\n",
    "# Hyperparameters: https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#stable_baselines3.ppo.PPO\n",
    "hparams = [\n",
    "    {\n",
    "        'name': \"n_envs\",\n",
    "        'type': \"fixed\",\n",
    "        'value_type': \"int\",\n",
    "        'value': 1,\n",
    "    },\n",
    "    {\n",
    "        'name': \"learning_rate\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.0005, 0.007],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"steps_per_update_pow2\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"int\",\n",
    "        'bounds': [8, 11], # Inclusive, 2**n between [256, 2048]\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"batch_size_div_pow2\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"int\",\n",
    "        'bounds': [0, 3], # Inclusive, 2**n between [512, 4096]\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"gae_lambda\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.9, 0.99],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"clip_range\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.1, 0.4],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"gamma\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.92, 0.99],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"entropy_coef\",\n",
    "        'value_type': \"float\",\n",
    "        'type': \"range\",\n",
    "        'bounds': [0.0, 0.01],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"vf_coef\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.2, 0.7],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"max_grad_norm\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.5, 5.0],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"use_sde\",\n",
    "        'type': \"fixed\",\n",
    "        'value_type': \"bool\",\n",
    "        'value': True,\n",
    "    },\n",
    "    {\n",
    "        'name': \"sde_freq\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"int\",\n",
    "        'bounds': [2, 6],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"layer_1_pow2\",\n",
    "        'type': \"fixed\",\n",
    "        'value_type': \"int\",\n",
    "        'value': 8, # 2**n (is 256)\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"layer_2_pow2\",\n",
    "        'type': \"fixed\",\n",
    "        'value_type': \"int\",\n",
    "        'value': 8, # 2**n (is 256)\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Set parameter constraints\n",
    "# Example: https://github.com/facebook/Ax/issues/621\n",
    "parameter_constraints = [\n",
    "    \"minibatch_size_pow2 >= steps_per_update_pow2\" # `batch_size` should be a factor of `n_steps * n_envs`, assume n_envs=1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af5b3fb4-2186-425e-8079-a54735dde9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our environment\n",
    "try:\n",
    "    env.close()\n",
    "except:\n",
    "    pass\n",
    "env = Pendulum(\n",
    "        SERIAL_PORT,\n",
    "        BAUD_RATE,\n",
    "        ctrl_timeout=CTRL_TIMEOUT,\n",
    "        debug_level=DEBUG_LEVEL,\n",
    "        env_timeout=ENV_TIMEOUT, \n",
    "        stp_mode=STEP_MODE, \n",
    "        stp_blocking=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "362c011c-85ab-4460-a5cd-a2a687feb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosntruct path to Ax experiment snapshot file\n",
    "ax_snapshot_path = os.path.join(settings['save_dir'], f\"{settings['ax_experiment_name']}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8a7eb35-aa2f-47ff-bdbf-de1658632e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DANGER! Uncomment to delete the experiment file to start over\n",
    "\n",
    "# os.remove(ax_snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70621040-a54e-4e8b-ba5b-89f30be1730f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 10-04 09:25:59] ax.service.ax_client: Random seed set to 42. Note that this setting only affects the Sobol quasi-random generator and BoTorch-powered Bayesian optimization models. For the latter models, setting random seed to the same number for two optimizations will make the generated trials similar, but not exactly the same, and over time the trials will diverge more.\n",
      "[INFO 10-04 09:25:59] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[FixedParameter(name='n_envs', parameter_type=INT, value=1), RangeParameter(name='learning_rate', parameter_type=FLOAT, range=[0.0005, 0.007]), RangeParameter(name='steps_per_update_pow2', parameter_type=INT, range=[6, 9]), RangeParameter(name='minibatch_size_pow2', parameter_type=INT, range=[9, 12]), RangeParameter(name='gae_lambda', parameter_type=FLOAT, range=[0.9, 0.99]), RangeParameter(name='clip_range', parameter_type=FLOAT, range=[0.1, 0.4]), RangeParameter(name='gamma', parameter_type=FLOAT, range=[0.92, 0.99]), RangeParameter(name='entropy_coef', parameter_type=FLOAT, range=[0.0, 0.01]), RangeParameter(name='vf_coef', parameter_type=FLOAT, range=[0.2, 0.7]), RangeParameter(name='max_grad_norm', parameter_type=FLOAT, range=[0.5, 5.0]), FixedParameter(name='use_sde', parameter_type=BOOL, value=True), RangeParameter(name='sde_freq', parameter_type=INT, range=[2, 6]), FixedParameter(name='layer_1_pow2', parameter_type=INT, value=8), FixedParameter(name='layer_2_pow2', parameter_type=INT, value=8)], parameter_constraints=[OrderConstraint(steps_per_update_pow2 <= minibatch_size_pow2)]).\n",
      "[INFO 10-04 09:25:59] ax.modelbridge.dispatch_utils: Using Models.GPEI since there are more ordered parameters than there are categories for the unordered categorical parameters.\n",
      "[INFO 10-04 09:25:59] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=10 num_trials=None use_batch_trials=False\n",
      "[INFO 10-04 09:25:59] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=20\n",
      "[INFO 10-04 09:25:59] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=20\n",
      "[INFO 10-04 09:25:59] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 20 trials, GPEI for subsequent trials]). Iterations after 20 will take longer to generate due to model-fitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new experiment. Snapshot to be saved at checkpoints\\ppo-pendulum-esp32-1.json.\n"
     ]
    }
   ],
   "source": [
    "# Load experiment from snapshot if it exists, otherwise create a new one\n",
    "# Ref: https://ax.dev/versions/0.2.10/api/service.html#ax.service.ax_client.AxClient.create_experiment\n",
    "if os.path.exists(ax_snapshot_path):\n",
    "    print(f\"Loading experiment from snapshot: {ax_snapshot_path}\")\n",
    "    ax_client = AxClient.load_from_json_file(ax_snapshot_path)\n",
    "else:\n",
    "    print(f\"Creating new experiment. Snapshot to be saved at {ax_snapshot_path}.\")\n",
    "    ax_client = AxClient(\n",
    "        random_seed=settings['seed'],\n",
    "        verbose_logging=settings['verbose_ax'],\n",
    "    )\n",
    "    ax_client.create_experiment(\n",
    "        name=settings['ax_experiment_name'],\n",
    "        parameters=hparams,\n",
    "        objective_name=settings['ax_objective_name'],\n",
    "        minimize=False,\n",
    "        parameter_constraints=parameter_constraints,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e98af995-9535-44d0-b269-16d341f7b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DANGER! Use this cell to mark trials as failed (e.g. if component breaks and WandB shows bad data for a given trial)\n",
    "# Check .json file with a site like https://jsonformatter.org/json-pretty-print\n",
    "\n",
    "# trial_index = 8\n",
    "# trial = ax_client.experiment.trials[trial_index]\n",
    "# trial.mark_failed(unsafe=True)\n",
    "# print(trial)\n",
    "# ax_client.save_to_json_file(ax_snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4a184b8-3f2b-48cf-9e07-c8f97dd23ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial 0 ---\n",
      "WandB run ID: qksjhpot\n",
      "WandB run name: 2023-10-04 15:26:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sgmustadio\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:148: UserWarning:\n",
      "\n",
      "You have specified a mini-batch size of 4096, but because the `RolloutBuffer` is of size `n_steps * n_envs = 64`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=64 and n_envs=1)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Perform trial\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m avg_ep_rew \u001b[38;5;241m=\u001b[39m \u001b[43mdo_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_hparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m ax_client\u001b[38;5;241m.\u001b[39mcomplete_trial(\n\u001b[0;32m     16\u001b[0m     trial_index\u001b[38;5;241m=\u001b[39mtrial_index,\n\u001b[0;32m     17\u001b[0m     raw_data\u001b[38;5;241m=\u001b[39mavg_ep_rew,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Save experiment snapshot\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[44], line 76\u001b[0m, in \u001b[0;36mdo_trial\u001b[1;34m(settings, hparams)\u001b[0m\n\u001b[0;32m     64\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m EvalAndSaveCallback(\n\u001b[0;32m     65\u001b[0m     check_freq\u001b[38;5;241m=\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_freq\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     66\u001b[0m     save_dir\u001b[38;5;241m=\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_dir\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m     verbose\u001b[38;5;241m=\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose_test\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     73\u001b[0m )\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Choo choo train\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_to_complete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Get dataframe of run metrics\u001b[39;00m\n\u001b[0;32m     80\u001b[0m history \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mApi()\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39mproject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mhistory()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:259\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 259\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:184\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n\u001b[0;32m    183\u001b[0m callback\u001b[38;5;241m.\u001b[39mupdate_locals(\u001b[38;5;28mlocals\u001b[39m())\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_info_buffer(infos)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:104\u001b[0m, in \u001b[0;36mBaseCallback.on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_calls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:208\u001b[0m, in \u001b[0;36mCallbackList._on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Return False (stop training) if at least one callback returns False\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m continue_training\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m continue_training\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:104\u001b[0m, in \u001b[0;36mBaseCallback.on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_calls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[42], line 52\u001b[0m, in \u001b[0;36mEvalAndSaveCallback._on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_replay_buffer(replay_buffer_path)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Evaluate the agent\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m avg_ep_len, avg_ep_rew, avg_step_time, avg_action_mean, avg_action_std \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps_per_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_tests\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(actual_steps)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m steps | average test length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_ep_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, average test reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_ep_rew\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[41], line 13\u001b[0m, in \u001b[0;36mevaluate_agent\u001b[1;34m(env, model, steps_per_test, num_tests)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Test the agent a number of times\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_tests):\n\u001b[1;32m---> 13\u001b[0m     ep_len, ep_rew, step_time, action_mean, action_std \u001b[38;5;241m=\u001b[39m \u001b[43mtest_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     avg_ep_len \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ep_len\n\u001b[0;32m     15\u001b[0m     avg_ep_rew \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ep_rew\n",
      "Cell \u001b[1;32mIn[40], line 20\u001b[0m, in \u001b[0;36mtest_agent\u001b[1;34m(env, model, max_steps)\u001b[0m\n\u001b[0;32m     17\u001b[0m actions\u001b[38;5;241m.\u001b[39mappend(action)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Perform action, update total reward\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m avg_step_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m timestamp\n\u001b[0;32m     22\u001b[0m ep_rew \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[31], line 100\u001b[0m, in \u001b[0;36mPendulum.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     97\u001b[0m action_list \u001b[38;5;241m=\u001b[39m action_scaled\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Move the stepper motor and wait for a response\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCMD_MOVE_BY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp:\n\u001b[0;32m    102\u001b[0m     \n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# Extract information from controller response\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     status, timestamp, terminated, angles \u001b[38;5;241m=\u001b[39m resp\n",
      "File \u001b[1;32mD:\\Projects\\GitHub\\pendulum-rl\\control_comms.py:249\u001b[0m, in \u001b[0;36mControlComms.step\u001b[1;34m(self, command, action)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# Wait for a response\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 249\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_until\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug_level \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m DebugLevel\u001b[38;5;241m.\u001b[39mDEBUG_ERROR:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\serial\\serialutil.py:663\u001b[0m, in \u001b[0;36mSerialBase.read_until\u001b[1;34m(self, expected, size)\u001b[0m\n\u001b[0;32m    661\u001b[0m timeout \u001b[38;5;241m=\u001b[39m Timeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout)\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 663\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c:\n\u001b[0;32m    665\u001b[0m         line \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m c\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\serial\\serialwin32.py:288\u001b[0m, in \u001b[0;36mSerial.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m read_ok \u001b[38;5;129;01mand\u001b[39;00m win32\u001b[38;5;241m.\u001b[39mGetLastError() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (win32\u001b[38;5;241m.\u001b[39mERROR_SUCCESS, win32\u001b[38;5;241m.\u001b[39mERROR_IO_PENDING):\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SerialException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadFile failed (\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ctypes\u001b[38;5;241m.\u001b[39mWinError()))\n\u001b[1;32m--> 288\u001b[0m result_ok \u001b[38;5;241m=\u001b[39m \u001b[43mwin32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetOverlappedResult\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_port_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_overlapped_read\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result_ok:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m win32\u001b[38;5;241m.\u001b[39mGetLastError() \u001b[38;5;241m!=\u001b[39m win32\u001b[38;5;241m.\u001b[39mERROR_OPERATION_ABORTED:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Choo choo! Perform trials to optimize hyperparameters\n",
    "while True:\n",
    "    \n",
    "    # Get next hyperparameters and end experiment if we've reached max trials\n",
    "    next_hparams, trial_index = ax_client.get_next_trial()\n",
    "    if trial_index >= settings['num_trials']:\n",
    "        break\n",
    "        \n",
    "    # Show that we're starting a new trial\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(f\"--- Trial {trial_index} ---\")\n",
    "        \n",
    "    # Perform trial\n",
    "    avg_ep_rew = do_trial(settings, next_hparams)\n",
    "    ax_client.complete_trial(\n",
    "        trial_index=trial_index,\n",
    "        raw_data=avg_ep_rew,\n",
    "    )\n",
    "    \n",
    "    # Save experiment snapshot\n",
    "    ax_client.save_to_json_file(ax_snapshot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1dc72-fc2e-4b2f-8f55-7c83978d67d9",
   "metadata": {},
   "source": [
    "## Analyze Top Performing Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a823a-2a29-4da1-9f07-8e8fdb99c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get runs in WandB project\n",
    "runs = wandb.Api().runs(settings['wandb_project'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b848830-72fe-42aa-b860-0542ce4164f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot best average episode reward from each run over time\n",
    "avg_rews = []\n",
    "for i, run in enumerate(runs):\n",
    "    avg_rew = run.summary['Average test episode reward']\n",
    "    if isinstance(avg_rew, float):\n",
    "        avg_rews.append(avg_rew)\n",
    "avg_rews.reverse()\n",
    "plt.plot(avg_rews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859de2a9-09c9-4d5f-b22a-53598098d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file path\n",
    "csv_file_path = os.path.join(\".\", settings['wandb_project'] + \".csv\")\n",
    "\n",
    "# List summary names\n",
    "summary_names = [\n",
    "    \"Average test episode reward\",\n",
    "    \"Average test episode length\",\n",
    "    \"Average test step time\",\n",
    "]\n",
    "\n",
    "# Get hyperparameter names\n",
    "hparam_names = [hparam['name'] for hparam in hparams]\n",
    "\n",
    "print()\n",
    "\n",
    "# Create CSV with HPO trial results\n",
    "with open(csv_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"name\"] + summary_names + hparam_names)\n",
    "    for run in runs:\n",
    "        row = [run.name]\n",
    "        for name in summary_names:\n",
    "            row.append(run.summary[name])\n",
    "        for name in hparam_names:\n",
    "            row.append(run.config[name])\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dadaee-9b34-4fa4-bd19-71261541b871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
