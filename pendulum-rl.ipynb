{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4561acc1-bea2-4e8b-8342-e1de5391f578",
   "metadata": {},
   "source": [
    "TODO:\n",
    " * Stepper motor skipping steps--more current (better power supply)?\n",
    " * Set up experiments (WandB?)\n",
    " * Train!\n",
    " * Normalize action and observation spaces (see: https://ai.stackexchange.com/questions/21477/why-do-we-also-need-to-normalize-the-actions-values-on-continuous-action-spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37363014-d5bd-4d0b-8093-ad182644070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install gymnasium==0.28.1\n",
    "# !python -m pip install stable-baselines3[extra]==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6601a351-afc4-4ad6-8119-335dce1392cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gym version: 0.28.1\n",
      "sb3 version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from control_comms import ControlComms, StatusCode, DebugLevel\n",
    "\n",
    "# Reinforcement model modules\n",
    "import stable_baselines3 as sb3\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import KVWriter, Logger\n",
    "\n",
    "# Check versions\n",
    "print(f\"gym version: {gym.__version__}\")\n",
    "print(f\"sb3 version: {sb3.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5512c5e3-f346-4866-be07-c9f275fc1b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communication settings\n",
    "SERIAL_PORT = \"COM6\"    # Check your devices\n",
    "BAUD_RATE = 500000      # Must match what's in the Arduino code!\n",
    "CTRL_TIMEOUT = 1.0      # Seconds\n",
    "DEBUG_LEVEL = DebugLevel.DEBUG_ERROR\n",
    "\n",
    "# Reinforcement learning settings\n",
    "K_T = 1                 # Reward constant to multiply theta (angle of encoder)\n",
    "K_DT = 0.1              # Reward constant to multiply dtheto/dt (angular velocity of encoder)\n",
    "K_P = 0.01              # Reward constant to multiply phi (angle of stepper)\n",
    "K_DP = 0.001            # Reward constant to multiply dphi/dt (angular velocity of stepper)\n",
    "REWARD_OOB = -10_000    # Reward (penalty) for having the stepper motor move out of bounds (OOB)\n",
    "ENC_OFFSET = 180.0      # Pendulum in the \"up\" position should be 0 deg\n",
    "STP_MOVE_MIN = -10.0\n",
    "STP_MOVE_MAX = 10.0\n",
    "STP_ANGLE_MIN = -180.0  # Episode ends if stepper goes beyond this angle\n",
    "STP_ANGLE_MAX = 180.0   # Episode ends if stepper goes beyond this angle\n",
    "ENV_TIMEOUT = 10.0\n",
    "RESET_SETTLE_TIME = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "631b6b53-ca9c-41c4-858c-581fcfbbe524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communication constants\n",
    "CMD_SET_HOME = 0        # Set current stepper position as home (0 deg)\n",
    "CMD_MOVE_TO = 1         # Move stepper to a particular position (deg)\n",
    "CMD_MOVE_BY = 2         # Move stepper by a given amount (deg)\n",
    "CMD_SET_STEP_MODE = 3   # Set step mode\n",
    "CMD_SET_BLOCK_MODE = 4  # Set blocking mode\n",
    "CMD_NOP = 5             # Take no action, just receive observation\n",
    "STEP_MODE_1 = 0         # 1 division per step\n",
    "STEP_MODE_2 = 1         # 2 divisions per step\n",
    "STEP_MODE_4 = 2         # 4 divisions per step\n",
    "STEP_MODE_8 = 3         # 8 divisions per step\n",
    "STEP_MODE_16 = 4        # 16 divisions per step\n",
    "STATUS_OK = 0           # Stepper idle\n",
    "STATUS_STP_MOVING = 1   # Stepper is currently moving\n",
    "\n",
    "# Set to desired step mode\n",
    "STEP_MODE = STEP_MODE_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "316bc585-a495-4ad3-ae94-6b0930a38bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection to Arduino board (if open)\n",
    "try:\n",
    "    controller.close()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6f5fef-12a0-405f-972a-fc6eb40b2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Arduino board\n",
    "controller = ControlComms(timeout=CTRL_TIMEOUT, debug_level=DEBUG_LEVEL)\n",
    "ret = controller.connect(SERIAL_PORT, BAUD_RATE)\n",
    "if ret is not StatusCode.OK:\n",
    "    print(\"ERROR: Could not connect to board\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f80790-322b-498b-bef8-211d8a2696d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 448581, False, [0.0, 0.22])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test basic comms\n",
    "controller.step(CMD_SET_STEP_MODE, [STEP_MODE_8])\n",
    "controller.step(CMD_SET_HOME, [0])\n",
    "controller.step(CMD_SET_BLOCK_MODE, [1])\n",
    "controller.step(CMD_MOVE_BY, [90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c07c94e-8ab6-490f-b856-ca817352049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close comms\n",
    "controller.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9cd180-65fe-40f2-88bf-e584bdbbd2cd",
   "metadata": {},
   "source": [
    "## Build gym Environment\n",
    "\n",
    "Subclass gymnasium.Env to create a custom environment. Learn more here:<br>\n",
    "https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32bcddaa-b899-4cab-9a7b-82bd214c3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pendulum(gym.Env):\n",
    "    \"\"\"\n",
    "    Subclass gymnasium Env class\n",
    "    \n",
    "    This is the gym wrapper class that allows our agent to interact with our environment. We need\n",
    "    to implement four main methods: step(), reset(), render(), and close(). We should also define\n",
    "    the action_space and observation space as class members.\n",
    "    \n",
    "    Note: on Windows, time.sleep() is only accurate to around 10ms. As a result, setting fps_limit\n",
    "    will give you a \"best effort\" limit.\n",
    "    \n",
    "    More information: https://gymnasium.farama.org/api/env/\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        serial_port,\n",
    "        baud_rate,\n",
    "        ctrl_timeout=1.0,\n",
    "        debug_level=DebugLevel.DEBUG_NONE,\n",
    "        env_timeout=0.0, \n",
    "        stp_mode=STEP_MODE_8, \n",
    "        stp_blocking=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Set up the environment, action, and observation shapes. Optional tiemout in seconds.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Call superclass's constructor\n",
    "        super().__init__()\n",
    "        \n",
    "        # Connect to Arduino board\n",
    "        self.ctrl = ControlComms(timeout=ctrl_timeout, debug_level=debug_level)\n",
    "        try:\n",
    "            self.ctrl.close()\n",
    "        except:\n",
    "            pass\n",
    "        ret = self.ctrl.connect(serial_port, baud_rate)\n",
    "        if ret is not StatusCode.OK:\n",
    "            print(\"ERROR: Could not connect to board\")\n",
    "        \n",
    "        # Define action space (scalar signifying how many degrees to move stepper by)\n",
    "        self.action_space = gym.spaces.Box(\n",
    "            low=STP_MOVE_MIN,\n",
    "            high=STP_MOVE_MAX,\n",
    "            shape=(1, 1),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Define observation space \n",
    "        # [encoder angle, encoder angular velocity, stepper angle, stepper angular velocity]\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=np.array([-180, -np.inf, STP_ANGLE_MIN, -np.inf]),\n",
    "            high=np.array([180, np.inf, STP_ANGLE_MAX, np.inf]),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Record time from microcontroller and own elapsed time\n",
    "        self.timestamp = 0\n",
    "        self.timeout = env_timeout\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # Record previous encoder and stepper angles (to calculate velocities)\n",
    "        self.angle_stp_prev = 0\n",
    "        self.angle_enc_prev = 0\n",
    "        \n",
    "        # Set current stepper position as \"home\" and optionally set blocking\n",
    "        self.ctrl.step(CMD_SET_STEP_MODE, [stp_mode])\n",
    "        self.ctrl.step(CMD_SET_HOME, [0])\n",
    "        if stp_blocking:\n",
    "            self.ctrl.step(CMD_SET_BLOCK_MODE, [1])\n",
    "        else:\n",
    "            self.ctrl.step(CMD_SET_BLOCK_MODE, [0])\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"\n",
    "        Destructor: make sure to close the serial port\n",
    "        \"\"\"\n",
    "        self.close()\n",
    "    \n",
    "    def step(self, action: np.ndarray):\n",
    "        \"\"\"\n",
    "        What happens when you tell the stepper motor to do something then record the observation.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize return values\n",
    "        obs = np.array([0.0, 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "        reward = 0.0\n",
    "        info = {\"error\": False, \"dtime\": 0.0, \"elapesed_time\": 0.0}\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        \n",
    "        # Box is 2D NumPy array, action must be sent out as 1D list [...]\n",
    "        action_list = action.flatten().tolist()\n",
    "        \n",
    "        # Move the stepper motor and wait for a response\n",
    "        resp = self.ctrl.step(CMD_MOVE_BY, action_list)\n",
    "        if resp:\n",
    "            status, timestamp, terminated, angles = resp\n",
    "            \n",
    "            # Compute lapsed time from previous observation\n",
    "            info[\"dtime\"] = timestamp - self.timestamp\n",
    "            self.timestamp = timestamp\n",
    "            \n",
    "            # Calculate velocities\n",
    "            dtheta = (angles[0] - self.angle_enc_prev) / info[\"dtime\"]\n",
    "            dphi = (angles[1] - self.angle_stp_prev) / info[\"dtime\"]\n",
    "            \n",
    "            # Construct observation\n",
    "            obs[0] = angles[0] - ENC_OFFSET\n",
    "            obs[1] = dtheta\n",
    "            obs[2] = angles[1]\n",
    "            obs[3] = dphi\n",
    "                    \n",
    "            # Calculate reward\n",
    "            if (obs[2] >= STP_ANGLE_MIN) and (obs[2] <= STP_ANGLE_MAX):\n",
    "                reward = -1 * (K_T * obs[0] ** 2 + \n",
    "                               K_DT * obs[1] ** 2 + \n",
    "                               K_P * obs[2] ** 2 +\n",
    "                               K_DP * obs[3] ** 2)\n",
    "            \n",
    "            # Stepper motor is out of bounds--terminate episode\n",
    "            else:\n",
    "                reward = REWARD_OOB\n",
    "                terminated = True\n",
    "        \n",
    "        # Something is wrong with communication\n",
    "        else:\n",
    "            print(\"ERROR: Could not communicate with Arduino\")\n",
    "            info[\"error\"] = True\n",
    "            terminated = True\n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        info[\"elapsed_time\"] = time.time() - self.start_time\n",
    "        \n",
    "        # Check if we've exceeded the time limit\n",
    "        if not terminated and self.timeout > 0.0 and info[\"elapsed_time\"] >= self.timeout:\n",
    "            truncated = True\n",
    "        \n",
    "        return obs, reward, terminated, truncated, info\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        \"\"\"\n",
    "        Return the pendulum to the starting position\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize return values\n",
    "        obs = np.array([0.0, 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "        info = {\"error\": False, \"dtime\": 0, \"elapsed_time\": 0.0}\n",
    "        \n",
    "        # Reset timer\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # Let the pendulum fall and return to the starting position\n",
    "        time.sleep(RESET_SETTLE_TIME)\n",
    "        resp = self.ctrl.step(CMD_MOVE_TO, [0.0])\n",
    "        if resp:\n",
    "            status, timestamp, terminated, angles = resp\n",
    "            \n",
    "            # Compute lapsed time from previous observation\n",
    "            info[\"dtime\"] = timestamp - self.timestamp\n",
    "            self.timestamp = timestamp\n",
    "            \n",
    "            # Calculate velocities\n",
    "            dtheta = (angles[0] - self.angle_enc_prev) / info[\"dtime\"]\n",
    "            dphi = (angles[1] - self.angle_stp_prev) / info[\"dtime\"]\n",
    "            \n",
    "            # Construct observation\n",
    "            obs[0] = angles[0] - ENC_OFFSET\n",
    "            obs[1] = dtheta\n",
    "            obs[2] = angles[1]\n",
    "            obs[3] = dphi\n",
    "            time.sleep(RESET_SETTLE_TIME)\n",
    "            \n",
    "        # Something is wrong with communication\n",
    "        else:\n",
    "            print(\"ERROR: Could not communicate with Arduino\")\n",
    "            info[\"error\"] = True\n",
    "            \n",
    "        # Calculate elapsed time\n",
    "        info[\"elapsed_time\"] = time.time() - self.start_time\n",
    "        \n",
    "        return obs, info\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close connection to Arduino\n",
    "        \"\"\"\n",
    "        self.ctrl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac966999-8595-4e98-8a34-60ad251ce69c",
   "metadata": {},
   "source": [
    "## Test gym Environment\n",
    "\n",
    "Test the gym wrapper before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79b6c823-05f7-4368-815d-353bd1acf23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our environment\n",
    "try:\n",
    "    env.close()\n",
    "except:\n",
    "    pass\n",
    "env = Pendulum(\n",
    "        SERIAL_PORT,\n",
    "        BAUD_RATE,\n",
    "        ctrl_timeout=CTRL_TIMEOUT,\n",
    "        debug_level=DEBUG_LEVEL,\n",
    "        env_timeout=ENV_TIMEOUT, \n",
    "        stp_mode=STEP_MODE, \n",
    "        stp_blocking=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "656213f8-6fa8-4a41-828a-0761a601b384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step   |           Observation            |      Reward      |   Done   | Info\n",
      " Reset   | 176.10, 0.00, 0.00, 0.00         | 0.0              |  False   | {'error': False, 'dtime': 486453, 'elapsed_time': 2.0251104831695557}\n",
      "   0     | 178.20, 0.32, 0.00, 0.00         | -31755.25        |  False   | {'error': False, 'dtime': 1119, 'elapesed_time': 0.0, 'elapsed_time': 2.1230835914611816}\n",
      "   1     | -159.90, 0.20, -24.97, -0.25     | -25574.25        |  False   | {'error': False, 'dtime': 99, 'elapesed_time': 0.0, 'elapsed_time': 2.2191572189331055}\n",
      "   2     | -144.90, 0.36, -49.95, -0.51     | -21020.97        |  False   | {'error': False, 'dtime': 97, 'elapesed_time': 0.0, 'elapsed_time': 2.315276622772217}\n",
      "   3     | -140.10, 0.40, -74.93, -0.76     | -19684.17        |  False   | {'error': False, 'dtime': 99, 'elapesed_time': 0.0, 'elapsed_time': 2.412757158279419}\n",
      "   4     | -147.00, 0.34, -99.90, -1.02     | -21708.81        |  False   | {'error': False, 'dtime': 98, 'elapesed_time': 0.0, 'elapsed_time': 2.50752329826355}\n",
      "   5     | -160.80, 0.20, -124.87, -1.31    | -26012.57        |  False   | {'error': False, 'dtime': 95, 'elapesed_time': 0.0, 'elapsed_time': 2.6038126945495605}\n",
      "   6     | 179.70, 3.67, -149.85, -1.53     | -32517.99        |  False   | {'error': False, 'dtime': 98, 'elapesed_time': 0.0, 'elapsed_time': 2.6979176998138428}\n",
      "   7     | 162.00, 3.60, -174.83, -1.84     | -26550.95        |  False   | {'error': False, 'dtime': 95, 'elapesed_time': 0.0, 'elapsed_time': 2.792154550552368}\n",
      "   8     | 149.70, 3.47, -199.80, -2.10     | -10000.00        |   True   | {'error': False, 'dtime': 95, 'elapesed_time': 0.0, 'elapsed_time': 2.8862593173980713}\n",
      "Episode done\n"
     ]
    }
   ],
   "source": [
    "# Try running the environment for a few steps\n",
    "obs, info = env.reset()\n",
    "obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "if info[\"error\"]:\n",
    "    print(\"Stopping\")\n",
    "else:\n",
    "    print(f\"{'Step': ^8} | {'Observation': ^32} | {'Reward': ^16} | {'Done': ^8} | Info\")\n",
    "    print(f\"{'Reset': ^8} | {obs_str: <32} | {0.0: <16} | {str(False): ^8} | {info}\")\n",
    "    for i in range(10):\n",
    "        obs, reward, terminated, truncated, info = env.step(np.array([[-25]]))\n",
    "        obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "        print(f\"{i: ^8} | {obs_str: <32} | {reward: <16.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "        if info[\"error\"]:\n",
    "            print(\"Stopping\")\n",
    "            break\n",
    "        if terminated or truncated:\n",
    "            print(\"Episode done\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3b1cc85-0cc9-496e-93ba-4f670de7c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode done\n"
     ]
    }
   ],
   "source": [
    "# Test timeout\n",
    "obs, info = env.reset()\n",
    "action = 2\n",
    "if not info[\"error\"]:\n",
    "    for _ in range(1000):\n",
    "        action = -2 if action == 2 else 2\n",
    "        obs, reward, terminated, truncated, info = env.step(np.array([[action]]))\n",
    "        if terminated or truncated:\n",
    "            print(\"Episode done\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75c8710f-6a1b-4e54-ab1c-82cbc4d73080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final environment check to make sure it works with Stable-Baselines3\n",
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f593d48-dacf-424b-ae3c-531b2d5914c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a13f9-7fd8-41b8-a132-7ba226d43345",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74f6d7db-4f12-400a-b61e-b726e8f028a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that tests the model in the given environment\n",
    "def test_model(env, model):\n",
    "\n",
    "    # Reset environment\n",
    "    obs, info = env.reset()\n",
    "    ep_len = 0\n",
    "    ep_rew = 0\n",
    "\n",
    "    # Run episode until complete\n",
    "    while True:\n",
    "\n",
    "        # Provide observation to policy to predict the next action\n",
    "        action, _ = model.predict(obs)\n",
    "\n",
    "        # Perform action, update total reward\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        ep_rew += reward\n",
    "\n",
    "        # Increase step counter\n",
    "        ep_len += 1\n",
    "\n",
    "        # Check to see if episode has ended\n",
    "        if terminated or truncated:\n",
    "            return ep_len, ep_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "633eb05f-9a85-4573-83ad-cf711c9c2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "# PPO docs: https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html\n",
    "# Policy networks: https://stable-baselines.readthedocs.io/en/master/modules/policies.html\n",
    "# Hyperparameters from: https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml\n",
    "model = sb3.PPO(\n",
    "    'MlpPolicy',\n",
    "    env,\n",
    "    learning_rate=0.001,       # Learning rate of neural network (default: 0.0003)\n",
    "    n_steps=1024,               # Number of steps per update (default: 2048)\n",
    "    batch_size=64,              # Minibatch size for NN update (default: 64)\n",
    "    gamma=0.9,                 # Discount factor (default: 0.99)\n",
    "    ent_coef=0.0,               # Entropy, how much to explore (default: 0.0)\n",
    "    use_sde=True,               # Use generalized State Dependent Exploration (default: False)\n",
    "    sde_sample_freq=4,          # Number of steps before sampling new noise matrix (default -1)\n",
    "    policy_kwargs={'net_arch': [64, 64]}, # 2 hidden layers, 1 output layer (default: [64, 64])\n",
    "    verbose=0                   # Print training metrics (default: 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3974f14f-45d3-4a86-90ae-f8df2a9baef4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m avg_ep_rew \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_TESTS_PER_ROUND):\n\u001b[1;32m---> 22\u001b[0m     ep_len, ep_rew \u001b[38;5;241m=\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     avg_ep_len \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ep_len\n\u001b[0;32m     24\u001b[0m     avg_ep_rew \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ep_rew\n",
      "Cell \u001b[1;32mIn[23], line 16\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(env, model)\u001b[0m\n\u001b[0;32m     13\u001b[0m action, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Perform action, update total reward\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m ep_rew \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Increase step counter\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 97\u001b[0m, in \u001b[0;36mPendulum.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     94\u001b[0m action_list \u001b[38;5;241m=\u001b[39m action\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Move the stepper motor and wait for a response\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCMD_MOVE_BY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp:\n\u001b[0;32m     99\u001b[0m     status, timestamp, terminated, angles \u001b[38;5;241m=\u001b[39m resp\n",
      "File \u001b[1;32mD:\\Projects\\GitHub\\pendulum-rl\\control_comms.py:247\u001b[0m, in \u001b[0;36mControlComms.step\u001b[1;34m(self, command, action)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# Wait for a response\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 247\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_until\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug_level \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m DebugLevel\u001b[38;5;241m.\u001b[39mDEBUG_ERROR:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\serial\\serialutil.py:663\u001b[0m, in \u001b[0;36mSerialBase.read_until\u001b[1;34m(self, expected, size)\u001b[0m\n\u001b[0;32m    661\u001b[0m timeout \u001b[38;5;241m=\u001b[39m Timeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout)\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 663\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c:\n\u001b[0;32m    665\u001b[0m         line \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m c\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\serial\\serialwin32.py:274\u001b[0m, in \u001b[0;36mSerial.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    272\u001b[0m flags \u001b[38;5;241m=\u001b[39m win32\u001b[38;5;241m.\u001b[39mDWORD()\n\u001b[0;32m    273\u001b[0m comstat \u001b[38;5;241m=\u001b[39m win32\u001b[38;5;241m.\u001b[39mCOMSTAT()\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mwin32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClearCommError\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_port_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomstat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SerialException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClearCommError failed (\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ctypes\u001b[38;5;241m.\u001b[39mWinError()))\n\u001b[0;32m    276\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(comstat\u001b[38;5;241m.\u001b[39mcbInQue, size) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m size\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training and testing hyperparameters\n",
    "NUM_ROUNDS = 20\n",
    "NUM_TRAINING_STEPS_PER_ROUND = 5000\n",
    "NUM_TESTS_PER_ROUND = 100\n",
    "MODEL_FILENAME_BASE = \"inverted-pendulum-ppo\"\n",
    "\n",
    "# Train and test the model for a number of rounds\n",
    "avg_ep_lens = []\n",
    "avg_ep_rews = []\n",
    "for rnd in range(NUM_ROUNDS):\n",
    "\n",
    "    # Train the model\n",
    "    model.learn(total_timesteps=NUM_TRAINING_STEPS_PER_ROUND)\n",
    "\n",
    "    # Save the model\n",
    "    model.save(f\"{MODEL_FILENAME_BASE}_{rnd}\")\n",
    "\n",
    "    # Test the model in several episodes\n",
    "    avg_ep_len = 0\n",
    "    avg_ep_rew = 0\n",
    "    for ep in range(NUM_TESTS_PER_ROUND):\n",
    "        ep_len, ep_rew = test_model(env, model)\n",
    "        avg_ep_len += ep_len\n",
    "        avg_ep_rew += ep_rew\n",
    "\n",
    "    # Record and dieplay average episode length and reward\n",
    "    avg_ep_len /= NUM_TESTS_PER_ROUND\n",
    "    avg_ep_lens.append(avg_ep_len)\n",
    "    avg_ep_rew /= NUM_TESTS_PER_ROUND\n",
    "    avg_ep_rews.append(avg_ep_rew)\n",
    "    print(f\"Round {rnd} | average test length: {avg_ep_len}, average test reward: {avg_ep_rew}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b3fb4-2186-425e-8079-a54735dde9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
