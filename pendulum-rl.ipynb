{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4561acc1-bea2-4e8b-8342-e1de5391f578",
   "metadata": {},
   "source": [
    "TODO:\n",
    " * Stepper motor skipping steps--more current (better power supply)?\n",
    " * Normalize action and observation spaces (see: https://ai.stackexchange.com/questions/21477/why-do-we-also-need-to-normalize-the-actions-values-on-continuous-action-spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37363014-d5bd-4d0b-8093-ad182644070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install gymnasium==0.28.1\n",
    "# !python -m pip install stable-baselines3[extra]==2.1.0\n",
    "# !python -m pip install ax-platform==0.3.4\n",
    "# !python -m pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ed8b9b-73a0-4c11-9c12-4bbd6b0debfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.0.0\n",
      "gymnasium version: 0.28.1\n",
      "sb3 version: 2.1.0\n",
      "cv2 version: 4.7.0.68\n",
      "ax version: 0.3.4\n"
     ]
    }
   ],
   "source": [
    "# Check versions\n",
    "import importlib.metadata\n",
    "\n",
    "print(f\"torch version: {importlib.metadata.version('torch')}\")\n",
    "print(f\"gymnasium version: {importlib.metadata.version('gymnasium')}\")\n",
    "print(f\"sb3 version: {importlib.metadata.version('stable-baselines3')}\")\n",
    "print(f\"cv2 version: {importlib.metadata.version('opencv-python')}\")\n",
    "print(f\"ax version: {importlib.metadata.version('ax-platform')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6601a351-afc4-4ad6-8119-335dce1392cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Standard Library\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "import math\n",
    "import csv\n",
    "from typing import Any, Dict, Tuple, Union\n",
    "\n",
    "# Encoder and stepper controls (local)\n",
    "from control_comms import ControlComms, StatusCode, DebugLevel\n",
    "\n",
    "# Third-party packages\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "# Reinforcement model modules\n",
    "import stable_baselines3 as sb3\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import KVWriter, Logger\n",
    "\n",
    "# Meta Ax\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render\n",
    "from ax.utils.tutorials.cnn_utils import train, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002868a4-1404-46fb-88a0-80adf9ee9dc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5512c5e3-f346-4866-be07-c9f275fc1b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communication settings\n",
    "SERIAL_PORT = \"COM4\"    # Check your devices\n",
    "BAUD_RATE = 1_000_000   # Must match what's in the Arduino code!\n",
    "CTRL_TIMEOUT = 2.0      # Seconds\n",
    "DEBUG_LEVEL = DebugLevel.DEBUG_ERROR\n",
    "\n",
    "# Reinforcement learning settings\n",
    "K_T = 1                 # Reward constant to multiply theta (angle of encoder)\n",
    "K_DT = 0.01             # Reward constant to multiply dtheto/dt (angular velocity of encoder)\n",
    "K_P = 0.001             # Reward constant to multiply phi (angle of stepper)\n",
    "K_DP = 0.00001           # Reward constant to multiply dphi/dt (angular velocity of stepper)\n",
    "REWARD_OOB = -500       # Reward (penalty) for ha ving the stepper motor move out of bounds (OOB)\n",
    "ENC_ANGLE_NORM = 180    # Divide by this to normalize +/-180 deg angle to +/-1\n",
    "STP_ACTION_MULT = 30    # Action space is normalized to [-1, 1], multiply by this to get actual action\n",
    "STP_ANGLE_MIN = -180    # Episode ends if stepper goes beyond this angle\n",
    "STP_ANGLE_MAX = 180     # Episode ends if stepper goes beyond this angle\n",
    "STP_ANGLE_NORM = 180    # Divide by this to normalize +/-180 deg angle to +/-1\n",
    "\n",
    "ENV_TIMEOUT = 30.0\n",
    "RESET_SETTLE_TIME = 2.0 # Seconds to wait after reset to start moving again\n",
    "\n",
    "# Angle constants\n",
    "ENC_OFFSET = 180.0      # Pendulum in the \"up\" position should be 0 deg\n",
    "ANG_REV = 360           # Degrees in a single revolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631b6b53-ca9c-41c4-858c-581fcfbbe524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communication constants\n",
    "CMD_SET_HOME = 0        # Set current stepper position as home (0 deg)\n",
    "CMD_MOVE_TO = 1         # Move stepper to a particular position (deg)\n",
    "CMD_MOVE_BY = 2         # Move stepper by a given amount (deg)\n",
    "CMD_SET_STEP_MODE = 3   # Set step mode\n",
    "CMD_SET_BLOCK_MODE = 4  # Set blocking mode\n",
    "CMD_NOP = 5             # Take no action, just receive observation\n",
    "STEP_MODE_1 = 0         # 1 division per step\n",
    "STEP_MODE_2 = 1         # 2 divisions per step\n",
    "STEP_MODE_4 = 2         # 4 divisions per step\n",
    "STEP_MODE_8 = 3         # 8 divisions per step\n",
    "STEP_MODE_16 = 4        # 16 divisions per step\n",
    "STATUS_OK = 0           # Stepper idle\n",
    "STATUS_STP_MOVING = 1   # Stepper is currently moving\n",
    "\n",
    "# Set to desired step mode\n",
    "STEP_MODE = STEP_MODE_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00724565-b597-4c6a-a8fd-9dec4114949b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "316bc585-a495-4ad3-ae94-6b0930a38bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection to Arduino board (if open)\n",
    "try:\n",
    "    controller.close()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd6f5fef-12a0-405f-972a-fc6eb40b2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Arduino board\n",
    "controller = ControlComms(timeout=CTRL_TIMEOUT, debug_level=DEBUG_LEVEL)\n",
    "ret = controller.connect(SERIAL_PORT, BAUD_RATE)\n",
    "if ret is not StatusCode.OK:\n",
    "    print(\"ERROR: Could not connect to board\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61f80790-322b-498b-bef8-211d8a2696d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 102872, False, [357.9, 0.0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test basic comms\n",
    "controller.step(CMD_SET_STEP_MODE, [STEP_MODE_8])\n",
    "controller.step(CMD_SET_HOME, [0])\n",
    "controller.step(CMD_SET_BLOCK_MODE, [1])\n",
    "controller.step(CMD_MOVE_BY, [-25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef863618-7b2e-464f-9da1-f4f1f957d0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 102989, False, [3.9, -24.3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy test\n",
    "action = np.array([[-25]])\n",
    "action_list = action.flatten().tolist()\n",
    "controller.step(CMD_MOVE_BY, action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eeb8708-c488-42c6-8b2d-a6026fe9ea46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 103137, False, [353.7, -48.6])\n",
      "(0, 103387, False, [358.5, 1.8])\n",
      "(0, 103626, False, [336.9, 52.2])\n",
      "(0, 103865, False, [328.5, 102.6])\n",
      "(0, 104118, False, [359.7, 153.0])\n",
      "(0, 104356, False, [0.3, 203.4])\n",
      "(0, 104607, False, [321.9, 253.8])\n",
      "(0, 104859, False, [332.7, 304.2])\n",
      "(0, 104977, False, [2.7, 354.6])\n",
      "(0, 105102, False, [343.2, 354.6])\n",
      "(0, 105227, False, [3.6, 354.6])\n",
      "(0, 105353, False, [349.2, 354.6])\n",
      "(0, 105480, False, [354.9, 354.6])\n",
      "(0, 105606, False, [356.1, 354.6])\n",
      "(0, 105731, False, [352.2, 354.6])\n",
      "(0, 105858, False, [359.7, 354.6])\n",
      "(0, 105984, False, [353.4, 354.6])\n",
      "(0, 106094, False, [1.8, 354.6])\n",
      "(0, 106219, False, [354.0, 354.6])\n",
      "(0, 106331, False, [0.9, 354.6])\n"
     ]
    }
   ],
   "source": [
    "# Test hard limit (360 deg)\n",
    "for i in range(20):\n",
    "    resp = controller.step(CMD_MOVE_BY, [50])\n",
    "    print(resp)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c323e9db-1363-431f-8bae-9d44c0a03085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 106846, False, [359.4, 354.6])\n",
      "(0, 109137, False, [359.4, 0.0])\n",
      "(0, 109428, False, [347.1, -179.1])\n",
      "(0, 109719, False, [8.4, 0.9])\n",
      "(0, 110007, False, [353.1, -178.2])\n",
      "(0, 110300, False, [352.5, 1.8])\n",
      "(0, 110587, False, [4.5, -177.3])\n",
      "(0, 110879, False, [358.8, 2.7])\n",
      "(0, 111171, False, [354.3, -176.4])\n",
      "(0, 111472, False, [4.2, 3.6])\n",
      "(0, 111759, False, [356.7, -175.5])\n"
     ]
    }
   ],
   "source": [
    "# Stress/torque test\n",
    "resp = controller.step(CMD_MOVE_TO, [0])\n",
    "controller.step(CMD_SET_BLOCK_MODE, [1])\n",
    "print(resp)\n",
    "time.sleep(2.0)\n",
    "action = 180\n",
    "for i in range(10):\n",
    "    action = -180 if action == 180 else 180\n",
    "    resp = controller.step(CMD_MOVE_BY, [action])\n",
    "    print(resp)\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cfacfca-7ede-4fc3-a300-083084de93fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comms stress test\n",
    "# resp = controller.step(CMD_MOVE_TO, [0])\n",
    "# print(resp)\n",
    "# time.sleep(2.0)\n",
    "# for i in range(100000):\n",
    "#     resp = controller.step(CMD_MOVE_BY, [0])\n",
    "#     time.sleep(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a35db2c4-96d4-42f2-81f1-4b6a3746e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 111860, False, [335.1, 4.5])\n"
     ]
    }
   ],
   "source": [
    "# Move home\n",
    "resp = controller.step(CMD_MOVE_TO, [0])\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c07c94e-8ab6-490f-b856-ca817352049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close comms\n",
    "controller.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "827948c0-7a81-44e3-81e3-95d5c13eafb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 111899, False, [335.1, 0.0])\n",
      "(0, 111919, False, [337.5, 0.0])\n",
      "(0, 113937, False, [358.5, 0.0])\n",
      "(0, 115999, False, [359.1, 0.0])\n",
      "(0, 116156, False, [2.4, -9.0])\n",
      "(0, 116315, False, [3.0, -18.0])\n",
      "(0, 116472, False, [352.2, -27.0])\n",
      "(0, 116630, False, [2.1, -36.0])\n",
      "(0, 116787, False, [1.5, -45.0])\n",
      "(0, 116944, False, [354.3, -54.0])\n",
      "(0, 117100, False, [1.5, -63.0])\n",
      "(0, 117256, False, [3.0, -72.0])\n",
      "(0, 117414, False, [356.7, -81.0])\n",
      "(0, 117703, False, [0.0, -90.0])\n"
     ]
    }
   ],
   "source": [
    "# Basic step test\n",
    "action = np.array([[-10]])\n",
    "\n",
    "controller = ControlComms(timeout=CTRL_TIMEOUT, debug_level=DEBUG_LEVEL)\n",
    "ret = controller.connect(SERIAL_PORT, BAUD_RATE)\n",
    "if ret is not StatusCode.OK:\n",
    "    print(\"ERROR: Could not connect to board\")\n",
    "\n",
    "resp = controller.step(CMD_SET_BLOCK_MODE, [1])\n",
    "print(resp)\n",
    "resp = controller.step(CMD_SET_BLOCK_MODE, [1])\n",
    "print(resp)\n",
    "    \n",
    "# Reset\n",
    "time.sleep(2.0)\n",
    "resp = controller.step(CMD_MOVE_TO, [0.0])\n",
    "print(resp)\n",
    "time.sleep(2.0)\n",
    "\n",
    "# Loop\n",
    "for i in range(10):\n",
    "    action_list = action.flatten().tolist()\n",
    "    resp = controller.step(CMD_MOVE_BY, action_list)\n",
    "    print(resp)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# Move home and close\n",
    "resp = controller.step(CMD_MOVE_TO, [0])\n",
    "print(resp)\n",
    "controller.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbf62f43-718b-4997-b112-86c364a3f7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshawnhymel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log in to Weights & Biases\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3cce2f0-188f-40af-9282-ea58bb80e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make wandb be quiet\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "logger = logging.getLogger(\"wandb\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1566ff73-1195-4710-bab6-05a8309f7fa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6800b3d-197b-465f-b09b-b451708a16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds(seed: int) -> None:\n",
    "    \"\"\"\n",
    "    Seed the different random generators.\n",
    "    https://stable-baselines3.readthedocs.io/en/master/_modules/stable_baselines3/common/utils.html\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set seed for Python random and NumPy\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9bb2c64-36e7-41cc-9c86-67b35d741ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_angular_velocity(ang, ang_prev, dt):\n",
    "    \"\"\"\n",
    "    Estimate engular velocity based on current and previous readings. Note that we assume that the\n",
    "    object in question cannot go the long way around (e.g. more than 180 deg).\n",
    "    \"\"\"\n",
    "    da = ang - ang_prev\n",
    "    if da > (ANG_REV / 2):\n",
    "        da -= ANG_REV\n",
    "    elif da < -(ANG_REV / 2):\n",
    "        da += ANG_REV\n",
    "    \n",
    "    return da / dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9cd180-65fe-40f2-88bf-e584bdbbd2cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build gym Environment\n",
    "\n",
    "Subclass gymnasium.Env to create a custom environment. Learn more here:<br>\n",
    "https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32bcddaa-b899-4cab-9a7b-82bd214c3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pendulum(gym.Env):\n",
    "    \"\"\"\n",
    "    Subclass gymnasium Env class\n",
    "    \n",
    "    This is the gym wrapper class that allows our agent to interact with our environment. We need\n",
    "    to implement four main methods: step(), reset(), render(), and close(). We should also define\n",
    "    the action_space and observation space as class members.\n",
    "    \n",
    "    Note: on Windows, time.sleep() is only accurate to around 10ms. As a result, setting fps_limit\n",
    "    will give you a \"best effort\" limit.\n",
    "    \n",
    "    More information: https://gymnasium.farama.org/api/env/\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        serial_port,\n",
    "        baud_rate,\n",
    "        ctrl_timeout=1.0,\n",
    "        debug_level=DebugLevel.DEBUG_NONE,\n",
    "        env_timeout=0.0, \n",
    "        stp_mode=STEP_MODE_8, \n",
    "        stp_blocking=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Set up the environment, action, and observation shapes. Optional tiemout in seconds.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Call superclass's constructor\n",
    "        super().__init__()\n",
    "        \n",
    "        # Connect to Arduino board\n",
    "        self.ctrl = ControlComms(timeout=ctrl_timeout, debug_level=debug_level)\n",
    "        try:\n",
    "            self.ctrl.close()\n",
    "        except:\n",
    "            pass\n",
    "        ret = self.ctrl.connect(serial_port, baud_rate)\n",
    "        if ret is not StatusCode.OK:\n",
    "            print(\"ERROR: Could not connect to board\")\n",
    "        \n",
    "        # Define action space (scalar signifying how many degrees to move stepper by)\n",
    "        self.action_space = gym.spaces.Box(\n",
    "            low=-1.0,\n",
    "            high=1.0,\n",
    "            shape=(1, 1),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Define observation space \n",
    "        # [encoder angle, encoder angular velocity, stepper angle, stepper angular velocity]\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=np.array([-180, -np.inf, STP_ANGLE_MIN, -np.inf]),\n",
    "            high=np.array([180, np.inf, STP_ANGLE_MAX, np.inf]),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Record time from microcontroller and own elapsed time\n",
    "        self.timestamp = 0\n",
    "        self.timeout = env_timeout\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # Record previous encoder and stepper angles (to calculate velocities)\n",
    "        self.angle_stp_prev = 0\n",
    "        self.angle_enc_prev = 0\n",
    "        \n",
    "        # Set current stepper position as \"home\" and optionally set blocking\n",
    "        self.ctrl.step(CMD_SET_STEP_MODE, [stp_mode])\n",
    "        self.ctrl.step(CMD_SET_HOME, [0])\n",
    "        if stp_blocking:\n",
    "            self.ctrl.step(CMD_SET_BLOCK_MODE, [1])\n",
    "        else:\n",
    "            self.ctrl.step(CMD_SET_BLOCK_MODE, [0])\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"\n",
    "        Destructor: make sure to close the serial port\n",
    "        \"\"\"\n",
    "        self.close()\n",
    "    \n",
    "    def step(self, action: np.ndarray):\n",
    "        \"\"\"\n",
    "        What happens when you tell the stepper motor to do something then record the observation.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize return values\n",
    "        obs = np.array([0.0, 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "        reward = 0.0\n",
    "        info = {\"error\": False, \"dtime\": 0.0, \"elapsed_time\": 0.0}\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        \n",
    "        # Scale normalized action [-1, 1] to actual action (e.g. [-60, 60])\n",
    "        action_scaled = STP_ACTION_MULT * action\n",
    "        \n",
    "        # Box is 2D NumPy array, action must be sent out as 1D list [...]\n",
    "        action_list = action_scaled.flatten().tolist()\n",
    "        \n",
    "        # Move the stepper motor and wait for a response\n",
    "        resp = self.ctrl.step(CMD_MOVE_BY, action_list)\n",
    "        if resp:\n",
    "            \n",
    "            # Extract information from controller response\n",
    "            status, timestamp, terminated, angles = resp\n",
    "            \n",
    "            # Compute lapsed time (in seconds) from previous observation (milliseconds)\n",
    "            info[\"dtime\"] = (timestamp - self.timestamp) / 1000.0\n",
    "            self.timestamp = timestamp\n",
    "            \n",
    "            # Offset encoder angle so that 0 deg is up\n",
    "            angles[0] -= ENC_OFFSET\n",
    "            \n",
    "            # Calculate velocities\n",
    "            dtheta = calc_angular_velocity(angles[0], self.angle_enc_prev, info['dtime'])\n",
    "            dphi = calc_angular_velocity(angles[1], self.angle_stp_prev, info['dtime'])\n",
    "            self.angle_enc_prev = angles[0]\n",
    "            self.angle_stp_prev = angles[1]\n",
    "            \n",
    "            # Construct observation (normalized)\n",
    "            obs[0] = angles[0] / ENC_ANGLE_NORM\n",
    "            obs[1] = dtheta / ENC_ANGLE_NORM\n",
    "            obs[2] = angles[1] / STP_ANGLE_NORM\n",
    "            obs[3] = dphi / STP_ANGLE_NORM\n",
    "                    \n",
    "            # Calculate reward if stepper is not out of bounds\n",
    "            if (angles[1] >= STP_ANGLE_MIN) and (angles[1] <= STP_ANGLE_MAX):\n",
    "                reward = -1 * (K_T * obs[0] ** 2 + \n",
    "                               K_DT * obs[1] ** 2 + \n",
    "                               K_P * obs[2] ** 2 +\n",
    "                               K_DP * obs[3] ** 2)\n",
    "            \n",
    "            # Stepper motor is out of bounds--terminate episode\n",
    "            else:\n",
    "                reward = REWARD_OOB\n",
    "                terminated = True\n",
    "        \n",
    "        # Something is wrong with communication\n",
    "        else:\n",
    "            print(\"ERROR: Could not communicate with Arduino\")\n",
    "            info[\"error\"] = True\n",
    "            terminated = True\n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        info[\"elapsed_time\"] = time.time() - self.start_time\n",
    "        \n",
    "        # Check if we've exceeded the time limit\n",
    "        if not terminated and self.timeout > 0.0 and info[\"elapsed_time\"] >= self.timeout:\n",
    "            truncated = True\n",
    "        \n",
    "        return obs, reward, terminated, truncated, info\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        \"\"\"\n",
    "        Return the pendulum to the starting position\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize return values\n",
    "        obs = np.array([0.0, 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "        info = {\"error\": False, \"dtime\": 0, \"elapsed_time\": 0.0}\n",
    "        \n",
    "        # Reset timer\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # Let the pendulum fall and return to the starting position\n",
    "        time.sleep(RESET_SETTLE_TIME)\n",
    "        resp = self.ctrl.step(CMD_MOVE_TO, [0.0])\n",
    "        if resp:\n",
    "            \n",
    "            # Extract information from controller response\n",
    "            status, timestamp, terminated, angles = resp\n",
    "            \n",
    "            # Compute lapsed time (in seconds) from previous observation (milliseconds)\n",
    "            info[\"dtime\"] = (timestamp - self.timestamp) / 1000.0\n",
    "            self.timestamp = timestamp\n",
    "            \n",
    "            # Offset encoder angle so that 0 deg is up\n",
    "            angles[0] -= ENC_OFFSET\n",
    "            \n",
    "            # Calculate velocities\n",
    "            dtheta = calc_angular_velocity(angles[0], self.angle_enc_prev, info['dtime'])\n",
    "            dphi = calc_angular_velocity(angles[1], self.angle_stp_prev, info['dtime'])\n",
    "            self.angle_enc_prev = angles[0]\n",
    "            self.angle_stp_prev = angles[1]\n",
    "            \n",
    "            # Construct observation (normalized)\n",
    "            obs[0] = angles[0] / ENC_ANGLE_NORM\n",
    "            obs[1] = dtheta / ENC_ANGLE_NORM\n",
    "            obs[2] = angles[1] / STP_ANGLE_NORM\n",
    "            obs[3] = dphi / STP_ANGLE_NORM\n",
    "            \n",
    "            # Let pendulum settle for a bit\n",
    "            time.sleep(RESET_SETTLE_TIME)\n",
    "            \n",
    "        # Something is wrong with communication\n",
    "        else:\n",
    "            print(\"ERROR: Could not communicate with Arduino\")\n",
    "            info[\"error\"] = True\n",
    "            \n",
    "        # Calculate elapsed time\n",
    "        info[\"elapsed_time\"] = time.time() - self.start_time\n",
    "        \n",
    "        return obs, info\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close connection to Arduino\n",
    "        \"\"\"\n",
    "        self.ctrl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac966999-8595-4e98-8a34-60ad251ce69c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test gym Environment\n",
    "\n",
    "Test the gym wrapper before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79b6c823-05f7-4368-815d-353bd1acf23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our environment\n",
    "try:\n",
    "    env.close()\n",
    "except:\n",
    "    pass\n",
    "env = Pendulum(\n",
    "        SERIAL_PORT,\n",
    "        BAUD_RATE,\n",
    "        ctrl_timeout=CTRL_TIMEOUT,\n",
    "        debug_level=DEBUG_LEVEL,\n",
    "        env_timeout=ENV_TIMEOUT, \n",
    "        stp_mode=STEP_MODE, \n",
    "        stp_blocking=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4449add-5c21-4da2-9669-53e8017c7ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3029297]]\n",
      "[[-0.3660054]]\n",
      "[[0.11550331]]\n",
      "[[-0.8621913]]\n",
      "[[0.79393935]]\n",
      "[[0.14375901]]\n",
      "[[-0.8190681]]\n",
      "[[0.2739601]]\n",
      "[[0.36272833]]\n",
      "[[0.23119523]]\n"
     ]
    }
   ],
   "source": [
    "# Check action space (should be normalized to [-1, 1])\n",
    "for i in range(10):\n",
    "    print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f607dd4c-2858-48d4-a115-97e98a943c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step   |             Observation              |  Reward  |   Done   | Info\n",
      " Reset   | -1.00, -0.04, 0.00, 0.00             | 0.0      |  False   | {'error': False, 'dtime': 26.92, 'elapsed_time': 4.022206783294678}\n",
      "   0     | -1.00, 0.00, 0.00, 0.00              | -1.00    |  False   | {'error': False, 'dtime': 2.018, 'elapsed_time': 4.029207229614258}\n",
      "   1     | -1.00, 0.00, 0.00, 0.00              | -1.00    |  False   | {'error': False, 'dtime': 1.009, 'elapsed_time': 5.043374300003052}\n",
      "   2     | -1.00, 0.00, 0.00, 0.00              | -1.00    |  False   | {'error': False, 'dtime': 1.014, 'elapsed_time': 6.056128263473511}\n",
      "   3     | -1.00, 0.00, 0.00, 0.00              | -1.00    |  False   | {'error': False, 'dtime': 1.016, 'elapsed_time': 7.076892614364624}\n",
      "   4     | -1.00, 0.00, 0.00, 0.00              | -1.00    |  False   | {'error': False, 'dtime': 1.03, 'elapsed_time': 8.106818199157715}\n",
      "   5     | -1.00, 0.00, 0.00, 0.00              | -1.00    |  False   | {'error': False, 'dtime': 1.028, 'elapsed_time': 9.134826183319092}\n",
      "   6     | 0.53, -0.46, 0.00, 0.00              | -0.28    |  False   | {'error': False, 'dtime': 1.025, 'elapsed_time': 10.159421682357788}\n",
      "   7     | 0.90, 0.36, 0.00, 0.00               | -0.81    |  False   | {'error': False, 'dtime': 1.029, 'elapsed_time': 11.189071655273438}\n",
      "   8     | -0.48, 0.60, 0.00, 0.00              | -0.23    |  False   | {'error': False, 'dtime': 1.029, 'elapsed_time': 12.217586755752563}\n",
      "   9     | -0.95, -0.47, 0.00, 0.00             | -0.91    |  False   | {'error': False, 'dtime': 1.022, 'elapsed_time': 13.239590167999268}\n"
     ]
    }
   ],
   "source": [
    "# Test encoder\n",
    "obs, info = env.reset()\n",
    "obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "if info[\"error\"]:\n",
    "    print(\"Stopping\")\n",
    "else:\n",
    "    print(f\"{'Step': ^8} | {'Observation': ^36} | {'Reward': ^8} | {'Done': ^8} | Info\")\n",
    "    print(f\"{'Reset': ^8} | {obs_str: <36} | {0.0: <8} | {str(False): ^8} | {info}\")\n",
    "    for i in range(10):\n",
    "        obs, reward, terminated, truncated, info = env.step(np.array([[0]]))\n",
    "        obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "        print(f\"{i: ^8} | {obs_str: <36} | {reward: <8.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "        if info[\"error\"]:\n",
    "            print(\"Stopping\")\n",
    "            break\n",
    "        if terminated or truncated:\n",
    "            print(\"Episode done\")\n",
    "            break\n",
    "        time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ac5a0e1-d72a-4052-a8db-086fd6d288a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step   |  Action  |             Observation              |  Reward  |   Done   | Info\n",
      " Reset   | 0.0      | -0.95, -0.47, 0.00, 0.00             | 0.0      |  False   | {'error': False, 'dtime': 12.142, 'elapsed_time': 4.040973901748657}\n",
      "   0     | 0.52     | -0.95, -0.47, 0.00, 0.00             | -0.06    |  False   | {'error': False, 'dtime': 2.09, 'elapsed_time': 4.120587110519409}\n",
      "   1     | 0.74     | -0.95, -0.47, 0.00, 0.00             | -0.06    |  False   | {'error': False, 'dtime': 0.101, 'elapsed_time': 4.213994741439819}\n",
      "   2     | -0.41    | -0.95, -0.47, 0.00, 0.00             | -0.08    |  False   | {'error': False, 'dtime': 0.063, 'elapsed_time': 4.279219388961792}\n",
      "   3     | -0.10    | -0.95, -0.47, 0.00, 0.00             | -0.14    |  False   | {'error': False, 'dtime': 0.021, 'elapsed_time': 4.300459384918213}\n",
      "   4     | -0.01    | -0.95, -0.47, 0.00, 0.00             | -0.11    |  False   | {'error': False, 'dtime': 0.015, 'elapsed_time': 4.315528392791748}\n",
      "   5     | -0.30    | -0.95, -0.47, 0.00, 0.00             | -0.08    |  False   | {'error': False, 'dtime': 0.056, 'elapsed_time': 4.373174667358398}\n",
      "   6     | -0.19    | -0.95, -0.47, 0.00, 0.00             | -0.07    |  False   | {'error': False, 'dtime': 0.041, 'elapsed_time': 4.412801027297974}\n",
      "   7     | -0.02    | -0.95, -0.47, 0.00, 0.00             | -0.06    |  False   | {'error': False, 'dtime': 0.015, 'elapsed_time': 4.432503938674927}\n",
      "   8     | -0.63    | -0.95, -0.47, 0.00, 0.00             | -0.03    |  False   | {'error': False, 'dtime': 0.083, 'elapsed_time': 4.515504598617554}\n",
      "   9     | 0.53     | -0.95, -0.47, 0.00, 0.00             | -0.07    |  False   | {'error': False, 'dtime': 0.079, 'elapsed_time': 4.594604253768921}\n",
      "   10    | -0.44    | -0.95, -0.47, 0.00, 0.00             | -0.07    |  False   | {'error': False, 'dtime': 0.069, 'elapsed_time': 4.663339376449585}\n",
      "   11    | -0.44    | -0.95, -0.47, 0.00, 0.00             | -0.12    |  False   | {'error': False, 'dtime': 0.069, 'elapsed_time': 4.732726097106934}\n",
      "   12    | 0.17     | -0.95, -0.47, 0.00, 0.00             | -0.10    |  False   | {'error': False, 'dtime': 0.044, 'elapsed_time': 4.776120901107788}\n",
      "   13    | 0.91     | -0.95, -0.47, 0.00, 0.00             | -0.03    |  False   | {'error': False, 'dtime': 0.103, 'elapsed_time': 4.8741350173950195}\n",
      "   14    | -0.60    | -0.95, -0.47, 0.00, 0.00             | -0.02    |  False   | {'error': False, 'dtime': 0.083, 'elapsed_time': 4.957736253738403}\n",
      "   15    | -0.31    | -0.95, -0.47, 0.00, 0.00             | -0.14    |  False   | {'error': False, 'dtime': 0.056, 'elapsed_time': 5.0179665088653564}\n",
      "   16    | -0.76    | -0.95, -0.47, 0.00, 0.00             | -0.12    |  False   | {'error': False, 'dtime': 0.091, 'elapsed_time': 5.105572938919067}\n",
      "   17    | 0.47     | -0.95, -0.47, 0.00, 0.00             | -0.08    |  False   | {'error': False, 'dtime': 0.07, 'elapsed_time': 5.1746790409088135}\n",
      "   18    | -0.75    | -0.95, -0.47, 0.00, 0.00             | -0.04    |  False   | {'error': False, 'dtime': 0.086, 'elapsed_time': 5.265628814697266}\n",
      "   19    | -0.49    | -0.95, -0.47, 0.00, 0.00             | -0.04    |  False   | {'error': False, 'dtime': 0.078, 'elapsed_time': 5.344796657562256}\n",
      "Action mean: -0.10613566637039185\n",
      "Action std dev: 0.4945122301578522\n",
      "Total reward: -1.5138425556744135\n"
     ]
    }
   ],
   "source": [
    "# Run some random steps\n",
    "actions = []\n",
    "rewards = []\n",
    "obs, info = env.reset()\n",
    "if info[\"error\"]:\n",
    "    print(\"Stopping\")\n",
    "else:\n",
    "    print(f\"{'Step': ^8} | {'Action': ^8} | {'Observation': ^36} | {'Reward': ^8} | {'Done': ^8} | Info\")\n",
    "    print(f\"{'Reset': ^8} | {0.0: <8} | {obs_str: <36} | {0.0: <8} | {str(False): ^8} | {info}\")\n",
    "    for i in range(20):\n",
    "        action = env.action_space.sample()\n",
    "        actions.append(action)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        print(f\"{i: ^8} | {action[0][0]: <8.2f} | {obs_str: <36} | {reward: <8.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "        if info[\"error\"]:\n",
    "            print(\"Stopping\")\n",
    "            break\n",
    "        if terminated or truncated:\n",
    "            print(\"Episode done\")\n",
    "            break\n",
    "\n",
    "# Print stats\n",
    "action_mean = np.mean(np.array(actions))\n",
    "action_std = np.std(np.array(actions))\n",
    "print(f\"Action mean: {action_mean}\")\n",
    "print(f\"Action std dev: {action_std}\")\n",
    "print(f\"Total reward: {sum(rewards)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "656213f8-6fa8-4a41-828a-0761a601b384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step   |             Observation              |  Reward  |   Done   | Info\n",
      " Reset   | -0.07, -0.02, 0.00, 0.00             | 0.0      |  False   | {'error': False, 'dtime': 23.329, 'elapsed_time': 4.034465551376343}\n",
      "   0     | 0.01, 0.04, 0.00, 0.00               | -0.00    |  False   | {'error': False, 'dtime': 2.036, 'elapsed_time': 4.066476106643677}\n",
      "   1     | 0.00, -0.43, 0.01, 0.43              | -0.00    |  False   | {'error': False, 'dtime': 0.035, 'elapsed_time': 4.101035833358765}\n",
      "   2     | 0.00, 0.10, 0.03, 0.43               | -0.00    |  False   | {'error': False, 'dtime': 0.035, 'elapsed_time': 4.136011362075806}\n",
      "   3     | 0.03, 0.86, 0.05, 0.43               | -0.01    |  False   | {'error': False, 'dtime': 0.035, 'elapsed_time': 4.171230316162109}\n",
      "   4     | 0.07, 1.00, 0.06, 0.43               | -0.01    |  False   | {'error': False, 'dtime': 0.035, 'elapsed_time': 4.2063422203063965}\n",
      "   5     | 0.10, 1.00, 0.08, 0.43               | -0.02    |  False   | {'error': False, 'dtime': 0.035, 'elapsed_time': 4.243080377578735}\n",
      "   6     | 0.09, -0.38, 0.09, 0.43              | -0.01    |  False   | {'error': False, 'dtime': 0.035, 'elapsed_time': 4.276158809661865}\n",
      "   7     | 0.09, 0.14, 0.10, 0.43               | -0.01    |  False   | {'error': False, 'dtime': 0.035, 'elapsed_time': 4.311053276062012}\n",
      "   8     | 0.10, 0.10, 0.12, 0.43               | -0.01    |  False   | {'error': False, 'dtime': 0.035, 'elapsed_time': 4.347724914550781}\n",
      "   9     | 0.11, 0.24, 0.14, 0.43               | -0.01    |  False   | {'error': False, 'dtime': 0.035, 'elapsed_time': 4.382918119430542}\n"
     ]
    }
   ],
   "source": [
    "# Try running the environment for a few steps (stepper should move some)\n",
    "obs, info = env.reset()\n",
    "obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "if info[\"error\"]:\n",
    "    print(\"Stopping\")\n",
    "else:\n",
    "    print(f\"{'Step': ^8} | {'Observation': ^36} | {'Reward': ^8} | {'Done': ^8} | Info\")\n",
    "    print(f\"{'Reset': ^8} | {obs_str: <36} | {0.0: <8} | {str(False): ^8} | {info}\")\n",
    "    for i in range(10):\n",
    "        obs, reward, terminated, truncated, info = env.step(np.array([[0.1]]))\n",
    "        obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "        print(f\"{i: ^8} | {obs_str: <36} | {reward: <8.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "        if info[\"error\"]:\n",
    "            print(\"Stopping\")\n",
    "            break\n",
    "        if terminated or truncated:\n",
    "            print(\"Episode done\")\n",
    "            break\n",
    "        # time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29e42ab0-f298-4443-983e-ee356ed9b61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.38666666, -0.00944287,  0.15      ,  0.00708215], dtype=float32),\n",
       " {'error': False, 'dtime': 2.118, 'elapsed_time': 4.105744123458862})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f17830a-cf64-4f28-b268-f1770ee132eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step   |             Observation              |  Reward  |   Done   | Info\n",
      "Total reward: -15.466197187222843\n"
     ]
    }
   ],
   "source": [
    "# Run reward test (try moving the pendulum)\n",
    "print(f\"{'Step': ^8} | {'Observation': ^36} | {'Reward': ^8} | {'Done': ^8} | Info\")\n",
    "rewards = []\n",
    "for i in range(100):\n",
    "    obs, reward, terminated, truncated, info = env.step(np.array([[0.0]]))\n",
    "    rewards.append(reward)\n",
    "    obs_str = \", \".join([f\"{val:.2f}\" for val in obs])\n",
    "    # print(f\"{i: ^8} | {obs_str: <36} | {reward: <8.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "    if info[\"error\"]:\n",
    "        print(\"Stopping\")\n",
    "        break\n",
    "    if terminated or truncated:\n",
    "        print(\"Episode done\")\n",
    "        break\n",
    "\n",
    "print(f\"Total reward: {sum(rewards)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3b1cc85-0cc9-496e-93ba-4f670de7c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs: [0.39333335 0.02290219 0.15       0.00119837], info: {'error': False, 'dtime': 12.517, 'elapsed_time': 4.110898971557617}\n",
      "Episode done\n"
     ]
    }
   ],
   "source": [
    "# Test timeout (stepper will reset and vibrate for a while)\n",
    "obs, info = env.reset()\n",
    "print(f\"obs: {obs}, info: {info}\")\n",
    "action = 0.1\n",
    "if not info[\"error\"]:\n",
    "    for i in range(1000):\n",
    "        action = -0.1 if action == 0.1 else 0.1\n",
    "        obs, reward, terminated, truncated, info = env.step(np.array([[action]]))\n",
    "        # print(f\"{i: ^8} | {obs_str: <36} | {reward: <8.2f} | {str(terminated or truncated): ^8} | {info}\")\n",
    "        if terminated or truncated:\n",
    "            print(\"Episode done\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75c8710f-6a1b-4e54-ab1c-82cbc4d73080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final environment check to make sure it works with Stable-Baselines3 (no errors means it worked)\n",
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f593d48-dacf-424b-ae3c-531b2d5914c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a13f9-7fd8-41b8-a132-7ba226d43345",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74f6d7db-4f12-400a-b61e-b726e8f028a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that tests the model in the given environment\n",
    "def test_agent(env, model, max_steps=0):\n",
    "\n",
    "    # Reset environment\n",
    "    obs, info = env.reset()\n",
    "    ep_len = 0\n",
    "    ep_rew = 0\n",
    "    avg_step_time = 0.0\n",
    "    actions = []\n",
    "\n",
    "    # Run episode until complete\n",
    "    while True:\n",
    "\n",
    "        # Provide observation to policy to predict the next action\n",
    "        timestamp = time.time()\n",
    "        action, _ = model.predict(obs)\n",
    "        actions.append(action)\n",
    "\n",
    "        # Perform action, update total reward\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        avg_step_time += time.time() - timestamp\n",
    "        ep_rew += reward\n",
    "\n",
    "        # Increase step counter\n",
    "        ep_len += 1\n",
    "        if (max_steps > 0) and (ep_len >= max_steps):\n",
    "            break\n",
    "\n",
    "        # Check to see if episode has ended\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "        \n",
    "    # Calculate average step time\n",
    "    avg_step_time /= ep_len\n",
    "    \n",
    "    # Calculate action stats\n",
    "    action_mean = np.mean(np.array(actions))\n",
    "    action_std = np.std(np.array(actions))\n",
    "    \n",
    "    return ep_len, ep_rew, avg_step_time, action_mean, action_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de81902-9bcc-451d-99fd-7db9febdd73a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing and logging callbacks\n",
    "\n",
    "Construct custom callbacks for Stable-Baselines3 to test our agent and log metrics to Weights & Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f3870bb-7d23-4d12-a171-4f284c3335e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate agent on a number of tests\n",
    "def evaluate_agent(env, model, steps_per_test, num_tests):\n",
    "    \n",
    "    # Initialize metrics\n",
    "    avg_ep_len = 0.0\n",
    "    avg_ep_rew = 0.0\n",
    "    avg_step_time = 0.0\n",
    "    avg_action_mean = 0.0\n",
    "    avg_action_std = 0.0\n",
    "    \n",
    "    # Test the agent a number of times\n",
    "    for ep in range(num_tests):\n",
    "        ep_len, ep_rew, step_time, action_mean, action_std = test_agent(env, model, max_steps=steps_per_test)\n",
    "        avg_ep_len += ep_len\n",
    "        avg_ep_rew += ep_rew\n",
    "        avg_step_time += step_time\n",
    "        avg_action_mean += action_mean\n",
    "        avg_action_std += action_std\n",
    "        \n",
    "    # Compute metrics\n",
    "    avg_ep_len /= num_tests\n",
    "    avg_ep_rew /= num_tests\n",
    "    avg_step_time /= num_tests\n",
    "    avg_action_mean /= num_tests\n",
    "    avg_action_std /= num_tests\n",
    "    \n",
    "    return avg_ep_len, avg_ep_rew, avg_step_time, avg_action_mean, avg_action_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e467390-4f21-48cd-a5e3-2862ddf25cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalAndSaveCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Evaluate and save the model every ``check_freq`` steps\n",
    "    \n",
    "    More info: https://stable-baselines3.readthedocs.io/en/master/guide/callbacks.html\n",
    "    \"\"\"\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(\n",
    "        self, \n",
    "        check_freq, \n",
    "        save_dir,\n",
    "        model_name=\"model\",\n",
    "        replay_buffer_name=None,\n",
    "        steps_per_test=0, \n",
    "        num_tests=10,\n",
    "        step_offset=0,\n",
    "        verbose=1,\n",
    "    ):\n",
    "        super(EvalAndSaveCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_dir = save_dir\n",
    "        self.model_name = model_name\n",
    "        self.replay_buffer_name = replay_buffer_name\n",
    "        self.num_tests = num_tests\n",
    "        self.steps_per_test = steps_per_test\n",
    "        self.step_offset = step_offset\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    # Create directory for saving the models\n",
    "    def _init_callback(self):\n",
    "        if self.save_dir is not None:\n",
    "            os.makedirs(self.save_dir, exist_ok=True)\n",
    "            \n",
    "    # Save and evaluate model at a set interval\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            \n",
    "            # Set actual number of steps (including offset)\n",
    "            actual_steps = self.step_offset + self.n_calls\n",
    "            \n",
    "            # Save model\n",
    "            model_path = os.path.join(self.save_dir, f\"{self.model_name}_{str(actual_steps)}\")\n",
    "            self.model.save(model_path)\n",
    "            \n",
    "            # Save replay buffer\n",
    "            if self.replay_buffer_name != None:\n",
    "                replay_buffer_path = os.path.join(self.save_dir, f\"{self.replay_buffer_name}\")\n",
    "                self.model.save_replay_buffer(replay_buffer_path)\n",
    "            \n",
    "            # Evaluate the agent\n",
    "            avg_ep_len, avg_ep_rew, avg_step_time, avg_action_mean, avg_action_std = evaluate_agent(\n",
    "                env, \n",
    "                self.model, \n",
    "                self.steps_per_test, \n",
    "                self.num_tests\n",
    "            )\n",
    "            if self.verbose:\n",
    "                print(f\"{str(actual_steps)} steps | average test length: {avg_ep_len}, average test reward: {avg_ep_rew}\")\n",
    "                \n",
    "            # Log metrics to WandB\n",
    "            log_dict = {\n",
    "                'avg_ep_len': avg_ep_len,\n",
    "                'avg_ep_rew': avg_ep_rew,\n",
    "                'avg_step_time': avg_step_time,\n",
    "                'avg_action_mean': avg_action_mean,\n",
    "                'avg_action_std': avg_action_std,\n",
    "            }\n",
    "            wandb.log(log_dict, commit=True, step=actual_steps)\n",
    "            \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ef5e1e7-bc63-4288-9a2e-f165b78a17fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandBWriter(KVWriter):\n",
    "    \"\"\"\n",
    "    Log metrics to Weights & Biases when called by .learn()\n",
    "    \n",
    "    More info: https://stable-baselines3.readthedocs.io/en/master/_modules/stable_baselines3/common/logger.html#KVWriter\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize run\n",
    "    def __init__(self, run, verbose=1):\n",
    "        super().__init__()\n",
    "        self.run = run\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # Write metrics to W&B project\n",
    "    def write(self, \n",
    "              key_values: Dict[str, Any], \n",
    "              key_excluded: Dict[str, Union[str, Tuple[str, ...]]], \n",
    "              step: int = 0) -> None:\n",
    "        log_dict = {}\n",
    "        \n",
    "        # Go through each key/value pairs\n",
    "        for (key, value), (_, excluded) in zip(\n",
    "            sorted(key_values.items()), sorted(key_excluded.items())):\n",
    "            \n",
    "            if self.verbose >= 2:\n",
    "                print(f\"step={step} | {key} : {value} ({type(value)})\")\n",
    "            \n",
    "            # Skip excluded items\n",
    "            if excluded is not None and \"wandb\" in excluded:\n",
    "                continue\n",
    "                \n",
    "            # Log integers and floats\n",
    "            if isinstance(value, np.ScalarType):\n",
    "                if not isinstance(value, str):\n",
    "                    wandb.log(data={key: value}, step=step)\n",
    "                    log_dict[key] = value\n",
    "                \n",
    "        # Print to console\n",
    "        if self.verbose >= 1:\n",
    "            print(f\"Log for steps={step}\")\n",
    "            print(f\"--------------\")\n",
    "            for (key, value) in sorted(log_dict.items()):\n",
    "                print(f\"  {key}: {value}\")\n",
    "            print()\n",
    "                \n",
    "    # Close the W&B run\n",
    "    def close(self) -> None:\n",
    "        self.run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdecb53-cf01-41b5-ad9e-224806c4ac7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define train and test function for a single trial\n",
    "\n",
    "A single \"trial\" is fully training and then testing the agent using one set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aebdc5ce-4123-448c-a675-d067932e24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_trial(settings, hparams):\n",
    "    \"\"\"\n",
    "    Training loop used to evaluate a set of hyperparameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set random seed\n",
    "    set_random_seeds(settings['seed'])\n",
    "    \n",
    "    # Create new W&B run\n",
    "    config = {}\n",
    "    dt = datetime.datetime.now(datetime.timezone.utc)\n",
    "    dt = dt.replace(microsecond=0, tzinfo=None)\n",
    "    run = wandb.init(\n",
    "        project=settings['wandb_project'], \n",
    "        name=str(dt), \n",
    "        config=config,\n",
    "        settings=wandb.Settings(silent=(not settings['verbose_wandb']))\n",
    "    )\n",
    "\n",
    "    # Print run info\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(f\"WandB run ID: {run.id}\")\n",
    "        print(f\"WandB run name: {run.name}\")\n",
    "    \n",
    "    # Log hyperparameters to W&B\n",
    "    wandb.config.update(hparams)\n",
    "    \n",
    "    # Set custom logger with our custom writer\n",
    "    wandb_writer = WandBWriter(run, verbose=settings['verbose_log'])\n",
    "    loggers = Logger(\n",
    "        folder=None,\n",
    "        output_formats=[wandb_writer]\n",
    "    )\n",
    "    \n",
    "    # Calculate derived hyperparameters\n",
    "    n_steps = 2 ** hparams['steps_per_update_pow2']\n",
    "    minibatch_size = (hparams['n_envs'] * n_steps) // (2 ** hparams['batch_size_div_pow2'])\n",
    "    layer_1 = 2 ** hparams['layer_1_pow2']\n",
    "    layer_2 = 2 ** hparams['layer_2_pow2']\n",
    "\n",
    "    # Create new agent\n",
    "    # PPO docs: https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html\n",
    "    # Policy networks: https://stable-baselines.readthedocs.io/en/master/modules/policies.html\n",
    "    model = sb3.PPO(\n",
    "        'MlpPolicy',\n",
    "        env,\n",
    "        learning_rate=hparams['learning_rate'], # Learning rate of neural network (default: 0.0003)\n",
    "        n_steps=n_steps,                        # Number of steps per update (default: 2048)\n",
    "        batch_size=minibatch_size,              # Minibatch size for NN update (default: 64)\n",
    "        gamma=hparams['gamma'],                 # Discount factor (default: 0.99)\n",
    "        gae_lambda=hparams['gae_lambda'],       # Trade-off of bias vs. variance for GAE (default: 0.95)\n",
    "        clip_range=hparams['clip_range'],       # Clipping parameter (default: 0.2)\n",
    "        ent_coef=hparams['entropy_coef'],       # Entropy, how much to explore (default: 0.0)\n",
    "        vf_coef=hparams['vf_coef'],             # Value function coefficient for the loss calculation (default: 0.5)\n",
    "        max_grad_norm=hparams['max_grad_norm'], # Max value for gradient clipping (default: 0.5)\n",
    "        use_sde=hparams['use_sde'],             # Use generalized State Dependent Exploration (default: False)\n",
    "        sde_sample_freq=hparams['sde_freq'],    # Number of steps before sampling new noise matrix (default -1)\n",
    "        policy_kwargs={'net_arch': [layer_1, layer_2]}, # (default: [64, 64])\n",
    "        verbose=settings['verbose_train']       # Print training metrics (default: 0)\n",
    "    )\n",
    "    steps_to_complete = settings['total_steps']\n",
    "        \n",
    "    # Set up checkpoint callback\n",
    "    checkpoint_callback = EvalAndSaveCallback(\n",
    "        check_freq=settings['checkpoint_freq'], \n",
    "        save_dir=settings['save_dir'],\n",
    "        model_name=settings['model_name'],\n",
    "        replay_buffer_name=settings['replay_buffer_name'],\n",
    "        steps_per_test=settings['steps_per_test'],\n",
    "        num_tests=settings['tests_per_check'],\n",
    "        step_offset=(settings['total_steps'] - steps_to_complete),\n",
    "        verbose=settings['verbose_test'],\n",
    "    )\n",
    "    \n",
    "    # Choo choo train\n",
    "    model.learn(total_timesteps=steps_to_complete, \n",
    "                callback=[checkpoint_callback])\n",
    "    \n",
    "    # Get dataframe of run metrics\n",
    "    history = wandb.Api().run(f\"{run.project}/{run.id}\").history()\n",
    "\n",
    "    # Get index of evaluation with maximum reward\n",
    "    max_idx = np.argmax(history.loc[:, 'avg_ep_rew'].values)\n",
    "\n",
    "    # Find number of steps required to produce that maximum reward\n",
    "    max_rew_steps = history['_step'][max_idx]\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(f\"Steps with max reward: {max_rew_steps}\")\n",
    "    \n",
    "    # Load model with maximum reward from previous run\n",
    "    model_path = os.path.join(settings['save_dir'], f\"{settings['model_name']}_{str(max_rew_steps)}.zip\")\n",
    "    model = sb3.PPO.load(model_path, env)\n",
    "    \n",
    "    # Evaluate the agent\n",
    "    avg_ep_len, avg_ep_rew, avg_step_time, avg_action_mean, avg_action_std = evaluate_agent(\n",
    "        env, \n",
    "        model, \n",
    "        settings['steps_per_test'],\n",
    "        settings['tests_per_check'],\n",
    "    )\n",
    "    \n",
    "    # Log final evaluation metrics to WandB run\n",
    "    wandb.run.summary['Average test episode length'] = avg_ep_len\n",
    "    wandb.run.summary['Average test episode reward'] = avg_ep_rew\n",
    "    wandb.run.summary['Average test step time'] = avg_step_time\n",
    "    \n",
    "    # Print final run metrics\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(\"---\")\n",
    "        print(f\"Best model: {settings['model_name']}_{str(max_rew_steps)}.zip\")\n",
    "        print(f\"Average episode length: {avg_ep_len}\")\n",
    "        print(f\"Average episode reward: {avg_ep_rew}\")\n",
    "        print(f\"Average step time: {avg_step_time}\")\n",
    "        print(f\"Average action mean: {avg_action_mean}\")\n",
    "        print(f\"Average action std dev: {avg_action_std}\")\n",
    "                      \n",
    "    # Close W&B run\n",
    "    run.finish()\n",
    "    \n",
    "    return avg_ep_rew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a7822-6c9e-4fff-a03f-0304d787702d",
   "metadata": {},
   "source": [
    "## Perform trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "288b5de3-822d-4395-b1e8-2537680b0336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project settings that do not change\n",
    "settings = {\n",
    "    'wandb_project': \"pendulum-esp32-hpo-1\",\n",
    "    'model_name': \"ppo-pendulum\",\n",
    "    'ax_experiment_name': \"ppo-pendulum-esp32-1\",\n",
    "    'ax_objective_name': \"avg_ep_rew\",\n",
    "    'replay_buffer_name': None,\n",
    "    'save_dir': \"checkpoints\",\n",
    "    'checkpoint_freq': 5_000,\n",
    "    'steps_per_test': 500,\n",
    "    'tests_per_check': 10,\n",
    "    'total_steps': 50_000,\n",
    "    'num_trials': 100,\n",
    "    'seed': 42,\n",
    "    'verbose_ax': False,\n",
    "    'verbose_wandb': False,\n",
    "    'verbose_train': 0,\n",
    "    'verbose_log': 0,\n",
    "    'verbose_test': 0,\n",
    "    'verbose_trial': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed4bcd36-4d5a-489a-8a4c-86403a6a1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters we want to optimize\n",
    "# Ref: https://github.com/facebook/Ax/blob/6443cee30cbf8cec290200a7420a3db08e4b5445/ax/service/ax_client.py#L236\n",
    "# Example: https://github.com/facebook/Ax/blob/main/tutorials/tune_cnn_service.ipynb\n",
    "# Hyperparameters: https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#stable_baselines3.ppo.PPO\n",
    "hparams = [\n",
    "    {\n",
    "        'name': \"n_envs\",\n",
    "        'type': \"fixed\",\n",
    "        'value_type': \"int\",\n",
    "        'value': 1,\n",
    "    },\n",
    "    {\n",
    "        'name': \"learning_rate\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [1e-5, 1e-3],\n",
    "        'log_scale': True,\n",
    "    },\n",
    "    {\n",
    "        'name': \"steps_per_update_pow2\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"int\",\n",
    "        'bounds': [8, 11], # Inclusive, 2**n between [256, 2048]\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"batch_size_div_pow2\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"int\",\n",
    "        'bounds': [0, 3], # Inclusive, 2**n between [512, 4096]\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"gae_lambda\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.9, 0.99],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"clip_range\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.1, 0.4],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"gamma\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.92, 0.99],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"entropy_coef\",\n",
    "        'value_type': \"float\",\n",
    "        'type': \"range\",\n",
    "        'bounds': [0.0, 0.01],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"vf_coef\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.2, 0.7],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"max_grad_norm\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.5, 5.0],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"use_sde\",\n",
    "        'type': \"fixed\",\n",
    "        'value_type': \"bool\",\n",
    "        'value': True,\n",
    "    },\n",
    "    {\n",
    "        'name': \"sde_freq\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"int\",\n",
    "        'bounds': [2, 6],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"layer_1_pow2\",\n",
    "        'type': \"fixed\",\n",
    "        'value_type': \"int\",\n",
    "        'value': 8, # 2**n (is 256)\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"layer_2_pow2\",\n",
    "        'type': \"fixed\",\n",
    "        'value_type': \"int\",\n",
    "        'value': 8, # 2**n (is 256)\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Set parameter constraints\n",
    "# Example: https://github.com/facebook/Ax/issues/621\n",
    "parameter_constraints = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af5b3fb4-2186-425e-8079-a54735dde9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our environment\n",
    "try:\n",
    "    env.close()\n",
    "except:\n",
    "    pass\n",
    "env = Pendulum(\n",
    "        SERIAL_PORT,\n",
    "        BAUD_RATE,\n",
    "        ctrl_timeout=CTRL_TIMEOUT,\n",
    "        debug_level=DEBUG_LEVEL,\n",
    "        env_timeout=ENV_TIMEOUT, \n",
    "        stp_mode=STEP_MODE, \n",
    "        stp_blocking=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "362c011c-85ab-4460-a5cd-a2a687feb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosntruct path to Ax experiment snapshot file\n",
    "ax_snapshot_path = os.path.join(settings['save_dir'], f\"{settings['ax_experiment_name']}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8a7eb35-aa2f-47ff-bdbf-de1658632e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DANGER! Uncomment to delete the experiment file to start over\n",
    "\n",
    "# os.remove(ax_snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70621040-a54e-4e8b-ba5b-89f30be1730f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 10-05 08:17:03] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading experiment from snapshot: checkpoints\\ppo-pendulum-esp32-1.json\n"
     ]
    }
   ],
   "source": [
    "# Load experiment from snapshot if it exists, otherwise create a new one\n",
    "# Ref: https://ax.dev/versions/0.2.10/api/service.html#ax.service.ax_client.AxClient.create_experiment\n",
    "if os.path.exists(ax_snapshot_path):\n",
    "    print(f\"Loading experiment from snapshot: {ax_snapshot_path}\")\n",
    "    ax_client = AxClient.load_from_json_file(ax_snapshot_path)\n",
    "else:\n",
    "    print(f\"Creating new experiment. Snapshot to be saved at {ax_snapshot_path}.\")\n",
    "    ax_client = AxClient(\n",
    "        random_seed=settings['seed'],\n",
    "        verbose_logging=settings['verbose_ax'],\n",
    "    )\n",
    "    ax_client.create_experiment(\n",
    "        name=settings['ax_experiment_name'],\n",
    "        parameters=hparams,\n",
    "        objective_name=settings['ax_objective_name'],\n",
    "        minimize=False,\n",
    "        parameter_constraints=parameter_constraints,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e98af995-9535-44d0-b269-16d341f7b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DANGER! Use this cell to mark trials as failed (e.g. if component breaks and WandB shows bad data for a given trial)\n",
    "# Check .json file with a site like https://jsonformatter.org/json-pretty-print\n",
    "\n",
    "# trial_index = 8\n",
    "# trial = ax_client.experiment.trials[trial_index]\n",
    "# trial.mark_failed(unsafe=True)\n",
    "# print(trial)\n",
    "# ax_client.save_to_json_file(ax_snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4a184b8-3f2b-48cf-9e07-c8f97dd23ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 10-05 08:17:06] ax.service.ax_client: Generated new trial 1 with parameters {'learning_rate': 4.3e-05, 'steps_per_update_pow2': 10, 'batch_size_div_pow2': 1, 'gae_lambda': 0.974512, 'clip_range': 0.20621, 'gamma': 0.970567, 'entropy_coef': 0.009551, 'vf_coef': 0.356935, 'max_grad_norm': 3.890971, 'sde_freq': 2, 'n_envs': 1, 'use_sde': True, 'layer_1_pow2': 8, 'layer_2_pow2': 8}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial 1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run ID: 7dfxzqm2\n",
      "WandB run name: 2023-10-05 14:17:06\n",
      "Steps with max reward: 35000\n",
      "---\n",
      "Best model: ppo-pendulum_35000.zip\n",
      "Average episode length: 232.9\n",
      "Average episode reward: -32.14707204680953\n",
      "Average step time: 0.1109757172711336\n",
      "Average action mean: -0.0015010806528152898\n",
      "Average action std dev: 0.9946295022964478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 10-05 11:21:25] ax.service.ax_client: Completed trial 1 with data: {'avg_ep_rew': (-32.147072, None)}.\n",
      "[INFO 10-05 11:21:25] ax.service.ax_client: Saved JSON-serialized state of optimization to `checkpoints\\ppo-pendulum-esp32-1.json`.\n",
      "[INFO 10-05 11:21:25] ax.service.ax_client: Generated new trial 2 with parameters {'learning_rate': 1.7e-05, 'steps_per_update_pow2': 9, 'batch_size_div_pow2': 2, 'gae_lambda': 0.910865, 'clip_range': 0.171547, 'gamma': 0.976132, 'entropy_coef': 0.001144, 'vf_coef': 0.303073, 'max_grad_norm': 3.418562, 'sde_freq': 3, 'n_envs': 1, 'use_sde': True, 'layer_1_pow2': 8, 'layer_2_pow2': 8}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial 2 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201c4cd6e2b44dc5b3a8a0bb7b7aa072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333327028, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run ID: 3k8b0neg\n",
      "WandB run name: 2023-10-05 17:21:25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Perform trial\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m avg_ep_rew \u001b[38;5;241m=\u001b[39m \u001b[43mdo_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_hparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m ax_client\u001b[38;5;241m.\u001b[39mcomplete_trial(\n\u001b[0;32m     16\u001b[0m     trial_index\u001b[38;5;241m=\u001b[39mtrial_index,\n\u001b[0;32m     17\u001b[0m     raw_data\u001b[38;5;241m=\u001b[39mavg_ep_rew,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Save experiment snapshot\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[40], line 76\u001b[0m, in \u001b[0;36mdo_trial\u001b[1;34m(settings, hparams)\u001b[0m\n\u001b[0;32m     64\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m EvalAndSaveCallback(\n\u001b[0;32m     65\u001b[0m     check_freq\u001b[38;5;241m=\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_freq\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     66\u001b[0m     save_dir\u001b[38;5;241m=\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_dir\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m     verbose\u001b[38;5;241m=\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose_test\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     73\u001b[0m )\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Choo choo train\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_to_complete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Get dataframe of run metrics\u001b[39;00m\n\u001b[0;32m     80\u001b[0m history \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mApi()\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39mproject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mhistory()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:259\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 259\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:184\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n\u001b[0;32m    183\u001b[0m callback\u001b[38;5;241m.\u001b[39mupdate_locals(\u001b[38;5;28mlocals\u001b[39m())\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_info_buffer(infos)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:104\u001b[0m, in \u001b[0;36mBaseCallback.on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_calls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:208\u001b[0m, in \u001b[0;36mCallbackList._on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Return False (stop training) if at least one callback returns False\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m continue_training\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m continue_training\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:104\u001b[0m, in \u001b[0;36mBaseCallback.on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_calls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[38], line 52\u001b[0m, in \u001b[0;36mEvalAndSaveCallback._on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_replay_buffer(replay_buffer_path)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Evaluate the agent\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m avg_ep_len, avg_ep_rew, avg_step_time, avg_action_mean, avg_action_std \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps_per_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_tests\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(actual_steps)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m steps | average test length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_ep_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, average test reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_ep_rew\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[37], line 13\u001b[0m, in \u001b[0;36mevaluate_agent\u001b[1;34m(env, model, steps_per_test, num_tests)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Test the agent a number of times\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_tests):\n\u001b[1;32m---> 13\u001b[0m     ep_len, ep_rew, step_time, action_mean, action_std \u001b[38;5;241m=\u001b[39m \u001b[43mtest_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     avg_ep_len \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ep_len\n\u001b[0;32m     15\u001b[0m     avg_ep_rew \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ep_rew\n",
      "Cell \u001b[1;32mIn[36], line 20\u001b[0m, in \u001b[0;36mtest_agent\u001b[1;34m(env, model, max_steps)\u001b[0m\n\u001b[0;32m     17\u001b[0m actions\u001b[38;5;241m.\u001b[39mappend(action)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Perform action, update total reward\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m avg_step_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m timestamp\n\u001b[0;32m     22\u001b[0m ep_rew \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[24], line 100\u001b[0m, in \u001b[0;36mPendulum.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     97\u001b[0m action_list \u001b[38;5;241m=\u001b[39m action_scaled\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Move the stepper motor and wait for a response\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCMD_MOVE_BY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp:\n\u001b[0;32m    102\u001b[0m     \n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# Extract information from controller response\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     status, timestamp, terminated, angles \u001b[38;5;241m=\u001b[39m resp\n",
      "File \u001b[1;32mD:\\Projects\\GitHub\\pendulum-rl\\control_comms.py:249\u001b[0m, in \u001b[0;36mControlComms.step\u001b[1;34m(self, command, action)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# Wait for a response\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 249\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_until\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug_level \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m DebugLevel\u001b[38;5;241m.\u001b[39mDEBUG_ERROR:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\serial\\serialutil.py:663\u001b[0m, in \u001b[0;36mSerialBase.read_until\u001b[1;34m(self, expected, size)\u001b[0m\n\u001b[0;32m    661\u001b[0m timeout \u001b[38;5;241m=\u001b[39m Timeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout)\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 663\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c:\n\u001b[0;32m    665\u001b[0m         line \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m c\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\serial\\serialwin32.py:288\u001b[0m, in \u001b[0;36mSerial.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m read_ok \u001b[38;5;129;01mand\u001b[39;00m win32\u001b[38;5;241m.\u001b[39mGetLastError() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (win32\u001b[38;5;241m.\u001b[39mERROR_SUCCESS, win32\u001b[38;5;241m.\u001b[39mERROR_IO_PENDING):\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SerialException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadFile failed (\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ctypes\u001b[38;5;241m.\u001b[39mWinError()))\n\u001b[1;32m--> 288\u001b[0m result_ok \u001b[38;5;241m=\u001b[39m \u001b[43mwin32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetOverlappedResult\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_port_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_overlapped_read\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result_ok:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m win32\u001b[38;5;241m.\u001b[39mGetLastError() \u001b[38;5;241m!=\u001b[39m win32\u001b[38;5;241m.\u001b[39mERROR_OPERATION_ABORTED:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Choo choo! Perform trials to optimize hyperparameters\n",
    "while True:\n",
    "    \n",
    "    # Get next hyperparameters and end experiment if we've reached max trials\n",
    "    next_hparams, trial_index = ax_client.get_next_trial()\n",
    "    if trial_index >= settings['num_trials']:\n",
    "        break\n",
    "        \n",
    "    # Show that we're starting a new trial\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(f\"--- Trial {trial_index} ---\")\n",
    "        \n",
    "    # Perform trial\n",
    "    avg_ep_rew = do_trial(settings, next_hparams)\n",
    "    ax_client.complete_trial(\n",
    "        trial_index=trial_index,\n",
    "        raw_data=avg_ep_rew,\n",
    "    )\n",
    "    \n",
    "    # Save experiment snapshot\n",
    "    ax_client.save_to_json_file(ax_snapshot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1dc72-fc2e-4b2f-8f55-7c83978d67d9",
   "metadata": {},
   "source": [
    "## Analyze Top Performing Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a823a-2a29-4da1-9f07-8e8fdb99c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get runs in WandB project\n",
    "runs = wandb.Api().runs(settings['wandb_project'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b848830-72fe-42aa-b860-0542ce4164f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot best average episode reward from each run over time\n",
    "avg_rews = []\n",
    "for i, run in enumerate(runs):\n",
    "    avg_rew = run.summary['Average test episode reward']\n",
    "    if isinstance(avg_rew, float):\n",
    "        avg_rews.append(avg_rew)\n",
    "avg_rews.reverse()\n",
    "plt.plot(avg_rews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859de2a9-09c9-4d5f-b22a-53598098d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file path\n",
    "csv_file_path = os.path.join(\".\", settings['wandb_project'] + \".csv\")\n",
    "\n",
    "# List summary names\n",
    "summary_names = [\n",
    "    \"Average test episode reward\",\n",
    "    \"Average test episode length\",\n",
    "    \"Average test step time\",\n",
    "]\n",
    "\n",
    "# Get hyperparameter names\n",
    "hparam_names = [hparam['name'] for hparam in hparams]\n",
    "\n",
    "print()\n",
    "\n",
    "# Create CSV with HPO trial results\n",
    "with open(csv_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"name\"] + summary_names + hparam_names)\n",
    "    for run in runs:\n",
    "        row = [run.name]\n",
    "        for name in summary_names:\n",
    "            row.append(run.summary[name])\n",
    "        for name in hparam_names:\n",
    "            row.append(run.config[name])\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dadaee-9b34-4fa4-bd19-71261541b871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
